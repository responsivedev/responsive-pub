Initialized native services in: /Users/sophie/.gradle/native
Initialized jansi services in: /Users/sophie/.gradle/native
Received JVM installation metadata from '/Users/sophie/Library/Java/JavaVirtualMachines/corretto-17.0.7/Contents/Home': {JAVA_HOME=/Users/sophie/Library/Java/JavaVirtualMachines/corretto-17.0.7/Contents/Home, JAVA_VERSION=17.0.7, JAVA_VENDOR=Amazon.com Inc., RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=17.0.7+7-LTS, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=17.0.7+7-LTS, VM_VENDOR=Amazon.com Inc., OS_ARCH=aarch64}
The client will now receive all logging from the daemon (pid: 79783). The daemon log file: /Users/sophie/.gradle/daemon/8.1.1/daemon-79783.out.log
Starting 2nd build in daemon [uptime: 51.963 secs, performance: 98%, GC rate: 0.00/s, heap usage: 0% of 512 MiB, non-heap usage: 13% of 384 MiB]
Using 8 worker leases.
Now considering [/Users/sophie/Responsive/responsive-pub-copy, /Users/sophie/Responsive/responsive-pub-copy/buildSrc] as hierarchies to watch
Now considering [/Users/sophie/Responsive/responsive-pub-copy/buildSrc, /Users/sophie/Responsive/responsive-pub-copy] as hierarchies to watch
Watching the file system is configured to be enabled if available
Invalidating hierarchy because watch probe hasn't been triggered /Users/sophie/Responsive/responsive-pub-copy
Invalidating hierarchy because watch probe hasn't been triggered /Users/sophie/Responsive/responsive-pub-copy/buildSrc
Not watching anything anymore
Watching 0 directory hierarchies to track changes
File system watching is active
Starting Build
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration detachedConfiguration2 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration2 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration detachedConfiguration2 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration2 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Settings evaluated using settings file '/Users/sophie/Responsive/responsive-pub-copy/settings.gradle.kts'.
Skipping generation of dependency accessors for libs as it is up-to-date.
Skipping generation of dependency accessors for testlibs as it is up-to-date.
Projects loaded. Root project using build file '/Users/sophie/Responsive/responsive-pub-copy/build.gradle.kts'.
Included projects: [root project 'responsive-pub', project ':controller-api', project ':kafka-client', project ':kafka-client-bootstrap', project ':kafka-client-examples', project ':operator', project ':responsive-spring', project ':responsive-test-utils', project ':tools', project ':kafka-client-examples:e2e-test', project ':kafka-client-examples:simple-example']

> Configure project :buildSrc
Evaluating project ':buildSrc' using build file '/Users/sophie/Responsive/responsive-pub-copy/buildSrc/build.gradle.kts'.
Caching disabled for Kotlin DSL plugin specs accessors for classpath 'b071c723bc5d6b66c9ab8003947fb7ac' because:
  Build cache is disabled
Skipping Kotlin DSL plugin specs accessors for classpath 'b071c723bc5d6b66c9ab8003947fb7ac' as it is up-to-date.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage1) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage1) as it is up-to-date.
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :buildSrc:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :buildSrc:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :buildSrc:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :buildSrc:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Resource missing. [HTTP HEAD: https://plugins.gradle.org/m2/org/gradle/kotlin/kotlin-dsl/org.gradle.kotlin.kotlin-dsl.gradle.plugin/4.0.7/org.gradle.kotlin.kotlin-dsl.gradle.plugin-4.0.7.jar]
Using Kotlin Gradle Plugin gradle76 variant
kotlin scripting plugin: created the scripting discovery configuration: kotlinScriptDef
kotlin scripting plugin: created the scripting discovery configuration: testKotlinScriptDef
file or directory '/Users/sophie/Responsive/responsive-pub-copy/buildSrc/src/main/java', not found
Caching disabled for Kotlin DSL accessors for project ':buildSrc' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':buildSrc' as it is up-to-date.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage2) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage2) as it is up-to-date.
The configuration :buildSrc:mainSourceElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Resolve mutations for :buildSrc:generateExternalPluginSpecBuilders (Thread[Execution worker,5,main]) started.
:buildSrc:generateExternalPluginSpecBuilders (Thread[included builds,5,main]) started.

> Task :buildSrc:generateExternalPluginSpecBuilders UP-TO-DATE
Caching disabled for task ':buildSrc:generateExternalPluginSpecBuilders' because:
  Build cache is disabled
Skipping task ':buildSrc:generateExternalPluginSpecBuilders' as it is up-to-date.
Resolve mutations for :buildSrc:extractPrecompiledScriptPluginPlugins (Thread[included builds,5,main]) started.
:buildSrc:extractPrecompiledScriptPluginPlugins (Thread[Execution worker,5,main]) started.

> Task :buildSrc:extractPrecompiledScriptPluginPlugins UP-TO-DATE
Caching disabled for task ':buildSrc:extractPrecompiledScriptPluginPlugins' because:
  Build cache is disabled
Skipping task ':buildSrc:extractPrecompiledScriptPluginPlugins' as it is up-to-date.
Resolve mutations for :buildSrc:compilePluginsBlocks (Thread[Execution worker,5,main]) started.
:buildSrc:compilePluginsBlocks (Thread[Execution worker,5,main]) started.

> Task :buildSrc:compilePluginsBlocks UP-TO-DATE
Caching disabled for task ':buildSrc:compilePluginsBlocks' because:
  Build cache is disabled
Skipping task ':buildSrc:compilePluginsBlocks' as it is up-to-date.
Resolve mutations for :buildSrc:generatePrecompiledScriptPluginAccessors (Thread[Execution worker,5,main]) started.
:buildSrc:generatePrecompiledScriptPluginAccessors (Thread[Execution worker,5,main]) started.

> Task :buildSrc:generatePrecompiledScriptPluginAccessors UP-TO-DATE
Caching disabled for task ':buildSrc:generatePrecompiledScriptPluginAccessors' because:
  Build cache is disabled
Skipping task ':buildSrc:generatePrecompiledScriptPluginAccessors' as it is up-to-date.
Resolve mutations for :buildSrc:generateScriptPluginAdapters (Thread[Execution worker,5,main]) started.
:buildSrc:generateScriptPluginAdapters (Thread[Execution worker,5,main]) started.

> Task :buildSrc:generateScriptPluginAdapters UP-TO-DATE
Caching disabled for task ':buildSrc:generateScriptPluginAdapters' because:
  Build cache is disabled
Skipping task ':buildSrc:generateScriptPluginAdapters' as it is up-to-date.
Resolve mutations for :buildSrc:compileKotlin (Thread[Execution worker,5,main]) started.
:buildSrc:compileKotlin (Thread[Execution worker,5,main]) started.

> Task :buildSrc:compileKotlin UP-TO-DATE
Custom actions are attached to task ':buildSrc:compileKotlin'.
Caching disabled for task ':buildSrc:compileKotlin' because:
  Build cache is disabled
Skipping task ':buildSrc:compileKotlin' as it is up-to-date.
Resolve mutations for :buildSrc:compileJava (Thread[Execution worker,5,main]) started.
:buildSrc:compileJava (Thread[Execution worker,5,main]) started.

> Task :buildSrc:compileJava NO-SOURCE
Skipping task ':buildSrc:compileJava' as it has no source files and no previous output files.
Resolve mutations for :buildSrc:compileGroovy (Thread[Execution worker,5,main]) started.
:buildSrc:compileGroovy (Thread[Execution worker,5,main]) started.

> Task :buildSrc:compileGroovy NO-SOURCE
Skipping task ':buildSrc:compileGroovy' as it has no source files and no previous output files.
Resolve mutations for :buildSrc:pluginDescriptors (Thread[Execution worker,5,main]) started.
:buildSrc:pluginDescriptors (Thread[Execution worker,5,main]) started.

> Task :buildSrc:pluginDescriptors UP-TO-DATE
Caching disabled for task ':buildSrc:pluginDescriptors' because:
  Build cache is disabled
  Not worth caching
Skipping task ':buildSrc:pluginDescriptors' as it is up-to-date.
Resolve mutations for :buildSrc:processResources (Thread[Execution worker,5,main]) started.
:buildSrc:processResources (Thread[Execution worker,5,main]) started.

> Task :buildSrc:processResources UP-TO-DATE
Caching disabled for task ':buildSrc:processResources' because:
  Build cache is disabled
  Not worth caching
Skipping task ':buildSrc:processResources' as it is up-to-date.
Resolve mutations for :buildSrc:classes (Thread[Execution worker,5,main]) started.
:buildSrc:classes (Thread[Execution worker,5,main]) started.

> Task :buildSrc:classes UP-TO-DATE
Skipping task ':buildSrc:classes' as it has no actions.
Resolve mutations for :buildSrc:jar (Thread[Execution worker,5,main]) started.
:buildSrc:jar (Thread[Execution worker,5,main]) started.

> Task :buildSrc:jar UP-TO-DATE
Caching disabled for task ':buildSrc:jar' because:
  Build cache is disabled
  Not worth caching
Skipping task ':buildSrc:jar' as it is up-to-date.
Resolve mutations for :buildSrc:inspectClassesForKotlinIC (Thread[Execution worker,5,main]) started.
:buildSrc:inspectClassesForKotlinIC (Thread[Execution worker,5,main]) started.

> Task :buildSrc:inspectClassesForKotlinIC UP-TO-DATE
Caching disabled for task ':buildSrc:inspectClassesForKotlinIC' because:
  Build cache is disabled
  Caching has been disabled for the task
Skipping task ':buildSrc:inspectClassesForKotlinIC' as it is up-to-date.

> Configure project :
Evaluating root project 'responsive-pub' using build file '/Users/sophie/Responsive/responsive-pub-copy/build.gradle.kts'.
Caching disabled for Kotlin DSL version catalog plugin accessors for classpath 'f8a5d527ce0a89572c23be3ff04bd89d' because:
  Build cache is disabled
Skipping Kotlin DSL version catalog plugin accessors for classpath 'f8a5d527ce0a89572c23be3ff04bd89d' as it is up-to-date.
Caching disabled for Kotlin DSL plugin specs accessors for classpath 'f8a5d527ce0a89572c23be3ff04bd89d' because:
  Build cache is disabled
Skipping Kotlin DSL plugin specs accessors for classpath 'f8a5d527ce0a89572c23be3ff04bd89d' as it is up-to-date.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage1) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage1) as it is up-to-date.
The configuration :classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for root project 'responsive-pub' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for root project 'responsive-pub' as it is up-to-date.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage2) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage2) as it is up-to-date.

> Configure project :controller-api
Evaluating project ':controller-api' using build file '/Users/sophie/Responsive/responsive-pub-copy/controller-api/build.gradle.kts'.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage1) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage1) as it is up-to-date.
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :controller-api:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :controller-api:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :controller-api:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :controller-api:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Resource missing. [HTTP HEAD: https://plugins.gradle.org/m2/com/google/protobuf/com.google.protobuf.gradle.plugin/0.9.2/com.google.protobuf.gradle.plugin-0.9.2.jar]
The com.google.protobuf plugin was already applied to the project: :controller-api and will not be applied again after plugin: java-library
Caching disabled for Kotlin DSL accessors for project ':controller-api' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':controller-api' as it is up-to-date.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage2) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage2) as it is up-to-date.
------------------------------------------------------------------------
Detecting the operating system and CPU architecture
------------------------------------------------------------------------
os.detected.name=osx
os.detected.arch=aarch_64
os.detected.bitness=64
os.detected.version=13.3
os.detected.version.major=13
os.detected.version.minor=3
os.detected.classifier=osx-aarch_64

> Configure project :kafka-client
Evaluating project ':kafka-client' using build file '/Users/sophie/Responsive/responsive-pub-copy/kafka-client/build.gradle.kts'.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage1) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage1) as it is up-to-date.
The configuration :kafka-client:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':kafka-client' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':kafka-client' as it is up-to-date.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage2) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage2) as it is up-to-date.

> Configure project :kafka-client-bootstrap
Evaluating project ':kafka-client-bootstrap' using build file '/Users/sophie/Responsive/responsive-pub-copy/kafka-client-bootstrap/build.gradle.kts'.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage1) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage1) as it is up-to-date.
The configuration :kafka-client-bootstrap:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-bootstrap:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client-bootstrap:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-bootstrap:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':kafka-client-bootstrap' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':kafka-client-bootstrap' as it is up-to-date.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage2) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage2) as it is up-to-date.

> Configure project :kafka-client-examples
Evaluating project ':kafka-client-examples' using build file '/Users/sophie/Responsive/responsive-pub-copy/kafka-client-examples/build.gradle'.

> Configure project :operator
Evaluating project ':operator' using build file '/Users/sophie/Responsive/responsive-pub-copy/operator/build.gradle.kts'.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage1) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage1) as it is up-to-date.
The configuration :operator:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :operator:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :operator:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :operator:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':operator' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':operator' as it is up-to-date.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage2) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage2) as it is up-to-date.

> Configure project :responsive-spring
Evaluating project ':responsive-spring' using build file '/Users/sophie/Responsive/responsive-pub-copy/responsive-spring/build.gradle.kts'.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage1) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage1) as it is up-to-date.
The configuration :responsive-spring:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :responsive-spring:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :responsive-spring:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :responsive-spring:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':responsive-spring' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':responsive-spring' as it is up-to-date.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage2) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage2) as it is up-to-date.

> Configure project :responsive-test-utils
Evaluating project ':responsive-test-utils' using build file '/Users/sophie/Responsive/responsive-pub-copy/responsive-test-utils/build.gradle.kts'.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage1) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage1) as it is up-to-date.
The configuration :responsive-test-utils:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :responsive-test-utils:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :responsive-test-utils:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :responsive-test-utils:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':responsive-test-utils' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':responsive-test-utils' as it is up-to-date.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage2) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage2) as it is up-to-date.
Starting process 'command '/usr/libexec/java_home''. Working directory: /Users/sophie/.gradle/daemon/8.1.1 Command: /usr/libexec/java_home -V
Successfully started process 'command '/usr/libexec/java_home''

> Configure project :tools
Evaluating project ':tools' using build file '/Users/sophie/Responsive/responsive-pub-copy/tools/build.gradle.kts'.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage1) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage1) as it is up-to-date.
The configuration :tools:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :tools:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :tools:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :tools:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':tools' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':tools' as it is up-to-date.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage2) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage2) as it is up-to-date.
Starting process 'command '/Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home/bin/java''. Working directory: /Users/sophie/.gradle/.tmp/tmp-jvm5055601409698640911probe Command: /Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home/bin/java -cp . JavaProbe
Successfully started process 'command '/Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home/bin/java''
Received JVM installation metadata from '/Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home': {JAVA_HOME=/Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home, JAVA_VERSION=11.0.18, JAVA_VENDOR=Amazon.com Inc., RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=11.0.18+10-LTS, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=11.0.18+10-LTS, VM_VENDOR=Amazon.com Inc., OS_ARCH=aarch64}
Starting process 'command '/Users/sophie/Library/Java/JavaVirtualMachines/openjdk-20/Contents/Home/bin/java''. Working directory: /Users/sophie/.gradle/.tmp/tmp-jvm8789416626198176926probe Command: /Users/sophie/Library/Java/JavaVirtualMachines/openjdk-20/Contents/Home/bin/java -cp . JavaProbe
Successfully started process 'command '/Users/sophie/Library/Java/JavaVirtualMachines/openjdk-20/Contents/Home/bin/java''
Received JVM installation metadata from '/Users/sophie/Library/Java/JavaVirtualMachines/openjdk-20/Contents/Home': {JAVA_HOME=/Users/sophie/Library/Java/JavaVirtualMachines/openjdk-20/Contents/Home, JAVA_VERSION=20, JAVA_VENDOR=Oracle Corporation, RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=20+36-2344, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=20+36-2344, VM_VENDOR=Oracle Corporation, OS_ARCH=aarch64}
Starting process 'command '/Users/sophie/.gradle/jdks/eclipse_adoptium-21-aarch64-os_x/jdk-21.0.4+7/Contents/Home/bin/java''. Working directory: /Users/sophie/.gradle/.tmp/tmp-jvm10128633667031777591probe Command: /Users/sophie/.gradle/jdks/eclipse_adoptium-21-aarch64-os_x/jdk-21.0.4+7/Contents/Home/bin/java -cp . JavaProbe
Successfully started process 'command '/Users/sophie/.gradle/jdks/eclipse_adoptium-21-aarch64-os_x/jdk-21.0.4+7/Contents/Home/bin/java''
Received JVM installation metadata from '/Users/sophie/.gradle/jdks/eclipse_adoptium-21-aarch64-os_x/jdk-21.0.4+7/Contents/Home': {JAVA_HOME=/Users/sophie/.gradle/jdks/eclipse_adoptium-21-aarch64-os_x/jdk-21.0.4+7/Contents/Home, JAVA_VERSION=21.0.4, JAVA_VENDOR=Eclipse Adoptium, RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=21.0.4+7-LTS, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=21.0.4+7-LTS, VM_VENDOR=Eclipse Adoptium, OS_ARCH=aarch64}
The configuration :tools:javadocElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :tools:mainSourceElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :tools:signatures is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :tools:signatures is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :tools:sourcesElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.

> Configure project :kafka-client-examples:e2e-test
Evaluating project ':kafka-client-examples:e2e-test' using build file '/Users/sophie/Responsive/responsive-pub-copy/kafka-client-examples/e2e-test/build.gradle.kts'.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage1) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage1) as it is up-to-date.
The configuration :kafka-client-examples:e2e-test:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-examples:e2e-test:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client-examples:e2e-test:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-examples:e2e-test:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':kafka-client-examples:e2e-test' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':kafka-client-examples:e2e-test' as it is up-to-date.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage2) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage2) as it is up-to-date.
Starting process 'command 'git''. Working directory: /Users/sophie/Responsive/responsive-pub-copy Command: git rev-parse --short HEAD
Successfully started process 'command 'git''

> Configure project :kafka-client-examples:simple-example
Evaluating project ':kafka-client-examples:simple-example' using build file '/Users/sophie/Responsive/responsive-pub-copy/kafka-client-examples/simple-example/build.gradle.kts'.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage1) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage1) as it is up-to-date.
The configuration :kafka-client-examples:simple-example:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-examples:simple-example:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client-examples:simple-example:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-examples:simple-example:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':kafka-client-examples:simple-example' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':kafka-client-examples:simple-example' as it is up-to-date.
Caching disabled for Kotlin DSL script compilation (Project/TopLevel/stage2) because:
  Build cache is disabled
Skipping Kotlin DSL script compilation (Project/TopLevel/stage2) as it is up-to-date.
All projects evaluated.
Task path 'kafka-client:test' matched project ':kafka-client'
Task name matched 'test'
Selected primary task 'test' from project :kafka-client
The configuration :kafka-client:javadocElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client:mainSourceElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client:signatures is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client:signatures is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client:sourcesElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Tasks to be executed: [task ':kafka-client:writeVersionPropertiesFile', task ':kafka-client:compileJava', task ':kafka-client:processResources', task ':kafka-client:classes', task ':kafka-client:compileTestJava', task ':kafka-client:processTestResources', task ':kafka-client:testClasses', task ':kafka-client:test']
Tasks that were excluded: []
Resolve mutations for :kafka-client:writeVersionPropertiesFile (Thread[Execution worker,5,main]) started.
:kafka-client:writeVersionPropertiesFile (Thread[Execution worker,5,main]) started.

> Task :kafka-client:writeVersionPropertiesFile UP-TO-DATE
Custom actions are attached to task ':kafka-client:writeVersionPropertiesFile'.
Caching disabled for task ':kafka-client:writeVersionPropertiesFile' because:
  Build cache is disabled
  Gradle would require more information to cache this task
Skipping task ':kafka-client:writeVersionPropertiesFile' as it is up-to-date.
Resolve mutations for :kafka-client:compileJava (Thread[Execution worker,5,main]) started.
:kafka-client:compileJava (Thread[Execution worker,5,main]) started.

> Task :kafka-client:compileJava UP-TO-DATE
Caching disabled for task ':kafka-client:compileJava' because:
  Build cache is disabled
Skipping task ':kafka-client:compileJava' as it is up-to-date.
Resolve mutations for :kafka-client:processResources (Thread[Execution worker,5,main]) started.
:kafka-client:processResources (Thread[Execution worker,5,main]) started.

> Task :kafka-client:processResources UP-TO-DATE
Caching disabled for task ':kafka-client:processResources' because:
  Build cache is disabled
  Not worth caching
Skipping task ':kafka-client:processResources' as it is up-to-date.
Resolve mutations for :kafka-client:classes (Thread[Execution worker,5,main]) started.
:kafka-client:classes (Thread[Execution worker,5,main]) started.

> Task :kafka-client:classes UP-TO-DATE
Skipping task ':kafka-client:classes' as it has no actions.
Resolve mutations for :kafka-client:compileTestJava (Thread[Execution worker,5,main]) started.
:kafka-client:compileTestJava (Thread[Execution worker,5,main]) started.
This JVM does not support getting OS memory, so no OS memory status updates will be broadcast

> Task :kafka-client:compileTestJava
Caching disabled for task ':kafka-client:compileTestJava' because:
  Build cache is disabled
Task ':kafka-client:compileTestJava' is not up-to-date because:
  Input property 'stableSources' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/src/test/java/dev/responsive/kafka/testutils/ResponsiveExtension.java has changed.
Created classpath snapshot for incremental compilation in 0.137 secs.
Compiling with toolchain '/Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home'.
Starting process 'Gradle Worker Daemon 1'. Working directory: /Users/sophie/.gradle/workers Command: /Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home/bin/java @/Users/sophie/.gradle/.tmp/gradle-worker-classpath2291069819579059751txt -Xmx512m -Dfile.encoding=UTF-8 -Duser.country=US -Duser.language=en -Duser.variant worker.org.gradle.process.internal.worker.GradleWorkerMain 'Gradle Worker Daemon 1'
Successfully started process 'Gradle Worker Daemon 1'
Started Gradle worker daemon (0.551 secs) with fork options DaemonForkOptions{executable=/Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home/bin/java, minHeapSize=null, maxHeapSize=null, jvmArgs=[], keepAliveMode=SESSION}.
Compiling with JDK Java compiler API.
Incremental compilation of 61 classes completed in 16.447 secs.
Class dependency analysis for incremental compilation took 0.221 secs.
Resolve mutations for :kafka-client:processTestResources (Thread[Execution worker,5,main]) started.
:kafka-client:processTestResources (Thread[Execution worker,5,main]) started.

> Task :kafka-client:processTestResources UP-TO-DATE
Caching disabled for task ':kafka-client:processTestResources' because:
  Build cache is disabled
  Not worth caching
Skipping task ':kafka-client:processTestResources' as it is up-to-date.
Resolve mutations for :kafka-client:testClasses (Thread[Execution worker,5,main]) started.
:kafka-client:testClasses (Thread[Execution worker,5,main]) started.

> Task :kafka-client:testClasses
Skipping task ':kafka-client:testClasses' as it has no actions.
Resolve mutations for :kafka-client:test (Thread[Execution worker,5,main]) started.
:kafka-client:test (Thread[Execution worker,5,main]) started.
Gradle Test Executor 2 started executing tests.

> Task :kafka-client:test
Custom actions are attached to task ':kafka-client:test'.
Caching disabled for task ':kafka-client:test' because:
  Build cache is disabled
Task ':kafka-client:test' is not up-to-date because:
  Input property 'candidateClassFiles' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/classes/java/test/dev/responsive/kafka/testutils/ResponsiveExtension$1.class has changed.
  Input property 'candidateClassFiles' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/classes/java/test/dev/responsive/kafka/testutils/ResponsiveExtension.class has changed.
  Input property 'stableClasspath' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/classes/java/test/dev/responsive/kafka/testutils/ResponsiveExtension$1.class has changed.

Starting process 'Gradle Test Executor 2'. Working directory: /Users/sophie/Responsive/responsive-pub-copy/kafka-client Command: /Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home/bin/java -Dorg.gradle.internal.worker.tmpdir=/Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/tmp/test/work -Dorg.gradle.native=false @/Users/sophie/.gradle/.tmp/gradle-worker-classpath14318900745011604460txt -Xmx512m -Dfile.encoding=UTF-8 -Duser.country=US -Duser.language=en -Duser.variant -ea worker.org.gradle.process.internal.worker.GradleWorkerMain 'Gradle Test Executor 2'
Successfully started process 'Gradle Test Executor 2'

Gradle Test Executor 2 STANDARD_OUT

Gradle Test Executor 2 STANDARD_ERROR
    Test 1: creating ResponsiveExtension(backend=CASSANDRA) at 1731054599768ms (speed check)

AsyncProcessorIntegrationTest STANDARD_ERROR
    Test 1(dev.responsive.kafka.async.AsyncProcessorIntegrationTest): CASSANDRA setup begins at 1731054599780ms (speed check)

AsyncProcessorIntegrationTest STANDARD_OUT
      Server Version: 23.0.5
      API Version: 1.42
      Operating System: Docker Desktop
      Total Memory: 3933 MB (org.testcontainers.DockerClientFactory:205)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

AsyncProcessorIntegrationTest STANDARD_ERROR
    Test 1(dev.responsive.kafka.async.AsyncProcessorIntegrationTest): CASSANDRA setup ends at 1731054627061ms (duration: PT27.281S) (speed check)

AsyncProcessorIntegrationTest > shouldProcessStatefulEventsInOrderByKey() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-1
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InputRecordSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 5
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 61487
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 9223372036854775807
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldProcessStatefulEventsInOrderByKey
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 30000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 4
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatefulEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-2-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-2-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-2
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-2-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatefulEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-3-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-3-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-3
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-3-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatefulEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-4-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-4-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-4
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-4-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatefulEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    6c4b6342-422c-487a-83a3-92f6cdb58926: [shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-2-consumer-b96f546c-5ae5-47b6-be2c-3f634ef04011, shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-3-consumer-7b933c8e-c0c4-405d-8cbc-87121e860937]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-2-consumer-b96f546c-5ae5-47b6-be2c-3f634ef04011=[], shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-3-consumer-7b933c8e-c0c4-405d-8cbc-87121e860937=[]}
    	assigned active {shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-2-consumer-b96f546c-5ae5-47b6-be2c-3f634ef04011=[0_10, 0_8, 0_6, 0_4, 0_2, 0_0], shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-3-consumer-7b933c8e-c0c4-405d-8cbc-87121e860937=[0_11, 0_9, 0_7, 0_5, 0_3, 0_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    6c4b6342-422c-487a-83a3-92f6cdb58926: [shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-1-consumer-c772f93e-1977-48a3-a4d8-f6a6f9b6a480, shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-2-consumer-b96f546c-5ae5-47b6-be2c-3f634ef04011, shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-3-consumer-7b933c8e-c0c4-405d-8cbc-87121e860937, shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-4-consumer-b39da7d8-c1de-424d-aff3-09f6e9608118]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-1-consumer-c772f93e-1977-48a3-a4d8-f6a6f9b6a480=[], shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-2-consumer-b96f546c-5ae5-47b6-be2c-3f634ef04011=[], shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-3-consumer-7b933c8e-c0c4-405d-8cbc-87121e860937=[], shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-4-consumer-b39da7d8-c1de-424d-aff3-09f6e9608118=[]}
    	assigned active {shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-1-consumer-c772f93e-1977-48a3-a4d8-f6a6f9b6a480=[0_8, 0_4, 0_0], shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-2-consumer-b96f546c-5ae5-47b6-be2c-3f634ef04011=[0_9, 0_5, 0_1], shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-3-consumer-7b933c8e-c0c4-405d-8cbc-87121e860937=[0_10, 0_6, 0_2], shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-4-consumer-b39da7d8-c1de-424d-aff3-09f6e9608118=[0_11, 0_7, 0_3]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-1, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-5, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-9]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-1, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-5, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-9]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-0, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-4, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-0, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-4, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-3, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-7, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-11]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-3, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-7, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-11]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-2, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-6, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-10]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-2, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-6, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-10]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput, partition=8, offset=8, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput, partition=8, offset=8, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-5-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-5-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-5
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-5-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatefulEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.ProcessorStateException: stream-thread [shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-1] stream-task [0_4] Failed to flush cache of store shouldProcessStatefulEventsInOrderByKeya1
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:546)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.ProcessorStateException: stream-thread [shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-1] stream-task [0_0] Failed to flush cache of store shouldProcessStatefulEventsInOrderByKeya1
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:546)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.ProcessorStateException: stream-thread [shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-1] stream-task [0_8] Failed to flush cache of store shouldProcessStatefulEventsInOrderByKeya1
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:546)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    6c4b6342-422c-487a-83a3-92f6cdb58926: [shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-2-consumer-b96f546c-5ae5-47b6-be2c-3f634ef04011, shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-3-consumer-7b933c8e-c0c4-405d-8cbc-87121e860937, shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-4-consumer-b39da7d8-c1de-424d-aff3-09f6e9608118, shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-5-consumer-a7d388fb-6d80-49fd-90e2-567db4f0d501]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-2-consumer-b96f546c-5ae5-47b6-be2c-3f634ef04011=[0_9, 0_5, 0_1], shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-3-consumer-7b933c8e-c0c4-405d-8cbc-87121e860937=[0_10, 0_6, 0_2], shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-4-consumer-b39da7d8-c1de-424d-aff3-09f6e9608118=[0_11, 0_7, 0_3]}
    	prev owned standby {shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-2-consumer-b96f546c-5ae5-47b6-be2c-3f634ef04011=[], shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-3-consumer-7b933c8e-c0c4-405d-8cbc-87121e860937=[], shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-4-consumer-b39da7d8-c1de-424d-aff3-09f6e9608118=[], shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-5-consumer-a7d388fb-6d80-49fd-90e2-567db4f0d501=[]}
    	assigned active {shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-2-consumer-b96f546c-5ae5-47b6-be2c-3f634ef04011=[0_9, 0_5, 0_1], shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-3-consumer-7b933c8e-c0c4-405d-8cbc-87121e860937=[0_10, 0_6, 0_2], shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-4-consumer-b39da7d8-c1de-424d-aff3-09f6e9608118=[0_11, 0_7, 0_3], shouldProcessStatefulEventsInOrderByKey-6c4b6342-422c-487a-83a3-92f6cdb58926-StreamThread-5-consumer-a7d388fb-6d80-49fd-90e2-567db4f0d501=[0_8, 0_4, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-0, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-4, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-0, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-4, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-2, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-6, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-10]
    	Current owned partitions:                  [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-2, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-6, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-10]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-1, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-5, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-9]
    	Current owned partitions:                  [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-1, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-5, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-9]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: [0_10, 0_6, 0_2]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: [0_9, 0_5, 0_1]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-3, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-7, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-11]
    	Current owned partitions:                  [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-3, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-7, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-11]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: [0_11, 0_7, 0_3]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-1
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
  [0K[39mdev.responsive.kafka.async.AsyncProcessorIntegrationTest[m

    [0K[32mâœ”[90m shouldProcessStatefulEventsInOrderByKey()[31m (49s)[m

AsyncProcessorIntegrationTest > shouldProcessStatelessEventsInOrderByKey() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-2
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InputRecordSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 5
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 61487
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 9223372036854775807
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldProcessStatelessEventsInOrderByKey
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 30000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 4
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatelessEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-2-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-2-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-2
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-2-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatelessEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-3-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-3-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-3
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-3-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatelessEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-4-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-4-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-4
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-4-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatelessEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    21c22f26-fe6d-452d-9d84-045a7000da28: [shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-1-consumer-3ffc0136-0997-421b-bf87-5bc857c8a50f, shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-2-consumer-0299134d-a40c-43d0-8c83-382c23a0ca9f, shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-3-consumer-23f9a1d4-5ca7-4563-8a5b-b7d0d83fd34a, shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-4-consumer-1068bccb-d7d3-4887-a802-fe83e0e9a72b]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-1-consumer-3ffc0136-0997-421b-bf87-5bc857c8a50f=[], shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-2-consumer-0299134d-a40c-43d0-8c83-382c23a0ca9f=[], shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-3-consumer-23f9a1d4-5ca7-4563-8a5b-b7d0d83fd34a=[], shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-4-consumer-1068bccb-d7d3-4887-a802-fe83e0e9a72b=[]}
    	assigned active {shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-1-consumer-3ffc0136-0997-421b-bf87-5bc857c8a50f=[0_8, 0_4, 0_0], shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-2-consumer-0299134d-a40c-43d0-8c83-382c23a0ca9f=[0_9, 0_5, 0_1], shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-3-consumer-23f9a1d4-5ca7-4563-8a5b-b7d0d83fd34a=[0_10, 0_6, 0_2], shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-4-consumer-1068bccb-d7d3-4887-a802-fe83e0e9a72b=[0_11, 0_7, 0_3]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-0, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-4, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-0, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-4, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-1, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-5, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-9]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-1, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-5, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-9]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-2, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-6, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-10]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-2, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-6, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-10]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-3, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-7, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-11]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-3, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-7, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-11]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput, partition=8, offset=4, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatelessAsyncProcessor(AsyncProcessorIntegrationTest.java:675)
    	at dev.responsive.kafka.testutils.SimpleStatelessProcessorSupplier$SimpleStatelessProcessor.process(SimpleStatelessProcessorSupplier.java:65)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatelessAsyncProcessor(AsyncProcessorIntegrationTest.java:675)
    	at dev.responsive.kafka.testutils.SimpleStatelessProcessorSupplier$SimpleStatelessProcessor.process(SimpleStatelessProcessorSupplier.java:65)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput, partition=8, offset=4, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatelessAsyncProcessor(AsyncProcessorIntegrationTest.java:675)
    	at dev.responsive.kafka.testutils.SimpleStatelessProcessorSupplier$SimpleStatelessProcessor.process(SimpleStatelessProcessorSupplier.java:65)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatelessAsyncProcessor(AsyncProcessorIntegrationTest.java:675)
    	at dev.responsive.kafka.testutils.SimpleStatelessProcessorSupplier$SimpleStatelessProcessor.process(SimpleStatelessProcessorSupplier.java:65)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-5-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-5-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-5
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-5-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatelessEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    21c22f26-fe6d-452d-9d84-045a7000da28: [shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-2-consumer-0299134d-a40c-43d0-8c83-382c23a0ca9f, shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-3-consumer-23f9a1d4-5ca7-4563-8a5b-b7d0d83fd34a, shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-4-consumer-1068bccb-d7d3-4887-a802-fe83e0e9a72b, shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-5-consumer-98576d0a-9afa-4782-ab8d-c75ab94f7b0d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-2-consumer-0299134d-a40c-43d0-8c83-382c23a0ca9f=[0_9, 0_5, 0_1], shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-3-consumer-23f9a1d4-5ca7-4563-8a5b-b7d0d83fd34a=[0_10, 0_6, 0_2], shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-4-consumer-1068bccb-d7d3-4887-a802-fe83e0e9a72b=[0_11, 0_7, 0_3]}
    	prev owned standby {shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-2-consumer-0299134d-a40c-43d0-8c83-382c23a0ca9f=[], shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-3-consumer-23f9a1d4-5ca7-4563-8a5b-b7d0d83fd34a=[], shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-4-consumer-1068bccb-d7d3-4887-a802-fe83e0e9a72b=[], shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-5-consumer-98576d0a-9afa-4782-ab8d-c75ab94f7b0d=[]}
    	assigned active {shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-2-consumer-0299134d-a40c-43d0-8c83-382c23a0ca9f=[0_9, 0_5, 0_1], shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-3-consumer-23f9a1d4-5ca7-4563-8a5b-b7d0d83fd34a=[0_10, 0_6, 0_2], shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-4-consumer-1068bccb-d7d3-4887-a802-fe83e0e9a72b=[0_11, 0_7, 0_3], shouldProcessStatelessEventsInOrderByKey-21c22f26-fe6d-452d-9d84-045a7000da28-StreamThread-5-consumer-98576d0a-9afa-4782-ab8d-c75ab94f7b0d=[0_8, 0_4, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-0, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-4, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-0, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-4, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-2, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-6, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-10]
    	Current owned partitions:                  [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-2, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-6, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-10]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-1, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-5, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-9]
    	Current owned partitions:                  [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-1, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-5, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-9]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: [0_9, 0_5, 0_1]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: [0_10, 0_6, 0_2]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-3, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-7, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-11]
    	Current owned partitions:                  [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-3, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-7, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-11]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: [0_11, 0_7, 0_3]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-2
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    [0K[32mâœ”[90m shouldProcessStatelessEventsInOrderByKey()[31m (43.7s)[m

AsyncProcessorIntegrationTest > shouldExecuteMultipleMixedAsyncProcessorsNoCaching() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-3
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InputRecordSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 5
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 61487
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 9223372036854775807
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 30000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 4
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-2-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-2-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-2
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-2-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-3-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-3-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-3
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-3-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-4-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-4-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-4
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-4-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    b7a43e8f-79d5-4f52-8e82-25671b8f8345: [shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-2-consumer-fb331e8c-b8cc-4288-9741-a6aef0ffa63a, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-3-consumer-2abf238d-8838-46c9-8396-06271665aefd]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-2-consumer-fb331e8c-b8cc-4288-9741-a6aef0ffa63a=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-3-consumer-2abf238d-8838-46c9-8396-06271665aefd=[]}
    	assigned active {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-2-consumer-fb331e8c-b8cc-4288-9741-a6aef0ffa63a=[0_10, 0_8, 0_6, 0_4, 0_2, 0_0], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-3-consumer-2abf238d-8838-46c9-8396-06271665aefd=[0_11, 0_9, 0_7, 0_5, 0_3, 0_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    b7a43e8f-79d5-4f52-8e82-25671b8f8345: [shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-1-consumer-7ddaf9be-f146-470a-9074-158463b4b2fe, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-2-consumer-fb331e8c-b8cc-4288-9741-a6aef0ffa63a, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-3-consumer-2abf238d-8838-46c9-8396-06271665aefd, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-4-consumer-8d5f4053-ca74-45a8-ad82-81d459460981]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-1-consumer-7ddaf9be-f146-470a-9074-158463b4b2fe=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-2-consumer-fb331e8c-b8cc-4288-9741-a6aef0ffa63a=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-3-consumer-2abf238d-8838-46c9-8396-06271665aefd=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-4-consumer-8d5f4053-ca74-45a8-ad82-81d459460981=[]}
    	assigned active {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-1-consumer-7ddaf9be-f146-470a-9074-158463b4b2fe=[0_8, 0_4, 0_0], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-2-consumer-fb331e8c-b8cc-4288-9741-a6aef0ffa63a=[0_9, 0_5, 0_1], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-3-consumer-2abf238d-8838-46c9-8396-06271665aefd=[0_10, 0_6, 0_2], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-4-consumer-8d5f4053-ca74-45a8-ad82-81d459460981=[0_11, 0_7, 0_3]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-2, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-6, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-10]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-2, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-6, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-10]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-1, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-5, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-9]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-1, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-5, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-9]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-3, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-7, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-11]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-3, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-7, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-11]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-0, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-4, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-0, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-4, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-3
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput, partition=8, offset=15, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput, partition=8, offset=15, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-5-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-5-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-5
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-5-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.ProcessorStateException: stream-thread [shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-1] stream-task [0_8] Failed to flush cache of store shouldExecuteMultipleMixedAsyncProcessorsNoCachinga1
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:546)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    b7a43e8f-79d5-4f52-8e82-25671b8f8345: [shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-2-consumer-fb331e8c-b8cc-4288-9741-a6aef0ffa63a, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-3-consumer-2abf238d-8838-46c9-8396-06271665aefd, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-4-consumer-8d5f4053-ca74-45a8-ad82-81d459460981, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-5-consumer-0aba6be8-9e92-4770-a083-5f9c18558e4c]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-2-consumer-fb331e8c-b8cc-4288-9741-a6aef0ffa63a=[0_9, 0_5, 0_1], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-3-consumer-2abf238d-8838-46c9-8396-06271665aefd=[0_10, 0_6, 0_2], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-4-consumer-8d5f4053-ca74-45a8-ad82-81d459460981=[0_11, 0_7, 0_3]}
    	prev owned standby {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-2-consumer-fb331e8c-b8cc-4288-9741-a6aef0ffa63a=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-3-consumer-2abf238d-8838-46c9-8396-06271665aefd=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-4-consumer-8d5f4053-ca74-45a8-ad82-81d459460981=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-5-consumer-0aba6be8-9e92-4770-a083-5f9c18558e4c=[]}
    	assigned active {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-2-consumer-fb331e8c-b8cc-4288-9741-a6aef0ffa63a=[0_9, 0_5, 0_1], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-3-consumer-2abf238d-8838-46c9-8396-06271665aefd=[0_10, 0_6, 0_2], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-4-consumer-8d5f4053-ca74-45a8-ad82-81d459460981=[0_11, 0_7, 0_3], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-b7a43e8f-79d5-4f52-8e82-25671b8f8345-StreamThread-5-consumer-0aba6be8-9e92-4770-a083-5f9c18558e4c=[0_8, 0_4, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-2, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-6, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-10]
    	Current owned partitions:                  [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-2, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-6, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-10]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-3, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-7, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-11]
    	Current owned partitions:                  [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-3, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-7, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-11]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-0, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-4, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-0, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-4, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-1, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-5, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-9]
    	Current owned partitions:                  [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-1, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-5, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-9]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: [0_10, 0_6, 0_2]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: [0_9, 0_5, 0_1]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: [0_11, 0_7, 0_3]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    [0K[32mâœ”[90m shouldExecuteMultipleMixedAsyncProcessorsNoCaching()[31m (40.9s)[m

AsyncProcessorIntegrationTest > shouldThrowIfStoresNotConnectedCorrectly() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 5
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 61487
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 9223372036854775807
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldThrowIfStoresNotConnectedCorrectly
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 30000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 4
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldThrowIfStoresNotConnectedCorrectly
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-2-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-2-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-2
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-2-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldThrowIfStoresNotConnectedCorrectly
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-3-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-3-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-3
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-3-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldThrowIfStoresNotConnectedCorrectly
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-4-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-4-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-4
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61514]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-4-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldThrowIfStoresNotConnectedCorrectly
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    e3f149fe-b673-4137-81cd-2eea8c8d4bc3: [shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-3-consumer-a998ec2e-cf3b-4caf-a6a0-c323250ee435]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-3-consumer-a998ec2e-cf3b-4caf-a6a0-c323250ee435=[]}
    	assigned active {shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-3-consumer-a998ec2e-cf3b-4caf-a6a0-c323250ee435=[0_11, 0_10, 0_9, 0_8, 0_7, 0_6, 0_5, 0_4, 0_3, 0_2, 0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    e3f149fe-b673-4137-81cd-2eea8c8d4bc3: [shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-1-consumer-4feb7eb0-eb72-4465-9eac-73829fd8241e, shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-2-consumer-61eb96e3-c552-4158-903a-f2e9141144b9, shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-3-consumer-a998ec2e-cf3b-4caf-a6a0-c323250ee435, shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-4-consumer-ee5c2c44-6004-452c-a81a-5b0d4b9ffa44]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-1-consumer-4feb7eb0-eb72-4465-9eac-73829fd8241e=[], shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-2-consumer-61eb96e3-c552-4158-903a-f2e9141144b9=[], shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-3-consumer-a998ec2e-cf3b-4caf-a6a0-c323250ee435=[], shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-4-consumer-ee5c2c44-6004-452c-a81a-5b0d4b9ffa44=[]}
    	assigned active {shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-1-consumer-4feb7eb0-eb72-4465-9eac-73829fd8241e=[0_8, 0_4, 0_0], shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-2-consumer-61eb96e3-c552-4158-903a-f2e9141144b9=[0_9, 0_5, 0_1], shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-3-consumer-a998ec2e-cf3b-4caf-a6a0-c323250ee435=[0_10, 0_6, 0_2], shouldThrowIfStoresNotConnectedCorrectly-e3f149fe-b673-4137-81cd-2eea8c8d4bc3-StreamThread-4-consumer-ee5c2c44-6004-452c-a81a-5b0d4b9ffa44=[0_11, 0_7, 0_3]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-2, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-6, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-10]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-2, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-6, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-10]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-3, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-7, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-11]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-3, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-7, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-11]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-1, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-5, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-9]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-1, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-5, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-9]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-0, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-4, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-0, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-4, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.streams.errors.StreamsException: failed to initialize processor AsyncProcessor
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.init(ProcessorNode.java:110)
    	at org.apache.kafka.streams.processor.internals.StreamTask.initializeTopology(StreamTask.java:1023)
    	at org.apache.kafka.streams.processor.internals.StreamTask.completeRestoration(StreamTask.java:287)
    	at org.apache.kafka.streams.processor.internals.TaskManager.tryToCompleteRestoration(TaskManager.java:752)
    	at org.apache.kafka.streams.processor.internals.StreamThread.initializeAndRestorePhase(StreamThread.java:1117)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:921)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: java.lang.IllegalStateException: Processor initialized some stores that were not connected via the ProcessorSupplier, please connect stores for async processors by implementing the ProcessorSupplier#storesNames method
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.verifyConnectedStateStores(AsyncProcessor.java:756)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.completeInitialization(AsyncProcessor.java:251)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.init(AsyncProcessor.java:177)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.init(ProcessorNode.java:107)
    	... 7 more
    org.apache.kafka.streams.errors.StreamsException: failed to initialize processor AsyncProcessor
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.init(ProcessorNode.java:110)
    	at org.apache.kafka.streams.processor.internals.StreamTask.initializeTopology(StreamTask.java:1023)
    	at org.apache.kafka.streams.processor.internals.StreamTask.completeRestoration(StreamTask.java:287)
    	at org.apache.kafka.streams.processor.internals.TaskManager.tryToCompleteRestoration(TaskManager.java:752)
    	at org.apache.kafka.streams.processor.internals.StreamThread.initializeAndRestorePhase(StreamThread.java:1117)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:921)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: java.lang.IllegalStateException: Processor initialized some stores that were not connected via the ProcessorSupplier, please connect stores for async processors by implementing the ProcessorSupplier#storesNames method
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.verifyConnectedStateStores(AsyncProcessor.java:756)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.completeInitialization(AsyncProcessor.java:251)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.init(AsyncProcessor.java:177)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.init(ProcessorNode.java:107)
    	... 7 more
    org.apache.kafka.streams.errors.StreamsException: failed to initialize processor AsyncProcessor
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.init(ProcessorNode.java:110)
    	at org.apache.kafka.streams.processor.internals.StreamTask.initializeTopology(StreamTask.java:1023)
    	at org.apache.kafka.streams.processor.internals.StreamTask.completeRestoration(StreamTask.java:287)
    	at org.apache.kafka.streams.processor.internals.TaskManager.tryToCompleteRestoration(TaskManager.java:752)
    	at org.apache.kafka.streams.processor.internals.StreamThread.initializeAndRestorePhase(StreamThread.java:1117)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:921)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: java.lang.IllegalStateException: Processor initialized some stores that were not connected via the ProcessorSupplier, please connect stores for async processors by implementing the ProcessorSupplier#storesNames method
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.verifyConnectedStateStores(AsyncProcessor.java:756)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.completeInitialization(AsyncProcessor.java:251)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.init(AsyncProcessor.java:177)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.init(ProcessorNode.java:107)
    	... 7 more
    [0K[32mâœ”[90m shouldThrowIfStoresNotConnectedCorrectly()[31m (7s)[m

AsyncProcessorIntegrationTest STANDARD_ERROR
    Test 1(dev.responsive.kafka.async.AsyncProcessorIntegrationTest): CASSANDRA teardown begins at 1731054767759ms (speed check)

AsyncProcessorIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

AsyncProcessorIntegrationTest STANDARD_ERROR
    Test 1(dev.responsive.kafka.async.AsyncProcessorIntegrationTest): CASSANDRA teardown ends at 1731054771305ms (duration: PT3.546S) (speed check)
    Test 1(dev.responsive.kafka.async.AsyncProcessorIntegrationTest): CASSANDRA test total runtime=PT2M51.537S) (speed check)

Gradle Test Executor 2 STANDARD_ERROR
    Test 2: creating ResponsiveExtension(backend=CASSANDRA) at 1731054771308ms (speed check)

  [0K[39mdev.responsive.kafka.bootstrap.ChangelogMigrationToolIntegrationTest[m

    [0K[36m- testFactStore()[m

ChangelogMigrationToolIntegrationTest > testFactStore() SKIPPED
    [0K[36m- test()[m

ChangelogMigrationToolIntegrationTest > test() SKIPPED

Gradle Test Executor 2 STANDARD_ERROR
    Test 2: creating ResponsiveExtension(empty) at 1731054771313ms (speed check)

GlobalStoreIntegrationTest STANDARD_ERROR
    Test 2(dev.responsive.kafka.integration.GlobalStoreIntegrationTest): CASSANDRA setup begins at 1731054771314ms (speed check)

GlobalStoreIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61815]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

GlobalStoreIntegrationTest STANDARD_ERROR
    Test 2(dev.responsive.kafka.integration.GlobalStoreIntegrationTest): CASSANDRA setup ends at 1731054787575ms (duration: PT16.261S) (speed check)

GlobalStoreIntegrationTest > shouldUseGlobalTable() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61815]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-4
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 61777
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61815]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldUseGlobalTable
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:61815]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 0
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61815]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-c243f5ae-c6e2-498f-bebf-7a08430df565-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61815]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-c243f5ae-c6e2-498f-bebf-7a08430df565-global-consumer
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61815]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-c243f5ae-c6e2-498f-bebf-7a08430df565-global-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldUseGlobalTable-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61815]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-c243f5ae-c6e2-498f-bebf-7a08430df565-global-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldUseGlobalTable-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61815]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-c243f5ae-c6e2-498f-bebf-7a08430df565-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61815]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61815]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-c243f5ae-c6e2-498f-bebf-7a08430df565-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61815]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-c243f5ae-c6e2-498f-bebf-7a08430df565-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldUseGlobalTable
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    c243f5ae-c6e2-498f-bebf-7a08430df565: [shouldUseGlobalTable-c243f5ae-c6e2-498f-bebf-7a08430df565-StreamThread-1-consumer-dac698b0-58db-4069-bbd0-522ccf7a9783]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [1_0, 1_1] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldUseGlobalTable-c243f5ae-c6e2-498f-bebf-7a08430df565-StreamThread-1-consumer-dac698b0-58db-4069-bbd0-522ccf7a9783=[]}
    	assigned active {shouldUseGlobalTable-c243f5ae-c6e2-498f-bebf-7a08430df565-StreamThread-1-consumer-dac698b0-58db-4069-bbd0-522ccf7a9783=[1_0, 1_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [input-0, input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [input-0, input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 1_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:61815]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-4
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.GlobalStoreIntegrationTest[m

    [0K[32mâœ”[90m shouldUseGlobalTable()[31m (7.6s)[m

GlobalStoreIntegrationTest STANDARD_ERROR
    Test 2(dev.responsive.kafka.integration.GlobalStoreIntegrationTest): CASSANDRA teardown begins at 1731054795236ms (speed check)

GlobalStoreIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

GlobalStoreIntegrationTest STANDARD_ERROR
    Test 2(dev.responsive.kafka.integration.GlobalStoreIntegrationTest): CASSANDRA teardown ends at 1731054797666ms (duration: PT2.43S) (speed check)
    Test 2(dev.responsive.kafka.integration.GlobalStoreIntegrationTest): CASSANDRA test total runtime=PT26.353S) (speed check)

Gradle Test Executor 2 STANDARD_ERROR
    Test 3: creating ResponsiveExtension(backend=MONGO_DB) at 1731054797669ms (speed check)

  [0K[39mdev.responsive.kafka.integration.MinimalIntegrationTest[m

    [0K[36m- test()[m

MinimalIntegrationTest > test() SKIPPED

Gradle Test Executor 2 STANDARD_ERROR
    Test 3: creating ResponsiveExtension(backend=MONGO_DB) at 1731054797673ms (speed check)

ResponsiveForeignKeyJoinIntegrationTest STANDARD_ERROR
    Test 3(dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest): MONGO_DB setup begins at 1731054797674ms (speed check)

ResponsiveForeignKeyJoinIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

ResponsiveForeignKeyJoinIntegrationTest STANDARD_ERROR
    Test 3(dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest): MONGO_DB setup ends at 1731054808112ms (duration: PT10.438S) (speed check)

ResponsiveForeignKeyJoinIntegrationTest > shouldComputeForeignKeyJoinsCorrectly() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-5
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$JsonSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-6
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$JsonSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:61899
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = CFKJC--176764460
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 2000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = CFKJC--176764460
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    f61e7bac-980c-4ca1-94e6-8edda2a0b145: [CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-StreamThread-1-consumer-636dfb5f-7351-4149-bbf4-dabc35a3fc94]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-StreamThread-1-consumer-636dfb5f-7351-4149-bbf4-dabc35a3fc94=[]}
    	assigned active {CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-StreamThread-1-consumer-636dfb5f-7351-4149-bbf4-dabc35a3fc94=[1_0, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [CFKJC--176764460-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC--176764460-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC--176764460.inventory-0, CFKJC--176764460.merchant-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [CFKJC--176764460-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC--176764460-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC--176764460.inventory-0, CFKJC--176764460.merchant-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    f61e7bac-980c-4ca1-94e6-8edda2a0b145: [CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-StreamThread-1-consumer-636dfb5f-7351-4149-bbf4-dabc35a3fc94]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-StreamThread-1-consumer-636dfb5f-7351-4149-bbf4-dabc35a3fc94=[1_0, 0_0]}
    	prev owned standby {CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-StreamThread-1-consumer-636dfb5f-7351-4149-bbf4-dabc35a3fc94=[]}
    	assigned active {CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-StreamThread-1-consumer-636dfb5f-7351-4149-bbf4-dabc35a3fc94=[1_0, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [CFKJC--176764460-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC--176764460-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC--176764460.inventory-0, CFKJC--176764460.merchant-0]
    	Current owned partitions:                  [CFKJC--176764460-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC--176764460-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC--176764460.inventory-0, CFKJC--176764460.merchant-0]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 0_0]
    	New standby tasks: []
    	Existing active tasks: [1_0, 0_0]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-5
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$EnrichedDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-7
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$JsonSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-8
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$JsonSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:61899
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = CFKJC--176764460
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 2000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = CFKJC--176764460
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    f61e7bac-980c-4ca1-94e6-8edda2a0b145: [CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-StreamThread-1-consumer-775aec02-28a3-470c-b5a1-9a8ba68a28cd]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-StreamThread-1-consumer-775aec02-28a3-470c-b5a1-9a8ba68a28cd=[1_0]}
    	assigned active {CFKJC--176764460-f61e7bac-980c-4ca1-94e6-8edda2a0b145-StreamThread-1-consumer-775aec02-28a3-470c-b5a1-9a8ba68a28cd=[1_0, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [CFKJC--176764460-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC--176764460-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC--176764460.inventory-0, CFKJC--176764460.merchant-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [CFKJC--176764460-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC--176764460-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC--176764460.inventory-0, CFKJC--176764460.merchant-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:61913]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-6
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$EnrichedDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest[m

    [0K[32mâœ”[90m shouldComputeForeignKeyJoinsCorrectly()[31m (24.2s)[m

ResponsiveForeignKeyJoinIntegrationTest STANDARD_ERROR
    Test 3(dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest): MONGO_DB teardown begins at 1731054832381ms (speed check)

ResponsiveForeignKeyJoinIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

ResponsiveForeignKeyJoinIntegrationTest STANDARD_ERROR
    Test 3(dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest): MONGO_DB teardown ends at 1731054833878ms (duration: PT1.497S) (speed check)
    Test 3(dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest): MONGO_DB test total runtime=PT36.205S) (speed check)

Gradle Test Executor 2 STANDARD_ERROR
    Test 4: creating ResponsiveExtension(backend=MONGO_DB) at 1731054833883ms (speed check)

ResponsiveKafkaStreamsIntegrationTest STANDARD_ERROR
    Test 4(dev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest): MONGO_DB setup begins at 1731054833884ms (speed check)

ResponsiveKafkaStreamsIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62120]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

ResponsiveKafkaStreamsIntegrationTest STANDARD_ERROR
    Test 4(dev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest): MONGO_DB setup ends at 1731054844449ms (duration: PT10.565S) (speed check)

ResponsiveKafkaStreamsIntegrationTest > shouldDefaultToResponsiveStoresWhenUsingDsl() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62120]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-9
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:62106
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62120]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldDefaultToResponsiveStoresWhenUsingDsl-1726268561
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62120]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62120]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDefaultToResponsiveStoresWhenUsingDsl-1726268561-c9fb5015-e10f-4cb7-b035-cdb7c75586a9-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62120]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDefaultToResponsiveStoresWhenUsingDsl-1726268561-c9fb5015-e10f-4cb7-b035-cdb7c75586a9-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62120]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62120]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDefaultToResponsiveStoresWhenUsingDsl-1726268561-c9fb5015-e10f-4cb7-b035-cdb7c75586a9-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62120]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDefaultToResponsiveStoresWhenUsingDsl-1726268561-c9fb5015-e10f-4cb7-b035-cdb7c75586a9-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldDefaultToResponsiveStoresWhenUsingDsl-1726268561
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    c9fb5015-e10f-4cb7-b035-cdb7c75586a9: [shouldDefaultToResponsiveStoresWhenUsingDsl-1726268561-c9fb5015-e10f-4cb7-b035-cdb7c75586a9-StreamThread-1-consumer-7f6b9d22-5899-484c-83f6-854f2e33926b]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldDefaultToResponsiveStoresWhenUsingDsl-1726268561-c9fb5015-e10f-4cb7-b035-cdb7c75586a9-StreamThread-1-consumer-7f6b9d22-5899-484c-83f6-854f2e33926b=[]}
    	assigned active {shouldDefaultToResponsiveStoresWhenUsingDsl-1726268561-c9fb5015-e10f-4cb7-b035-cdb7c75586a9-StreamThread-1-consumer-7f6b9d22-5899-484c-83f6-854f2e33926b=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldDefaultToResponsiveStoresWhenUsingDsl-1726268561.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldDefaultToResponsiveStoresWhenUsingDsl-1726268561.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    Pinged your deployment. You successfully connected to MongoDB!

  [0K[39mdev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest[m

    [0K[32mâœ”[90m shouldDefaultToResponsiveStoresWhenUsingDsl()[33m (1.6s)[m

ResponsiveKafkaStreamsIntegrationTest STANDARD_ERROR
    Test 4(dev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest): MONGO_DB teardown begins at 1731054846107ms (speed check)

ResponsiveKafkaStreamsIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

ResponsiveKafkaStreamsIntegrationTest STANDARD_ERROR
    Test 4(dev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest): MONGO_DB teardown ends at 1731054847217ms (duration: PT1.11S) (speed check)
    Test 4(dev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest): MONGO_DB test total runtime=PT13.334S) (speed check)

Gradle Test Executor 2 STANDARD_ERROR
    Test 5: creating ResponsiveExtension(empty) at 1731054847219ms (speed check)

ResponsiveKeyValueStoreEosIntegrationTest STANDARD_ERROR
    Test 5(dev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest): CASSANDRA setup begins at 1731054847224ms (speed check)

ResponsiveKeyValueStoreEosIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

ResponsiveKeyValueStoreEosIntegrationTest STANDARD_ERROR
    Test 5(dev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest): CASSANDRA setup ends at 1731054864552ms (duration: PT17.328S) (speed check)

ResponsiveKeyValueStoreEosIntegrationTest > shouldMaintainStateOnEosFailOverAndFenceOldClient(KVSchema) > [1] KEY_VALUE STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-10
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 62190
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue
    	application.server = a:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 20000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-dba7c48b-8014-4ccb-b8ff-3380bdfa7783-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-dba7c48b-8014-4ccb-b8ff-3380bdfa7783-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-dba7c48b-8014-4ccb-b8ff-3380bdfa7783-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-dba7c48b-8014-4ccb-b8ff-3380bdfa7783-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-dba7c48b-8014-4ccb-b8ff-3380bdfa7783-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 62190
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue
    	application.server = b:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 20000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-6b6c43e7-8609-4dd4-903c-aef3ae62c411-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-6b6c43e7-8609-4dd4-903c-aef3ae62c411-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-6b6c43e7-8609-4dd4-903c-aef3ae62c411-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-6b6c43e7-8609-4dd4-903c-aef3ae62c411-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-6b6c43e7-8609-4dd4-903c-aef3ae62c411-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    dba7c48b-8014-4ccb-b8ff-3380bdfa7783: [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-dba7c48b-8014-4ccb-b8ff-3380bdfa7783-StreamThread-1-consumer-ef133e6a-33d2-4a42-99fc-2b287a2ee1a3]
    6b6c43e7-8609-4dd4-903c-aef3ae62c411: [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-6b6c43e7-8609-4dd4-903c-aef3ae62c411-StreamThread-1-consumer-b4f9f3c9-1ca2-4bbb-8b6e-cb1f71de0fdf]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    6b6c43e7-8609-4dd4-903c-aef3ae62c411=[activeTasks: ([0_1]) standbyTasks: ([])] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:671)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-dba7c48b-8014-4ccb-b8ff-3380bdfa7783-StreamThread-1-consumer-ef133e6a-33d2-4a42-99fc-2b287a2ee1a3=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-dba7c48b-8014-4ccb-b8ff-3380bdfa7783-StreamThread-1-consumer-ef133e6a-33d2-4a42-99fc-2b287a2ee1a3=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-6b6c43e7-8609-4dd4-903c-aef3ae62c411-StreamThread-1-consumer-b4f9f3c9-1ca2-4bbb-8b6e-cb1f71de0fdf=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-6b6c43e7-8609-4dd4-903c-aef3ae62c411-StreamThread-1-consumer-b4f9f3c9-1ca2-4bbb-8b6e-cb1f71de0fdf=[0_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-7
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    6b6c43e7-8609-4dd4-903c-aef3ae62c411: [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-6b6c43e7-8609-4dd4-903c-aef3ae62c411-StreamThread-1-consumer-b4f9f3c9-1ca2-4bbb-8b6e-cb1f71de0fdf]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-6b6c43e7-8609-4dd4-903c-aef3ae62c411-StreamThread-1-consumer-b4f9f3c9-1ca2-4bbb-8b6e-cb1f71de0fdf=[0_1]}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-6b6c43e7-8609-4dd4-903c-aef3ae62c411-StreamThread-1-consumer-b4f9f3c9-1ca2-4bbb-8b6e-cb1f71de0fdf=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-6b6c43e7-8609-4dd4-903c-aef3ae62c411-StreamThread-1-consumer-b4f9f3c9-1ca2-4bbb-8b6e-cb1f71de0fdf=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0, shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Current owned partitions:                  [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: [0_1]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-8
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-9
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:322)
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:303)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:273)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeExceptionally(ProducerBatch.java:237)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:830)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:819)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:771)
    	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:702)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$null$1(Sender.java:627)
    	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:612)
    	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
    	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:612)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$8(Sender.java:917)
    	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:154)
    	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:608)
    	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:600)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:349)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-dba7c48b-8014-4ccb-b8ff-3380bdfa7783-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-dba7c48b-8014-4ccb-b8ff-3380bdfa7783-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	lost active tasks: []
    	lost assigned standby tasks: []
     (org.apache.kafka.streams.processor.internals.StreamThread:104)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-dba7c48b-8014-4ccb-b8ff-3380bdfa7783-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-dba7c48b-8014-4ccb-b8ff-3380bdfa7783-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    dba7c48b-8014-4ccb-b8ff-3380bdfa7783: [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-dba7c48b-8014-4ccb-b8ff-3380bdfa7783-StreamThread-1-consumer-26348685-6ae8-48ab-9051-9848cbda843d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-dba7c48b-8014-4ccb-b8ff-3380bdfa7783-StreamThread-1-consumer-26348685-6ae8-48ab-9051-9848cbda843d=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-dba7c48b-8014-4ccb-b8ff-3380bdfa7783-StreamThread-1-consumer-26348685-6ae8-48ab-9051-9848cbda843d=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0, shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0, shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)

  [0K[39mdev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest[m

    [0K[39mshouldMaintainStateOnEosFailOverAndFenceOldClient(KVSchema)[m

      [0K[32mâœ”[90m [1] KEY_VALUE[31m (32.2s)[m

ResponsiveKeyValueStoreEosIntegrationTest > shouldMaintainStateOnEosFailOverAndFenceOldClient(KVSchema) > [2] FACT STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-11
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 62190
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldmaintainstateoneosfailoverandfenceoldclientfact
    	application.server = a:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 20000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-39238640-02a5-4f92-bb31-1aa50d412b27-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-39238640-02a5-4f92-bb31-1aa50d412b27-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-39238640-02a5-4f92-bb31-1aa50d412b27-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-39238640-02a5-4f92-bb31-1aa50d412b27-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-39238640-02a5-4f92-bb31-1aa50d412b27-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldmaintainstateoneosfailoverandfenceoldclientfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 62190
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldmaintainstateoneosfailoverandfenceoldclientfact
    	application.server = b:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 20000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-cf560f29-fecb-4b9d-bd54-d3b3cb58f88f-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-cf560f29-fecb-4b9d-bd54-d3b3cb58f88f-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-cf560f29-fecb-4b9d-bd54-d3b3cb58f88f-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-cf560f29-fecb-4b9d-bd54-d3b3cb58f88f-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-cf560f29-fecb-4b9d-bd54-d3b3cb58f88f-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldmaintainstateoneosfailoverandfenceoldclientfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    cf560f29-fecb-4b9d-bd54-d3b3cb58f88f: [shouldmaintainstateoneosfailoverandfenceoldclientfact-cf560f29-fecb-4b9d-bd54-d3b3cb58f88f-StreamThread-1-consumer-0ea6ebae-4bc5-4cab-a25c-e32e4b985dbc]
    39238640-02a5-4f92-bb31-1aa50d412b27: [shouldmaintainstateoneosfailoverandfenceoldclientfact-39238640-02a5-4f92-bb31-1aa50d412b27-StreamThread-1-consumer-a0d5dd44-f9f7-4e8c-8bd0-ddf9c37f05e5]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    39238640-02a5-4f92-bb31-1aa50d412b27=[activeTasks: ([0_0]) standbyTasks: ([])] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:671)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientfact-39238640-02a5-4f92-bb31-1aa50d412b27-StreamThread-1-consumer-a0d5dd44-f9f7-4e8c-8bd0-ddf9c37f05e5=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientfact-39238640-02a5-4f92-bb31-1aa50d412b27-StreamThread-1-consumer-a0d5dd44-f9f7-4e8c-8bd0-ddf9c37f05e5=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientfact-cf560f29-fecb-4b9d-bd54-d3b3cb58f88f-StreamThread-1-consumer-0ea6ebae-4bc5-4cab-a25c-e32e4b985dbc=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientfact-cf560f29-fecb-4b9d-bd54-d3b3cb58f88f-StreamThread-1-consumer-0ea6ebae-4bc5-4cab-a25c-e32e4b985dbc=[0_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-10
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    cf560f29-fecb-4b9d-bd54-d3b3cb58f88f: [shouldmaintainstateoneosfailoverandfenceoldclientfact-cf560f29-fecb-4b9d-bd54-d3b3cb58f88f-StreamThread-1-consumer-0ea6ebae-4bc5-4cab-a25c-e32e4b985dbc]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldmaintainstateoneosfailoverandfenceoldclientfact-cf560f29-fecb-4b9d-bd54-d3b3cb58f88f-StreamThread-1-consumer-0ea6ebae-4bc5-4cab-a25c-e32e4b985dbc=[0_1]}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientfact-cf560f29-fecb-4b9d-bd54-d3b3cb58f88f-StreamThread-1-consumer-0ea6ebae-4bc5-4cab-a25c-e32e4b985dbc=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientfact-cf560f29-fecb-4b9d-bd54-d3b3cb58f88f-StreamThread-1-consumer-0ea6ebae-4bc5-4cab-a25c-e32e4b985dbc=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-0, shouldmaintainstateoneosfailoverandfenceoldclientfact.input-1]
    	Current owned partitions:                  [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-1]
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: [0_1]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-11
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-12
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:322)
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic shouldmaintainstateoneosfailoverandfenceoldclientfact-shouldmaintainstateoneosfailoverandfenceoldclientfact-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:303)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:273)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeExceptionally(ProducerBatch.java:237)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:830)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:819)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:771)
    	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:702)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$null$1(Sender.java:627)
    	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:612)
    	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
    	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:612)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$8(Sender.java:917)
    	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:154)
    	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:608)
    	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:600)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:349)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-39238640-02a5-4f92-bb31-1aa50d412b27-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-39238640-02a5-4f92-bb31-1aa50d412b27-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	lost active tasks: []
    	lost assigned standby tasks: []
     (org.apache.kafka.streams.processor.internals.StreamThread:104)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62243]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-39238640-02a5-4f92-bb31-1aa50d412b27-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-39238640-02a5-4f92-bb31-1aa50d412b27-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    39238640-02a5-4f92-bb31-1aa50d412b27: [shouldmaintainstateoneosfailoverandfenceoldclientfact-39238640-02a5-4f92-bb31-1aa50d412b27-StreamThread-1-consumer-d71f5bb5-4064-423f-a185-0997a5ca5507]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientfact-39238640-02a5-4f92-bb31-1aa50d412b27-StreamThread-1-consumer-d71f5bb5-4064-423f-a185-0997a5ca5507=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientfact-39238640-02a5-4f92-bb31-1aa50d412b27-StreamThread-1-consumer-d71f5bb5-4064-423f-a185-0997a5ca5507=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-0, shouldmaintainstateoneosfailoverandfenceoldclientfact.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-0, shouldmaintainstateoneosfailoverandfenceoldclientfact.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
      [0K[32mâœ”[90m [2] FACT[31m (32s)[m

ResponsiveKeyValueStoreEosIntegrationTest STANDARD_ERROR
    Test 5(dev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest): CASSANDRA teardown begins at 1731054928965ms (speed check)

ResponsiveKeyValueStoreEosIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

ResponsiveKeyValueStoreEosIntegrationTest STANDARD_ERROR
    Test 5(dev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest): CASSANDRA teardown ends at 1731054931960ms (duration: PT2.995S) (speed check)
    Test 5(dev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest): CASSANDRA test total runtime=PT1M24.741S) (speed check)

Gradle Test Executor 2 STANDARD_ERROR
    Test 6: creating ResponsiveExtension(backend=MONGO_DB) at 1731054931963ms (speed check)

ResponsiveKeyValueStoreIntegrationTest STANDARD_ERROR
    Test 6(dev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest): MONGO_DB setup begins at 1731054931964ms (speed check)

ResponsiveKeyValueStoreIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62781]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

ResponsiveKeyValueStoreIntegrationTest STANDARD_ERROR
    Test 6(dev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest): MONGO_DB setup ends at 1731054942326ms (duration: PT10.362S) (speed check)

ResponsiveKeyValueStoreIntegrationTest > shouldMatchRocksDB() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62781]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-12
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:62751
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62781]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldMatchRocksDB--924505871
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62781]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62781]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldMatchRocksDB--924505871-071b0eaa-de76-43fd-9dc8-8d1491292b76-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62781]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldMatchRocksDB--924505871-071b0eaa-de76-43fd-9dc8-8d1491292b76-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62781]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62781]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldMatchRocksDB--924505871-071b0eaa-de76-43fd-9dc8-8d1491292b76-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62781]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldMatchRocksDB--924505871-071b0eaa-de76-43fd-9dc8-8d1491292b76-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldMatchRocksDB--924505871
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    071b0eaa-de76-43fd-9dc8-8d1491292b76: [shouldMatchRocksDB--924505871-071b0eaa-de76-43fd-9dc8-8d1491292b76-StreamThread-1-consumer-b8456243-2a3b-482b-a530-d8a19d821b0c]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldMatchRocksDB--924505871-071b0eaa-de76-43fd-9dc8-8d1491292b76-StreamThread-1-consumer-b8456243-2a3b-482b-a530-d8a19d821b0c=[]}
    	assigned active {shouldMatchRocksDB--924505871-071b0eaa-de76-43fd-9dc8-8d1491292b76-StreamThread-1-consumer-b8456243-2a3b-482b-a530-d8a19d821b0c=[1_0, 0_1, 0_0, 1_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldMatchRocksDB--924505871-shouldMatchRocksDB--924505871-repartition-0, shouldMatchRocksDB--924505871-shouldMatchRocksDB--924505871-repartition-1, shouldMatchRocksDB--924505871.input-0, shouldMatchRocksDB--924505871.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldMatchRocksDB--924505871-shouldMatchRocksDB--924505871-repartition-0, shouldMatchRocksDB--924505871-shouldMatchRocksDB--924505871-repartition-1, shouldMatchRocksDB--924505871.input-0, shouldMatchRocksDB--924505871.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 0_1, 0_0, 1_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    071b0eaa-de76-43fd-9dc8-8d1491292b76: [shouldMatchRocksDB--924505871-071b0eaa-de76-43fd-9dc8-8d1491292b76-StreamThread-1-consumer-b8456243-2a3b-482b-a530-d8a19d821b0c]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldMatchRocksDB--924505871-071b0eaa-de76-43fd-9dc8-8d1491292b76-StreamThread-1-consumer-b8456243-2a3b-482b-a530-d8a19d821b0c=[1_0, 0_1, 1_1, 0_0]}
    	prev owned standby {shouldMatchRocksDB--924505871-071b0eaa-de76-43fd-9dc8-8d1491292b76-StreamThread-1-consumer-b8456243-2a3b-482b-a530-d8a19d821b0c=[]}
    	assigned active {shouldMatchRocksDB--924505871-071b0eaa-de76-43fd-9dc8-8d1491292b76-StreamThread-1-consumer-b8456243-2a3b-482b-a530-d8a19d821b0c=[1_0, 0_1, 0_0, 1_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldMatchRocksDB--924505871-shouldMatchRocksDB--924505871-repartition-0, shouldMatchRocksDB--924505871-shouldMatchRocksDB--924505871-repartition-1, shouldMatchRocksDB--924505871.input-0, shouldMatchRocksDB--924505871.input-1]
    	Current owned partitions:                  [shouldMatchRocksDB--924505871-shouldMatchRocksDB--924505871-repartition-0, shouldMatchRocksDB--924505871-shouldMatchRocksDB--924505871-repartition-1, shouldMatchRocksDB--924505871.input-0, shouldMatchRocksDB--924505871.input-1]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 0_1, 0_0, 1_1]
    	New standby tasks: []
    	Existing active tasks: [1_0, 0_1, 0_0, 1_1]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)

  [0K[39mdev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest[m

    [0K[32mâœ”[90m shouldMatchRocksDB()[31m (2.6s)[m

ResponsiveKeyValueStoreIntegrationTest STANDARD_ERROR
    Test 6(dev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest): MONGO_DB teardown begins at 1731054944970ms (speed check)

ResponsiveKeyValueStoreIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

ResponsiveKeyValueStoreIntegrationTest STANDARD_ERROR
    Test 6(dev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest): MONGO_DB teardown ends at 1731054946097ms (duration: PT1.127S) (speed check)
    Test 6(dev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest): MONGO_DB test total runtime=PT14.134S) (speed check)

Gradle Test Executor 2 STANDARD_ERROR
    Test 7: creating ResponsiveExtension(backend=CASSANDRA) at 1731054946105ms (speed check)

ResponsiveKeyValueStoreRestoreIntegrationTest STANDARD_ERROR
    Test 7(dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest): CASSANDRA setup begins at 1731054946111ms (speed check)

ResponsiveKeyValueStoreRestoreIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

ResponsiveKeyValueStoreRestoreIntegrationTest STANDARD_ERROR
    Test 7(dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest): CASSANDRA setup ends at 1731054961176ms (duration: PT15.065S) (speed check)

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldRestoreUnflushedChangelog(KVSchema) > [1] KEY_VALUE STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-13
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 62891
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogkeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-e7b11b5f-0e31-4e2d-ac57-29e38c45e1fc-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-e7b11b5f-0e31-4e2d-ac57-29e38c45e1fc-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-e7b11b5f-0e31-4e2d-ac57-29e38c45e1fc-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogkeyvalue-e7b11b5f-0e31-4e2d-ac57-29e38c45e1fc-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-e7b11b5f-0e31-4e2d-ac57-29e38c45e1fc-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    e7b11b5f-0e31-4e2d-ac57-29e38c45e1fc: [shouldrestoreunflushedchangelogkeyvalue-e7b11b5f-0e31-4e2d-ac57-29e38c45e1fc-StreamThread-1-consumer-71299ff3-a746-4d42-a47b-a2a42fe6b7d0]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogkeyvalue-e7b11b5f-0e31-4e2d-ac57-29e38c45e1fc-StreamThread-1-consumer-71299ff3-a746-4d42-a47b-a2a42fe6b7d0=[]}
    	assigned active {shouldrestoreunflushedchangelogkeyvalue-e7b11b5f-0e31-4e2d-ac57-29e38c45e1fc-StreamThread-1-consumer-71299ff3-a746-4d42-a47b-a2a42fe6b7d0=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 62891
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogkeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-ea823270-ccbe-4d61-9410-477615225640-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-ea823270-ccbe-4d61-9410-477615225640-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-ea823270-ccbe-4d61-9410-477615225640-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogkeyvalue-ea823270-ccbe-4d61-9410-477615225640-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-ea823270-ccbe-4d61-9410-477615225640-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    ea823270-ccbe-4d61-9410-477615225640: [shouldrestoreunflushedchangelogkeyvalue-ea823270-ccbe-4d61-9410-477615225640-StreamThread-1-consumer-cffdb249-7e84-4d29-b189-66da206a9eb3]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogkeyvalue-ea823270-ccbe-4d61-9410-477615225640-StreamThread-1-consumer-cffdb249-7e84-4d29-b189-66da206a9eb3=[]}
    	assigned active {shouldrestoreunflushedchangelogkeyvalue-ea823270-ccbe-4d61-9410-477615225640-StreamThread-1-consumer-cffdb249-7e84-4d29-b189-66da206a9eb3=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.streams.errors.StreamsException: java.lang.RuntimeException: oops
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:729)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: java.lang.RuntimeException: oops
    	at dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest.shouldRestoreUnflushedChangelog(ResponsiveKeyValueStoreRestoreIntegrationTest.java:304)
    	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
    	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:727)
    	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
    	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
    	at org.junit.jupiter.engine.extension.SameThreadTimeoutInvocation.proceed(SameThreadTimeoutInvocation.java:45)
    	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156)
    	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:147)
    	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestTemplateMethod(TimeoutExtension.java:94)
    	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103)
    	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)
    	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
    	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
    	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
    	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
    	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)
    	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86)
    	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:217)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:213)
    	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:138)
    	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:68)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:204)
    	at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:142)
    	at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.lambda$execute$2(TestTemplateTestDescriptor.java:110)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
    	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
    	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
    	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
    	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
    	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
    	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
    	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:274)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
    	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
    	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
    	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
    	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
    	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
    	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:274)
    	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
    	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
    	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
    	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
    	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
    	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
    	at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:110)
    	at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:44)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
    	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
    	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
    	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
    	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
    	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
    	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
    	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
    	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
    	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
    	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
    	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
    	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
    	at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.processAllTestClasses(JUnitPlatformTestClassProcessor.java:110)
    	at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.access$000(JUnitPlatformTestClassProcessor.java:90)
    	at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor.stop(JUnitPlatformTestClassProcessor.java:85)
    	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:62)
    	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
    	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
    	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
    	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)
    	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)
    	at com.sun.proxy.$Proxy2.stop(Unknown Source)
    	at org.gradle.api.internal.tasks.testing.worker.TestWorker$3.run(TestWorker.java:193)
    	at org.gradle.api.internal.tasks.testing.worker.TestWorker.executeAndMaintainThreadName(TestWorker.java:129)
    	at org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:100)
    	at org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:60)
    	at org.gradle.process.internal.worker.child.ActionExecutionWorker.execute(ActionExecutionWorker.java:56)
    	at org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:113)
    	at org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:65)
    	at worker.org.gradle.process.internal.worker.GradleWorkerMain.run(GradleWorkerMain.java:69)
    	at worker.org.gradle.process.internal.worker.GradleWorkerMain.main(GradleWorkerMain.java:74)
    Using Scylla optimized driver!!!
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 62891
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogkeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-5da5ab9f-749d-48e7-9f35-7ef338e32549-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-5da5ab9f-749d-48e7-9f35-7ef338e32549-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-5da5ab9f-749d-48e7-9f35-7ef338e32549-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogkeyvalue-5da5ab9f-749d-48e7-9f35-7ef338e32549-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-5da5ab9f-749d-48e7-9f35-7ef338e32549-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    5da5ab9f-749d-48e7-9f35-7ef338e32549: [shouldrestoreunflushedchangelogkeyvalue-5da5ab9f-749d-48e7-9f35-7ef338e32549-StreamThread-1-consumer-48f79415-7460-4064-839a-a35eddca8b75]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogkeyvalue-5da5ab9f-749d-48e7-9f35-7ef338e32549-StreamThread-1-consumer-48f79415-7460-4064-839a-a35eddca8b75=[]}
    	assigned active {shouldrestoreunflushedchangelogkeyvalue-5da5ab9f-749d-48e7-9f35-7ef338e32549-StreamThread-1-consumer-48f79415-7460-4064-839a-a35eddca8b75=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-13
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest[m

    [0K[39mshouldRestoreUnflushedChangelog(KVSchema)[m

      [0K[32mâœ”[90m [1] KEY_VALUE[31m (20.6s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldRestoreUnflushedChangelog(KVSchema) > [2] FACT STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-14
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 62891
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogfact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-7cad3a21-1b40-4477-be94-66c63245f646-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-7cad3a21-1b40-4477-be94-66c63245f646-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-7cad3a21-1b40-4477-be94-66c63245f646-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogfact-7cad3a21-1b40-4477-be94-66c63245f646-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-7cad3a21-1b40-4477-be94-66c63245f646-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    7cad3a21-1b40-4477-be94-66c63245f646: [shouldrestoreunflushedchangelogfact-7cad3a21-1b40-4477-be94-66c63245f646-StreamThread-1-consumer-7e5057aa-e991-4220-b492-5f03775b88d6]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogfact-7cad3a21-1b40-4477-be94-66c63245f646-StreamThread-1-consumer-7e5057aa-e991-4220-b492-5f03775b88d6=[]}
    	assigned active {shouldrestoreunflushedchangelogfact-7cad3a21-1b40-4477-be94-66c63245f646-StreamThread-1-consumer-7e5057aa-e991-4220-b492-5f03775b88d6=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	lost active tasks: [0_0]
    	lost assigned standby tasks: []
     (org.apache.kafka.streams.processor.internals.StreamThread:104)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-7cad3a21-1b40-4477-be94-66c63245f646-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogfact-7cad3a21-1b40-4477-be94-66c63245f646-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    7cad3a21-1b40-4477-be94-66c63245f646: [shouldrestoreunflushedchangelogfact-7cad3a21-1b40-4477-be94-66c63245f646-StreamThread-1-consumer-7f599c86-6c84-4051-8233-8eb406895070]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogfact-7cad3a21-1b40-4477-be94-66c63245f646-StreamThread-1-consumer-7f599c86-6c84-4051-8233-8eb406895070=[]}
    	assigned active {shouldrestoreunflushedchangelogfact-7cad3a21-1b40-4477-be94-66c63245f646-StreamThread-1-consumer-7f599c86-6c84-4051-8233-8eb406895070=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 62891
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogfact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-fffc8982-a4ae-46fa-bd3b-7b6a96dd320d-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-fffc8982-a4ae-46fa-bd3b-7b6a96dd320d-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-fffc8982-a4ae-46fa-bd3b-7b6a96dd320d-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogfact-fffc8982-a4ae-46fa-bd3b-7b6a96dd320d-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-fffc8982-a4ae-46fa-bd3b-7b6a96dd320d-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    fffc8982-a4ae-46fa-bd3b-7b6a96dd320d: [shouldrestoreunflushedchangelogfact-fffc8982-a4ae-46fa-bd3b-7b6a96dd320d-StreamThread-1-consumer-c4f185e0-3b3c-43e5-9026-179293c31398]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogfact-fffc8982-a4ae-46fa-bd3b-7b6a96dd320d-StreamThread-1-consumer-c4f185e0-3b3c-43e5-9026-179293c31398=[]}
    	assigned active {shouldrestoreunflushedchangelogfact-fffc8982-a4ae-46fa-bd3b-7b6a96dd320d-StreamThread-1-consumer-c4f185e0-3b3c-43e5-9026-179293c31398=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    Using Scylla optimized driver!!!
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 62891
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogfact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-d303ce1f-0660-468e-849e-9c2c98087e5f-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-d303ce1f-0660-468e-849e-9c2c98087e5f-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-d303ce1f-0660-468e-849e-9c2c98087e5f-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogfact-d303ce1f-0660-468e-849e-9c2c98087e5f-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-d303ce1f-0660-468e-849e-9c2c98087e5f-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    d303ce1f-0660-468e-849e-9c2c98087e5f: [shouldrestoreunflushedchangelogfact-d303ce1f-0660-468e-849e-9c2c98087e5f-StreamThread-1-consumer-23679478-9f1f-4e1e-8050-feabf8092359]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogfact-d303ce1f-0660-468e-849e-9c2c98087e5f-StreamThread-1-consumer-23679478-9f1f-4e1e-8050-feabf8092359=[]}
    	assigned active {shouldrestoreunflushedchangelogfact-d303ce1f-0660-468e-849e-9c2c98087e5f-StreamThread-1-consumer-23679478-9f1f-4e1e-8050-feabf8092359=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-14
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
      [0K[32mâœ”[90m [2] FACT[31m (24.3s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest STANDARD_OUT

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldFlushStoresBeforeClose(KVSchema) > [1] KEY_VALUE STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-15
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 62891
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldflushstoresbeforeclosekeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosekeyvalue-8b581540-d1be-46ab-aac9-71f1c3b6a258-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosekeyvalue-8b581540-d1be-46ab-aac9-71f1c3b6a258-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosekeyvalue-8b581540-d1be-46ab-aac9-71f1c3b6a258-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldflushstoresbeforeclosekeyvalue-8b581540-d1be-46ab-aac9-71f1c3b6a258-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosekeyvalue-8b581540-d1be-46ab-aac9-71f1c3b6a258-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldflushstoresbeforeclosekeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    8b581540-d1be-46ab-aac9-71f1c3b6a258: [shouldflushstoresbeforeclosekeyvalue-8b581540-d1be-46ab-aac9-71f1c3b6a258-StreamThread-1-consumer-51cd0cb7-b935-4e7a-86f6-6b7b667edae2]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldflushstoresbeforeclosekeyvalue-8b581540-d1be-46ab-aac9-71f1c3b6a258-StreamThread-1-consumer-51cd0cb7-b935-4e7a-86f6-6b7b667edae2=[]}
    	assigned active {shouldflushstoresbeforeclosekeyvalue-8b581540-d1be-46ab-aac9-71f1c3b6a258-StreamThread-1-consumer-51cd0cb7-b935-4e7a-86f6-6b7b667edae2=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldflushstoresbeforeclosekeyvalue.input-0, shouldflushstoresbeforeclosekeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldflushstoresbeforeclosekeyvalue.input-0, shouldflushstoresbeforeclosekeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    Using Scylla optimized driver!!!
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-15
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

    [0K[39mshouldFlushStoresBeforeClose(KVSchema)[m

      [0K[32mâœ”[90m [1] KEY_VALUE[31m (7.9s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldFlushStoresBeforeClose(KVSchema) > [2] FACT STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-16
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 62891
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldflushstoresbeforeclosefact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosefact-971fcdbe-e08d-44dc-9952-05b63f7e2258-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosefact-971fcdbe-e08d-44dc-9952-05b63f7e2258-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosefact-971fcdbe-e08d-44dc-9952-05b63f7e2258-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldflushstoresbeforeclosefact-971fcdbe-e08d-44dc-9952-05b63f7e2258-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosefact-971fcdbe-e08d-44dc-9952-05b63f7e2258-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldflushstoresbeforeclosefact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    971fcdbe-e08d-44dc-9952-05b63f7e2258: [shouldflushstoresbeforeclosefact-971fcdbe-e08d-44dc-9952-05b63f7e2258-StreamThread-1-consumer-bea74ff4-23f1-4e44-801f-cee7c341dc19]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldflushstoresbeforeclosefact-971fcdbe-e08d-44dc-9952-05b63f7e2258-StreamThread-1-consumer-bea74ff4-23f1-4e44-801f-cee7c341dc19=[]}
    	assigned active {shouldflushstoresbeforeclosefact-971fcdbe-e08d-44dc-9952-05b63f7e2258-StreamThread-1-consumer-bea74ff4-23f1-4e44-801f-cee7c341dc19=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldflushstoresbeforeclosefact.input-0, shouldflushstoresbeforeclosefact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldflushstoresbeforeclosefact.input-0, shouldflushstoresbeforeclosefact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	lost active tasks: [0_0]
    	lost assigned standby tasks: []
     (org.apache.kafka.streams.processor.internals.StreamThread:104)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosefact-971fcdbe-e08d-44dc-9952-05b63f7e2258-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldflushstoresbeforeclosefact-971fcdbe-e08d-44dc-9952-05b63f7e2258-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    971fcdbe-e08d-44dc-9952-05b63f7e2258: [shouldflushstoresbeforeclosefact-971fcdbe-e08d-44dc-9952-05b63f7e2258-StreamThread-1-consumer-f865546a-fa62-48bf-8092-6780e3a49e1d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldflushstoresbeforeclosefact-971fcdbe-e08d-44dc-9952-05b63f7e2258-StreamThread-1-consumer-f865546a-fa62-48bf-8092-6780e3a49e1d=[]}
    	assigned active {shouldflushstoresbeforeclosefact-971fcdbe-e08d-44dc-9952-05b63f7e2258-StreamThread-1-consumer-f865546a-fa62-48bf-8092-6780e3a49e1d=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldflushstoresbeforeclosefact.input-0, shouldflushstoresbeforeclosefact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldflushstoresbeforeclosefact.input-0, shouldflushstoresbeforeclosefact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    Using Scylla optimized driver!!!
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-16
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
      [0K[32mâœ”[90m [2] FACT[31m (10.2s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldRepairOffsetsIfOutOfRangeAndConfigured(KVSchema) > [1] KEY_VALUE STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-17
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 62891
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = true
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-92aba998-95ca-48bb-a222-bd667755bafc-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-92aba998-95ca-48bb-a222-bd667755bafc-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-92aba998-95ca-48bb-a222-bd667755bafc-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-92aba998-95ca-48bb-a222-bd667755bafc-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-92aba998-95ca-48bb-a222-bd667755bafc-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    92aba998-95ca-48bb-a222-bd667755bafc: [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-92aba998-95ca-48bb-a222-bd667755bafc-StreamThread-1-consumer-0be09f7f-a4fa-49f7-bbf0-ffb83245dfc5]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-92aba998-95ca-48bb-a222-bd667755bafc-StreamThread-1-consumer-0be09f7f-a4fa-49f7-bbf0-ffb83245dfc5=[]}
    	assigned active {shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-92aba998-95ca-48bb-a222-bd667755bafc-StreamThread-1-consumer-0be09f7f-a4fa-49f7-bbf0-ffb83245dfc5=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input-0, shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input-0, shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-17
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 62891
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = true
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-ee377265-345f-4482-a765-f41c8de71579-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-ee377265-345f-4482-a765-f41c8de71579-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-ee377265-345f-4482-a765-f41c8de71579-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-ee377265-345f-4482-a765-f41c8de71579-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-ee377265-345f-4482-a765-f41c8de71579-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    ee377265-345f-4482-a765-f41c8de71579: [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-ee377265-345f-4482-a765-f41c8de71579-StreamThread-1-consumer-0d2629cd-41c9-4262-9037-d5292bcac4d4]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-ee377265-345f-4482-a765-f41c8de71579-StreamThread-1-consumer-0d2629cd-41c9-4262-9037-d5292bcac4d4=[]}
    	assigned active {shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-ee377265-345f-4482-a765-f41c8de71579-StreamThread-1-consumer-0d2629cd-41c9-4262-9037-d5292bcac4d4=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input-0, shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input-0, shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.clients.consumer.OffsetOutOfRangeException: Fetch position FetchPosition{offset=198, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:62971 (id: 1 rack: null)], epoch=0}} is out of range for partition shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-shouldrepairoffsetsifoutofrangeandconfiguredkeyvalueagg-changelog-0
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.handleInitializeErrors(FetchCollector.java:348)
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.initialize(FetchCollector.java:230)
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.collectFetch(FetchCollector.java:110)
    	at org.apache.kafka.clients.consumer.internals.Fetcher.collectFetch(Fetcher.java:145)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.pollForFetches(LegacyKafkaConsumer.java:693)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.poll(LegacyKafkaConsumer.java:617)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.poll(LegacyKafkaConsumer.java:590)
    	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:874)
    	at dev.responsive.kafka.internal.clients.DelegatingConsumer.poll(DelegatingConsumer.java:95)
    	at dev.responsive.kafka.internal.clients.ResponsiveRestoreConsumer.poll(ResponsiveRestoreConsumer.java:111)
    	at org.apache.kafka.streams.processor.internals.StoreChangelogReader.pollRecordsFromRestoreConsumer(StoreChangelogReader.java:494)
    	at org.apache.kafka.streams.processor.internals.StoreChangelogReader.restore(StoreChangelogReader.java:450)
    	at org.apache.kafka.streams.processor.internals.StreamThread.initializeAndRestorePhase(StreamThread.java:1134)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:921)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-18
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

    [0K[39mshouldRepairOffsetsIfOutOfRangeAndConfigured(KVSchema)[m

      [0K[32mâœ”[90m [1] KEY_VALUE[31m (18.4s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldRepairOffsetsIfOutOfRangeAndConfigured(KVSchema) > [2] FACT STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-18
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 62891
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = true
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrepairoffsetsifoutofrangeandconfiguredfact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-21b92d8e-7b16-4d46-8e9e-54e218bcbbe2-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-21b92d8e-7b16-4d46-8e9e-54e218bcbbe2-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-21b92d8e-7b16-4d46-8e9e-54e218bcbbe2-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-21b92d8e-7b16-4d46-8e9e-54e218bcbbe2-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-21b92d8e-7b16-4d46-8e9e-54e218bcbbe2-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrepairoffsetsifoutofrangeandconfiguredfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    21b92d8e-7b16-4d46-8e9e-54e218bcbbe2: [shouldrepairoffsetsifoutofrangeandconfiguredfact-21b92d8e-7b16-4d46-8e9e-54e218bcbbe2-StreamThread-1-consumer-2164f0cb-a49d-41aa-8919-8b9936aefbd9]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrepairoffsetsifoutofrangeandconfiguredfact-21b92d8e-7b16-4d46-8e9e-54e218bcbbe2-StreamThread-1-consumer-2164f0cb-a49d-41aa-8919-8b9936aefbd9=[]}
    	assigned active {shouldrepairoffsetsifoutofrangeandconfiguredfact-21b92d8e-7b16-4d46-8e9e-54e218bcbbe2-StreamThread-1-consumer-2164f0cb-a49d-41aa-8919-8b9936aefbd9=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	lost active tasks: [0_0]
    	lost assigned standby tasks: []
     (org.apache.kafka.streams.processor.internals.StreamThread:104)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-21b92d8e-7b16-4d46-8e9e-54e218bcbbe2-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-21b92d8e-7b16-4d46-8e9e-54e218bcbbe2-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    21b92d8e-7b16-4d46-8e9e-54e218bcbbe2: [shouldrepairoffsetsifoutofrangeandconfiguredfact-21b92d8e-7b16-4d46-8e9e-54e218bcbbe2-StreamThread-1-consumer-9e25f66a-1592-4929-89f5-6e5963c96ee8]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrepairoffsetsifoutofrangeandconfiguredfact-21b92d8e-7b16-4d46-8e9e-54e218bcbbe2-StreamThread-1-consumer-9e25f66a-1592-4929-89f5-6e5963c96ee8=[]}
    	assigned active {shouldrepairoffsetsifoutofrangeandconfiguredfact-21b92d8e-7b16-4d46-8e9e-54e218bcbbe2-StreamThread-1-consumer-9e25f66a-1592-4929-89f5-6e5963c96ee8=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-19
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 62891
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = true
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrepairoffsetsifoutofrangeandconfiguredfact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-1746573c-37f1-4091-9dee-633a69d16a2a-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-1746573c-37f1-4091-9dee-633a69d16a2a-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-1746573c-37f1-4091-9dee-633a69d16a2a-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-1746573c-37f1-4091-9dee-633a69d16a2a-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-1746573c-37f1-4091-9dee-633a69d16a2a-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrepairoffsetsifoutofrangeandconfiguredfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    1746573c-37f1-4091-9dee-633a69d16a2a: [shouldrepairoffsetsifoutofrangeandconfiguredfact-1746573c-37f1-4091-9dee-633a69d16a2a-StreamThread-1-consumer-bbddc10c-565f-422f-a8cf-31863e03bc5d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrepairoffsetsifoutofrangeandconfiguredfact-1746573c-37f1-4091-9dee-633a69d16a2a-StreamThread-1-consumer-bbddc10c-565f-422f-a8cf-31863e03bc5d=[]}
    	assigned active {shouldrepairoffsetsifoutofrangeandconfiguredfact-1746573c-37f1-4091-9dee-633a69d16a2a-StreamThread-1-consumer-bbddc10c-565f-422f-a8cf-31863e03bc5d=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.clients.consumer.OffsetOutOfRangeException: Fetch position FetchPosition{offset=198, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:62971 (id: 1 rack: null)], epoch=0}} is out of range for partition shouldrepairoffsetsifoutofrangeandconfiguredfact-shouldrepairoffsetsifoutofrangeandconfiguredfactagg-changelog-0
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.handleInitializeErrors(FetchCollector.java:348)
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.initialize(FetchCollector.java:230)
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.collectFetch(FetchCollector.java:110)
    	at org.apache.kafka.clients.consumer.internals.Fetcher.collectFetch(Fetcher.java:145)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.pollForFetches(LegacyKafkaConsumer.java:693)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.poll(LegacyKafkaConsumer.java:617)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.poll(LegacyKafkaConsumer.java:590)
    	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:874)
    	at dev.responsive.kafka.internal.clients.DelegatingConsumer.poll(DelegatingConsumer.java:95)
    	at dev.responsive.kafka.internal.clients.ResponsiveRestoreConsumer.poll(ResponsiveRestoreConsumer.java:111)
    	at org.apache.kafka.streams.processor.internals.StoreChangelogReader.pollRecordsFromRestoreConsumer(StoreChangelogReader.java:494)
    	at org.apache.kafka.streams.processor.internals.StoreChangelogReader.restore(StoreChangelogReader.java:450)
    	at org.apache.kafka.streams.processor.internals.StreamThread.initializeAndRestorePhase(StreamThread.java:1134)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:921)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:62971]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-20
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
      [0K[32mâœ”[90m [2] FACT[31m (17.3s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest STANDARD_ERROR
    Test 7(dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest): CASSANDRA teardown begins at 1731055060243ms (speed check)

ResponsiveKeyValueStoreRestoreIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

ResponsiveKeyValueStoreRestoreIntegrationTest STANDARD_ERROR
    Test 7(dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest): CASSANDRA teardown ends at 1731055063471ms (duration: PT3.228S) (speed check)
    Test 7(dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest): CASSANDRA test total runtime=PT1M57.366S) (speed check)

Gradle Test Executor 2 STANDARD_ERROR
    Test 8: creating ResponsiveExtension(backend=MONGO_DB) at 1731055063476ms (speed check)

Gradle Test Executor 2 STANDARD_OUT

ResponsiveSessionStoreIntegrationTest STANDARD_OUT

ResponsiveSessionStoreIntegrationTest STANDARD_ERROR
    Test 8(dev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest): MONGO_DB setup begins at 1731055063490ms (speed check)

ResponsiveSessionStoreIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64203]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

ResponsiveSessionStoreIntegrationTest STANDARD_ERROR
    Test 8(dev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest): MONGO_DB setup ends at 1731055073050ms (duration: PT9.56S) (speed check)

ResponsiveSessionStoreIntegrationTest > shouldComputeSessionAggregate() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:64203]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-19
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:64154
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64203]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldComputeSessionAggregate--850533984
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:64203]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64203]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeSessionAggregate--850533984-b9904b9c-df04-480c-8605-95a66d0e3a49-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:64203]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeSessionAggregate--850533984-b9904b9c-df04-480c-8605-95a66d0e3a49-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64203]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:64203]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeSessionAggregate--850533984-b9904b9c-df04-480c-8605-95a66d0e3a49-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:64203]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeSessionAggregate--850533984-b9904b9c-df04-480c-8605-95a66d0e3a49-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldComputeSessionAggregate--850533984
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    b9904b9c-df04-480c-8605-95a66d0e3a49: [shouldComputeSessionAggregate--850533984-b9904b9c-df04-480c-8605-95a66d0e3a49-StreamThread-1-consumer-cc5dbd5b-5b82-4135-8de5-7963505deb9a]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldComputeSessionAggregate--850533984-b9904b9c-df04-480c-8605-95a66d0e3a49-StreamThread-1-consumer-cc5dbd5b-5b82-4135-8de5-7963505deb9a=[]}
    	assigned active {shouldComputeSessionAggregate--850533984-b9904b9c-df04-480c-8605-95a66d0e3a49-StreamThread-1-consumer-cc5dbd5b-5b82-4135-8de5-7963505deb9a=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldComputeSessionAggregate--850533984.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldComputeSessionAggregate--850533984.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)

  [0K[39mdev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest[m

    [0K[32mâœ”[90m shouldComputeSessionAggregate()[33m (1.6s)[m

ResponsiveSessionStoreIntegrationTest STANDARD_ERROR
    Test 8(dev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest): MONGO_DB teardown begins at 1731055074660ms (speed check)

ResponsiveSessionStoreIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

ResponsiveSessionStoreIntegrationTest STANDARD_ERROR
    Test 8(dev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest): MONGO_DB teardown ends at 1731055075999ms (duration: PT1.339S) (speed check)
    Test 8(dev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest): MONGO_DB test total runtime=PT12.523S) (speed check)

Gradle Test Executor 2 STANDARD_ERROR
    Test 9: creating ResponsiveExtension(backend=MONGO_DB) at 1731055076002ms (speed check)

ResponsiveWindowStoreIntegrationTest STANDARD_ERROR
    Test 9(dev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest): MONGO_DB setup begins at 1731055076005ms (speed check)

ResponsiveWindowStoreIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

ResponsiveWindowStoreIntegrationTest STANDARD_ERROR
    Test 9(dev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest): MONGO_DB setup ends at 1731055086443ms (duration: PT10.438S) (speed check)

ResponsiveWindowStoreIntegrationTest > shouldDoStreamStreamJoin() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-20
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:64366
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 1
    	responsive.window.bloom.filter.expected.keys = 10
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldDoStreamStreamJoin-331308691
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDoStreamStreamJoin-331308691-dd671694-9b4d-41ce-9089-0c2871ceec91-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDoStreamStreamJoin-331308691-dd671694-9b4d-41ce-9089-0c2871ceec91-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDoStreamStreamJoin-331308691-dd671694-9b4d-41ce-9089-0c2871ceec91-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDoStreamStreamJoin-331308691-dd671694-9b4d-41ce-9089-0c2871ceec91-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldDoStreamStreamJoin-331308691
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    dd671694-9b4d-41ce-9089-0c2871ceec91: [shouldDoStreamStreamJoin-331308691-dd671694-9b4d-41ce-9089-0c2871ceec91-StreamThread-1-consumer-ede1e4ac-293c-4939-86c4-241573ebed45]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldDoStreamStreamJoin-331308691-dd671694-9b4d-41ce-9089-0c2871ceec91-StreamThread-1-consumer-ede1e4ac-293c-4939-86c4-241573ebed45=[]}
    	assigned active {shouldDoStreamStreamJoin-331308691-dd671694-9b4d-41ce-9089-0c2871ceec91-StreamThread-1-consumer-ede1e4ac-293c-4939-86c4-241573ebed45=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldDoStreamStreamJoin-331308691.input-0, shouldDoStreamStreamJoin-331308691.other-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldDoStreamStreamJoin-331308691.input-0, shouldDoStreamStreamJoin-331308691.other-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    Joining: L:a, R:a
    Joining: L:a2, R:a
    Joining: L:a3, R:a
    Joining: L:b, R:b
    Joining: L:b, R:b2
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-21
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest[m

    [0K[32mâœ”[90m shouldDoStreamStreamJoin()[31m (2.1s)[m

ResponsiveWindowStoreIntegrationTest > shouldComputeHoppingWindowAggregateWithRetention() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-21
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:64366
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 1
    	responsive.window.bloom.filter.expected.keys = 10
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldComputeHoppingWindowAggregateWithRetention-1816552406
    	application.server = host1:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeHoppingWindowAggregateWithRetention-1816552406-a7f8a179-5e58-49bc-8a8e-6455bd4957d2-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeHoppingWindowAggregateWithRetention-1816552406-a7f8a179-5e58-49bc-8a8e-6455bd4957d2-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeHoppingWindowAggregateWithRetention-1816552406-a7f8a179-5e58-49bc-8a8e-6455bd4957d2-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeHoppingWindowAggregateWithRetention-1816552406-a7f8a179-5e58-49bc-8a8e-6455bd4957d2-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldComputeHoppingWindowAggregateWithRetention-1816552406
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    a7f8a179-5e58-49bc-8a8e-6455bd4957d2: [shouldComputeHoppingWindowAggregateWithRetention-1816552406-a7f8a179-5e58-49bc-8a8e-6455bd4957d2-StreamThread-1-consumer-24cfec66-003e-4483-a6d9-f93312b23e5a]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldComputeHoppingWindowAggregateWithRetention-1816552406-a7f8a179-5e58-49bc-8a8e-6455bd4957d2-StreamThread-1-consumer-24cfec66-003e-4483-a6d9-f93312b23e5a=[]}
    	assigned active {shouldComputeHoppingWindowAggregateWithRetention-1816552406-a7f8a179-5e58-49bc-8a8e-6455bd4957d2-StreamThread-1-consumer-24cfec66-003e-4483-a6d9-f93312b23e5a=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldComputeHoppingWindowAggregateWithRetention-1816552406.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldComputeHoppingWindowAggregateWithRetention-1816552406.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    [0K[32mâœ”[90m shouldComputeHoppingWindowAggregateWithRetention()[31m (1m)[m

ResponsiveWindowStoreIntegrationTest > shouldComputeTumblingWindowAggregateWithRetention() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:64366
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 1
    	responsive.window.bloom.filter.expected.keys = 10
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldComputeTumblingWindowAggregateWithRetention-1255401162
    	application.server = host1:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention-1255401162-31c3b809-eb77-4b3e-b8bd-41979230c5cf-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention-1255401162-31c3b809-eb77-4b3e-b8bd-41979230c5cf-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention-1255401162-31c3b809-eb77-4b3e-b8bd-41979230c5cf-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention-1255401162-31c3b809-eb77-4b3e-b8bd-41979230c5cf-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldComputeTumblingWindowAggregateWithRetention-1255401162
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-22
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    31c3b809-eb77-4b3e-b8bd-41979230c5cf: [shouldComputeTumblingWindowAggregateWithRetention-1255401162-31c3b809-eb77-4b3e-b8bd-41979230c5cf-StreamThread-1-consumer-e2a7468b-11fa-4ba3-b28f-4364fd96918d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldComputeTumblingWindowAggregateWithRetention-1255401162-31c3b809-eb77-4b3e-b8bd-41979230c5cf-StreamThread-1-consumer-e2a7468b-11fa-4ba3-b28f-4364fd96918d=[]}
    	assigned active {shouldComputeTumblingWindowAggregateWithRetention-1255401162-31c3b809-eb77-4b3e-b8bd-41979230c5cf-StreamThread-1-consumer-e2a7468b-11fa-4ba3-b28f-4364fd96918d=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldComputeTumblingWindowAggregateWithRetention-1255401162.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldComputeTumblingWindowAggregateWithRetention-1255401162.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:64366
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 1
    	responsive.window.bloom.filter.expected.keys = 10
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldComputeTumblingWindowAggregateWithRetention-1255401162
    	application.server = host2:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention-1255401162-55883961-8b3e-4239-bb58-957912dbb435-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention-1255401162-55883961-8b3e-4239-bb58-957912dbb435-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention-1255401162-55883961-8b3e-4239-bb58-957912dbb435-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention-1255401162-55883961-8b3e-4239-bb58-957912dbb435-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldComputeTumblingWindowAggregateWithRetention-1255401162
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-23
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    55883961-8b3e-4239-bb58-957912dbb435: [shouldComputeTumblingWindowAggregateWithRetention-1255401162-55883961-8b3e-4239-bb58-957912dbb435-StreamThread-1-consumer-2f7bb7bf-f0a0-480a-b4e3-850949b8d660]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldComputeTumblingWindowAggregateWithRetention-1255401162-55883961-8b3e-4239-bb58-957912dbb435-StreamThread-1-consumer-2f7bb7bf-f0a0-480a-b4e3-850949b8d660=[]}
    	assigned active {shouldComputeTumblingWindowAggregateWithRetention-1255401162-55883961-8b3e-4239-bb58-957912dbb435-StreamThread-1-consumer-2f7bb7bf-f0a0-480a-b4e3-850949b8d660=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldComputeTumblingWindowAggregateWithRetention-1255401162.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldComputeTumblingWindowAggregateWithRetention-1255401162.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    [0K[32mâœ”[90m shouldComputeTumblingWindowAggregateWithRetention()[31m (4m 6s)[m

ResponsiveWindowStoreIntegrationTest > shouldComputeMultipleWindowsPerSegment() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:64366
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 1
    	responsive.window.bloom.filter.expected.keys = 10
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldComputeMultipleWindowsPerSegment--680766895
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeMultipleWindowsPerSegment--680766895-cfe19382-e68b-4ca0-b4c3-c72b22ed98ca-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeMultipleWindowsPerSegment--680766895-cfe19382-e68b-4ca0-b4c3-c72b22ed98ca-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeMultipleWindowsPerSegment--680766895-cfe19382-e68b-4ca0-b4c3-c72b22ed98ca-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeMultipleWindowsPerSegment--680766895-cfe19382-e68b-4ca0-b4c3-c72b22ed98ca-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldComputeMultipleWindowsPerSegment--680766895
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:64421]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-24
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    cfe19382-e68b-4ca0-b4c3-c72b22ed98ca: [shouldComputeMultipleWindowsPerSegment--680766895-cfe19382-e68b-4ca0-b4c3-c72b22ed98ca-StreamThread-1-consumer-46c555db-45d3-4ead-9aae-7e631c0638d9]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldComputeMultipleWindowsPerSegment--680766895-cfe19382-e68b-4ca0-b4c3-c72b22ed98ca-StreamThread-1-consumer-46c555db-45d3-4ead-9aae-7e631c0638d9=[]}
    	assigned active {shouldComputeMultipleWindowsPerSegment--680766895-cfe19382-e68b-4ca0-b4c3-c72b22ed98ca-StreamThread-1-consumer-46c555db-45d3-4ead-9aae-7e631c0638d9=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldComputeMultipleWindowsPerSegment--680766895.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldComputeMultipleWindowsPerSegment--680766895.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    [0K[32mâœ”[90m shouldComputeMultipleWindowsPerSegment()[31m (1m 1s)[m

ResponsiveWindowStoreIntegrationTest STANDARD_ERROR
    Test 9(dev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest): MONGO_DB teardown begins at 1731055457093ms (speed check)

ResponsiveWindowStoreIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

ResponsiveWindowStoreIntegrationTest STANDARD_ERROR
    Test 9(dev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest): MONGO_DB teardown ends at 1731055458812ms (duration: PT1.719S) (speed check)
    Test 9(dev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest): MONGO_DB test total runtime=PT6M22.81S) (speed check)

Gradle Test Executor 2 STANDARD_ERROR
    Test 10: creating ResponsiveExtension(backend=CASSANDRA) at 1731055458816ms (speed check)

RowLevelTtlIntegrationTest STANDARD_ERROR
    Test 10(dev.responsive.kafka.integration.RowLevelTtlIntegrationTest): CASSANDRA setup begins at 1731055458820ms (speed check)

RowLevelTtlIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54297]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

RowLevelTtlIntegrationTest STANDARD_ERROR
    Test 10(dev.responsive.kafka.integration.RowLevelTtlIntegrationTest): CASSANDRA setup ends at 1731055472839ms (duration: PT14.019S) (speed check)

RowLevelTtlIntegrationTest > shouldApplyRowLevelTtlForKeyAndValue() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54297]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-25
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54151
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = maxIdleTimeMs=60000
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54297]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldApplyRowLevelTtlForKeyAndValue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54297]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54297]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldApplyRowLevelTtlForKeyAndValue-a91dc0bf-0be5-42c5-a08c-0255fd5a45e6-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54297]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldApplyRowLevelTtlForKeyAndValue-a91dc0bf-0be5-42c5-a08c-0255fd5a45e6-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54297]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54297]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldApplyRowLevelTtlForKeyAndValue-a91dc0bf-0be5-42c5-a08c-0255fd5a45e6-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54297]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldApplyRowLevelTtlForKeyAndValue-a91dc0bf-0be5-42c5-a08c-0255fd5a45e6-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldApplyRowLevelTtlForKeyAndValue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    a91dc0bf-0be5-42c5-a08c-0255fd5a45e6: [shouldApplyRowLevelTtlForKeyAndValue-a91dc0bf-0be5-42c5-a08c-0255fd5a45e6-StreamThread-1-consumer-9fc551fd-6e7b-423e-b72f-5ce14b1d7b2e]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldApplyRowLevelTtlForKeyAndValue-a91dc0bf-0be5-42c5-a08c-0255fd5a45e6-StreamThread-1-consumer-9fc551fd-6e7b-423e-b72f-5ce14b1d7b2e=[]}
    	assigned active {shouldApplyRowLevelTtlForKeyAndValue-a91dc0bf-0be5-42c5-a08c-0255fd5a45e6-StreamThread-1-consumer-9fc551fd-6e7b-423e-b72f-5ce14b1d7b2e=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldApplyRowLevelTtlForKeyAndValue.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldApplyRowLevelTtlForKeyAndValue.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54297]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-22
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.RowLevelTtlIntegrationTest[m

    [0K[32mâœ”[90m shouldApplyRowLevelTtlForKeyAndValue()[31m (6.1s)[m

RowLevelTtlIntegrationTest STANDARD_ERROR
    Test 10(dev.responsive.kafka.integration.RowLevelTtlIntegrationTest): CASSANDRA teardown begins at 1731055478992ms (speed check)

RowLevelTtlIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

RowLevelTtlIntegrationTest STANDARD_ERROR
    Test 10(dev.responsive.kafka.integration.RowLevelTtlIntegrationTest): CASSANDRA teardown ends at 1731055482068ms (duration: PT3.076S) (speed check)
    Test 10(dev.responsive.kafka.integration.RowLevelTtlIntegrationTest): CASSANDRA test total runtime=PT23.252S) (speed check)

Gradle Test Executor 2 STANDARD_ERROR
    Test 11: creating ResponsiveExtension(backend=CASSANDRA) at 1731055482074ms (speed check)

Gradle Test Executor 2 STANDARD_OUT

StoreQueryIntegrationTest STANDARD_ERROR
    Test 11(dev.responsive.kafka.integration.StoreQueryIntegrationTest): CASSANDRA setup begins at 1731055482083ms (speed check)

StoreQueryIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

StoreQueryIntegrationTest STANDARD_ERROR
    Test 11(dev.responsive.kafka.integration.StoreQueryIntegrationTest): CASSANDRA setup ends at 1731055495647ms (duration: PT13.564S) (speed check)

StoreQueryIntegrationTest > shouldAggregateAcrossAllKeysUsingAllQuery() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-26
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54576
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldAggregateAcrossAllKeysUsingAllQuery
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAcrossAllKeysUsingAllQuery-4a1233c0-025d-4ea5-956d-67a326952324-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAcrossAllKeysUsingAllQuery-4a1233c0-025d-4ea5-956d-67a326952324-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAcrossAllKeysUsingAllQuery-4a1233c0-025d-4ea5-956d-67a326952324-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAcrossAllKeysUsingAllQuery-4a1233c0-025d-4ea5-956d-67a326952324-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldAggregateAcrossAllKeysUsingAllQuery
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    4a1233c0-025d-4ea5-956d-67a326952324: [shouldAggregateAcrossAllKeysUsingAllQuery-4a1233c0-025d-4ea5-956d-67a326952324-StreamThread-1-consumer-b7e0e087-5f36-4817-81aa-d56804bb63de]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldAggregateAcrossAllKeysUsingAllQuery-4a1233c0-025d-4ea5-956d-67a326952324-StreamThread-1-consumer-b7e0e087-5f36-4817-81aa-d56804bb63de=[]}
    	assigned active {shouldAggregateAcrossAllKeysUsingAllQuery-4a1233c0-025d-4ea5-956d-67a326952324-StreamThread-1-consumer-b7e0e087-5f36-4817-81aa-d56804bb63de=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldAggregateAcrossAllKeysUsingAllQuery.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldAggregateAcrossAllKeysUsingAllQuery.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-23
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.StoreQueryIntegrationTest[m

    [0K[32mâœ”[90m shouldAggregateAcrossAllKeysUsingAllQuery()[31m (4.3s)[m

StoreQueryIntegrationTest > shouldAggregateAllCapitalLettersUsingRangeQuery() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-27
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54576
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldAggregateAllCapitalLettersUsingRangeQuery
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAllCapitalLettersUsingRangeQuery-1d1bd688-b4ff-4cc4-8c1c-2f56d81c42b0-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAllCapitalLettersUsingRangeQuery-1d1bd688-b4ff-4cc4-8c1c-2f56d81c42b0-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAllCapitalLettersUsingRangeQuery-1d1bd688-b4ff-4cc4-8c1c-2f56d81c42b0-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAllCapitalLettersUsingRangeQuery-1d1bd688-b4ff-4cc4-8c1c-2f56d81c42b0-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldAggregateAllCapitalLettersUsingRangeQuery
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    1d1bd688-b4ff-4cc4-8c1c-2f56d81c42b0: [shouldAggregateAllCapitalLettersUsingRangeQuery-1d1bd688-b4ff-4cc4-8c1c-2f56d81c42b0-StreamThread-1-consumer-c32d262b-fdf8-472b-a463-c594879da90b]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldAggregateAllCapitalLettersUsingRangeQuery-1d1bd688-b4ff-4cc4-8c1c-2f56d81c42b0-StreamThread-1-consumer-c32d262b-fdf8-472b-a463-c594879da90b=[]}
    	assigned active {shouldAggregateAllCapitalLettersUsingRangeQuery-1d1bd688-b4ff-4cc4-8c1c-2f56d81c42b0-StreamThread-1-consumer-c32d262b-fdf8-472b-a463-c594879da90b=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldAggregateAllCapitalLettersUsingRangeQuery.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldAggregateAllCapitalLettersUsingRangeQuery.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54721]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-24
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    [0K[32mâœ”[90m shouldAggregateAllCapitalLettersUsingRangeQuery()[31m (4.2s)[m

StoreQueryIntegrationTest STANDARD_ERROR
    Test 11(dev.responsive.kafka.integration.StoreQueryIntegrationTest): CASSANDRA teardown begins at 1731055504197ms (speed check)

StoreQueryIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

StoreQueryIntegrationTest STANDARD_ERROR
    Test 11(dev.responsive.kafka.integration.StoreQueryIntegrationTest): CASSANDRA teardown ends at 1731055506501ms (duration: PT2.304S) (speed check)
    Test 11(dev.responsive.kafka.integration.StoreQueryIntegrationTest): CASSANDRA test total runtime=PT24.427S) (speed check)

Gradle Test Executor 2 STANDARD_ERROR
    Test 12: creating ResponsiveExtension(empty) at 1731055506504ms (speed check)

TablePartitionerIntegrationTest STANDARD_ERROR
    Test 12(dev.responsive.kafka.integration.TablePartitionerIntegrationTest): CASSANDRA setup begins at 1731055506517ms (speed check)

TablePartitionerIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

TablePartitionerIntegrationTest STANDARD_ERROR
    Test 12(dev.responsive.kafka.integration.TablePartitionerIntegrationTest): CASSANDRA setup ends at 1731055521424ms (duration: PT14.907S) (speed check)

TablePartitionerIntegrationTest > shouldFlushToRemoteTableWithSubpartitions() STANDARD_OUT
    Using Scylla optimized driver!!!
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-28
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = 32
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 55063
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.integration.TablePartitionerIntegrationTest$LongBytesHasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldFlushToRemoteTableWithSubpartitions
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 100
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithSubpartitions-ea9fda3a-12b5-4c67-aa12-f71fda9dffdb-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithSubpartitions-ea9fda3a-12b5-4c67-aa12-f71fda9dffdb-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithSubpartitions-ea9fda3a-12b5-4c67-aa12-f71fda9dffdb-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 10000
    	transactional.id = shouldFlushToRemoteTableWithSubpartitions-ea9fda3a-12b5-4c67-aa12-f71fda9dffdb-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithSubpartitions-ea9fda3a-12b5-4c67-aa12-f71fda9dffdb-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldFlushToRemoteTableWithSubpartitions
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    ea9fda3a-12b5-4c67-aa12-f71fda9dffdb: [shouldFlushToRemoteTableWithSubpartitions-ea9fda3a-12b5-4c67-aa12-f71fda9dffdb-StreamThread-1-consumer-e4bd3bf3-be88-40fd-88f4-db4903085044]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldFlushToRemoteTableWithSubpartitions-ea9fda3a-12b5-4c67-aa12-f71fda9dffdb-StreamThread-1-consumer-e4bd3bf3-be88-40fd-88f4-db4903085044=[]}
    	assigned active {shouldFlushToRemoteTableWithSubpartitions-ea9fda3a-12b5-4c67-aa12-f71fda9dffdb-StreamThread-1-consumer-e4bd3bf3-be88-40fd-88f4-db4903085044=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldFlushToRemoteTableWithSubpartitions.input-0, shouldFlushToRemoteTableWithSubpartitions.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldFlushToRemoteTableWithSubpartitions.input-0, shouldFlushToRemoteTableWithSubpartitions.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-25
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.TablePartitionerIntegrationTest[m

    [0K[32mâœ”[90m shouldFlushToRemoteTableWithSubpartitions()[31m (6.7s)[m

TablePartitionerIntegrationTest > shouldFlushToRemoteTableWithoutSubpartitions() STANDARD_OUT
    Using Scylla optimized driver!!!
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-29
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = 32
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 55063
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.integration.TablePartitionerIntegrationTest$LongBytesHasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldFlushToRemoteTableWithoutSubpartitions
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 100
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithoutSubpartitions-4d2ef437-b309-4470-b060-68651fc8220b-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithoutSubpartitions-4d2ef437-b309-4470-b060-68651fc8220b-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithoutSubpartitions-4d2ef437-b309-4470-b060-68651fc8220b-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 10000
    	transactional.id = shouldFlushToRemoteTableWithoutSubpartitions-4d2ef437-b309-4470-b060-68651fc8220b-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithoutSubpartitions-4d2ef437-b309-4470-b060-68651fc8220b-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldFlushToRemoteTableWithoutSubpartitions
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    4d2ef437-b309-4470-b060-68651fc8220b: [shouldFlushToRemoteTableWithoutSubpartitions-4d2ef437-b309-4470-b060-68651fc8220b-StreamThread-1-consumer-a6f841e2-2e0e-4130-a9e5-9b45b4f0aeb1]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldFlushToRemoteTableWithoutSubpartitions-4d2ef437-b309-4470-b060-68651fc8220b-StreamThread-1-consumer-a6f841e2-2e0e-4130-a9e5-9b45b4f0aeb1=[]}
    	assigned active {shouldFlushToRemoteTableWithoutSubpartitions-4d2ef437-b309-4470-b060-68651fc8220b-StreamThread-1-consumer-a6f841e2-2e0e-4130-a9e5-9b45b4f0aeb1=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldFlushToRemoteTableWithoutSubpartitions.input-0, shouldFlushToRemoteTableWithoutSubpartitions.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldFlushToRemoteTableWithoutSubpartitions.input-0, shouldFlushToRemoteTableWithoutSubpartitions.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:55255]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-26
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    [0K[32mâœ”[90m shouldFlushToRemoteTableWithoutSubpartitions()[31m (6.3s)[m

TablePartitionerIntegrationTest STANDARD_ERROR
    Test 12(dev.responsive.kafka.integration.TablePartitionerIntegrationTest): CASSANDRA teardown begins at 1731055534570ms (speed check)

TablePartitionerIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

TablePartitionerIntegrationTest STANDARD_ERROR
    Test 12(dev.responsive.kafka.integration.TablePartitionerIntegrationTest): CASSANDRA teardown ends at 1731055537033ms (duration: PT2.463S) (speed check)
    Test 12(dev.responsive.kafka.integration.TablePartitionerIntegrationTest): CASSANDRA test total runtime=PT30.529S) (speed check)

Gradle Test Executor 2 STANDARD_ERROR
    Test 13: creating ResponsiveExtension(empty) at 1731055537036ms (speed check)

CassandraFactTableIntegrationTest STANDARD_ERROR
    Test 13(dev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest): CASSANDRA setup begins at 1731055537042ms (speed check)

CassandraFactTableIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:55951]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

CassandraFactTableIntegrationTest STANDARD_ERROR
    Test 13(dev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest): CASSANDRA setup ends at 1731055550966ms (duration: PT13.924S) (speed check)

CassandraFactTableIntegrationTest > shouldRespectSemanticKeyBasedTtl() STANDARD_OUT
    Using Scylla optimized driver!!!

  [0K[39mdev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest[m

    [0K[32mâœ”[90m shouldRespectSemanticKeyBasedTtl()[31m (2.5s)[m

CassandraFactTableIntegrationTest > shouldRespectOverridesWithValueBasedTtl() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldRespectOverridesWithValueBasedTtl()[31m (2.5s)[m

CassandraFactTableIntegrationTest > shouldInsertAndDelete() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldInsertAndDelete()[31m (2.4s)[m

CassandraFactTableIntegrationTest > shouldInitializeWithCorrectMetadata() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldInitializeWithCorrectMetadata()[31m (2.6s)[m

CassandraFactTableIntegrationTest > shouldRespectSemanticDefaultOnlyTtl() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldRespectSemanticDefaultOnlyTtl()[31m (2.5s)[m

CassandraFactTableIntegrationTest > shouldConfigureDefaultTtl() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldConfigureDefaultTtl()[31m (2.7s)[m

CassandraFactTableIntegrationTest > shouldRespectSemanticKeyValueBasedTtl() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldRespectSemanticKeyValueBasedTtl()[31m (2.6s)[m

CassandraFactTableIntegrationTest STANDARD_ERROR
    Test 13(dev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest): CASSANDRA teardown begins at 1731055569002ms (speed check)

CassandraFactTableIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

CassandraFactTableIntegrationTest STANDARD_ERROR
    Test 13(dev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest): CASSANDRA teardown ends at 1731055571228ms (duration: PT2.226S) (speed check)
    Test 13(dev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest): CASSANDRA test total runtime=PT34.192S) (speed check)

Gradle Test Executor 2 STANDARD_ERROR
    Test 14: creating ResponsiveExtension(empty) at 1731055571235ms (speed check)

Gradle Test Executor 2 STANDARD_OUT

CassandraKVTableIntegrationTest STANDARD_ERROR
    Test 14(dev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest): CASSANDRA setup begins at 1731055571242ms (speed check)

CassandraKVTableIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:56755]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

CassandraKVTableIntegrationTest STANDARD_ERROR
    Test 14(dev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest): CASSANDRA setup ends at 1731055585014ms (duration: PT13.772S) (speed check)

CassandraKVTableIntegrationTest > shouldSupportDataKeyThatEqualsMetadataKey() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 56549
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!

  [0K[39mdev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest[m

    [0K[32mâœ”[90m shouldSupportDataKeyThatEqualsMetadataKey()[33m (1.5s)[m

CassandraKVTableIntegrationTest > shouldReturnRangeKeysInLexicalOrderAcrossMultipleSubPartitions() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 56549
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldReturnRangeKeysInLexicalOrderAcrossMultipleSubPartitions()[33m (1.3s)[m

CassandraKVTableIntegrationTest > shouldRespectSemanticDefaultOnlyTtlForRangeQueries() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 56549
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldRespectSemanticDefaultOnlyTtlForRangeQueries()[33m (1.2s)[m

CassandraKVTableIntegrationTest > shouldRespectSemanticDefaultOnlyTtlForLookups() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 56549
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldRespectSemanticDefaultOnlyTtlForLookups()[33m (1.4s)[m

CassandraKVTableIntegrationTest > shouldConfigureDefaultTtl() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 56549
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldConfigureDefaultTtl()[33m (1.4s)[m

CassandraKVTableIntegrationTest > shouldReturnAllKeysInLexicalOrderAcrossMultipleSubPartitions() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 56549
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldReturnAllKeysInLexicalOrderAcrossMultipleSubPartitions()[33m (1.3s)[m

CassandraKVTableIntegrationTest > shouldRespectSemanticDefaultOnlyTtlForAllQueries() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 56549
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldRespectSemanticDefaultOnlyTtlForAllQueries()[33m (1.5s)[m

CassandraKVTableIntegrationTest STANDARD_ERROR
    Test 14(dev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest): CASSANDRA teardown begins at 1731055595088ms (speed check)

CassandraKVTableIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

CassandraKVTableIntegrationTest STANDARD_ERROR
    Test 14(dev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest): CASSANDRA teardown ends at 1731055597299ms (duration: PT2.211S) (speed check)
    Test 14(dev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest): CASSANDRA test total runtime=PT26.064S) (speed check)

Gradle Test Executor 2 STANDARD_ERROR
    Test 15: creating ResponsiveExtension(empty) at 1731055597303ms (speed check)

GlobalStreamThreadIntegrationTest STANDARD_ERROR
    Test 15(org.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest): CASSANDRA setup begins at 1731055597318ms (speed check)

GlobalStreamThreadIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

GlobalStreamThreadIntegrationTest STANDARD_ERROR
    Test 15(org.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest): CASSANDRA setup ends at 1731055613337ms (duration: PT16.019S) (speed check)

GlobalStreamThreadIntegrationTest > shouldRestoreWithSharedPartitionsAcrossApps() STANDARD_OUT
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-30
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldRestoreWithSharedPartitionsAcrossApps-global-27
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldRestoreWithSharedPartitionsAcrossApps-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldRestoreWithSharedPartitionsAcrossApps-global-28
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldRestoreWithSharedPartitionsAcrossApps-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acceptable.recovery.lag = 10000
    	application.id = shouldRestoreWithSharedPartitionsAcrossAppstestAppId
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 5000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	dsl.store.suppliers.class = class org.apache.kafka.streams.state.BuiltInDslStoreSuppliers$RocksDBDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 2000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T/junit16718389195212839553
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldRestoreWithSharedPartitionsAcrossApps-global-29
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldRestoreWithSharedPartitionsAcrossApps-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldRestoreWithSharedPartitionsAcrossApps-global-30
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldRestoreWithSharedPartitionsAcrossApps-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acceptable.recovery.lag = 10000
    	application.id = shouldRestoreWithSharedPartitionsAcrossAppstestAppId
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 5000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	dsl.store.suppliers.class = class org.apache.kafka.streams.state.BuiltInDslStoreSuppliers$RocksDBDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 2000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T/junit14500310702274474892
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)

  [0K[39morg.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest[m

    [0K[32mâœ”[90m shouldRestoreWithSharedPartitionsAcrossApps()[31m (2.8s)[m

GlobalStreamThreadIntegrationTest > shouldShareWorkInSteadyState() STANDARD_OUT
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-31
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldShareWorkInSteadyState-global-31
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldShareWorkInSteadyState-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldShareWorkInSteadyState-global-32
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldShareWorkInSteadyState-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acceptable.recovery.lag = 10000
    	application.id = shouldShareWorkInSteadyStatetestAppId
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 5000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	dsl.store.suppliers.class = class org.apache.kafka.streams.state.BuiltInDslStoreSuppliers$RocksDBDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 2000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T/junit3397385807521394856
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldShareWorkInSteadyState-global-33
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldShareWorkInSteadyState-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldShareWorkInSteadyState-global-34
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldShareWorkInSteadyState-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acceptable.recovery.lag = 10000
    	application.id = shouldShareWorkInSteadyStatetestAppId
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:57440]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 5000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	dsl.store.suppliers.class = class org.apache.kafka.streams.state.BuiltInDslStoreSuppliers$RocksDBDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 2000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T/junit215871476961119511
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    [0K[32mâœ”[90m shouldShareWorkInSteadyState()[31m (3.5s)[m

GlobalStreamThreadIntegrationTest STANDARD_ERROR
    Test 15(org.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest): CASSANDRA teardown begins at 1731055619818ms (speed check)

GlobalStreamThreadIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

GlobalStreamThreadIntegrationTest STANDARD_ERROR
    Test 15(org.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest): CASSANDRA teardown ends at 1731055622234ms (duration: PT2.416S) (speed check)
    Test 15(org.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest): CASSANDRA test total runtime=PT24.931S) (speed check)

Gradle Test Executor 2 STANDARD_OUT

Gradle Test Executor 2 finished executing tests.

> Task :kafka-client:test

  [0K[32m42 passing [90m(17m 3s)
  [0K[36m3 pending[m

Finished generating test XML results (0.159 secs) into: /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/test-results/test
Generating HTML test report...
Finished generating test html results (0.344 secs) into: /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/reports/tests/test

BUILD SUCCESSFUL in 17m 29s
16 actionable tasks: 2 executed, 14 up-to-date
Watched directory hierarchies: []
Stopped 1 worker daemon(s).
