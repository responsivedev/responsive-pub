Initialized native services in: /Users/sophie/.gradle/native
Initialized jansi services in: /Users/sophie/.gradle/native
Received JVM installation metadata from '/Users/sophie/Library/Java/JavaVirtualMachines/corretto-17.0.7/Contents/Home': {JAVA_HOME=/Users/sophie/Library/Java/JavaVirtualMachines/corretto-17.0.7/Contents/Home, JAVA_VERSION=17.0.7, JAVA_VENDOR=Amazon.com Inc., RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=17.0.7+7-LTS, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=17.0.7+7-LTS, VM_VENDOR=Amazon.com Inc., OS_ARCH=aarch64}
The client will now receive all logging from the daemon (pid: 90041). The daemon log file: /Users/sophie/.gradle/daemon/8.1.1/daemon-90041.out.log
Starting 10th build in daemon [uptime: 16 mins 23.893 secs, performance: 98%, GC rate: 0.00/s, heap usage: 0% of 512 MiB, non-heap usage: 26% of 384 MiB]
Using 8 worker leases.
Now considering [/Users/sophie/Responsive/responsive-pub-copy, /Users/sophie/Responsive/responsive-pub-copy/buildSrc] as hierarchies to watch
Now considering [/Users/sophie/Responsive/responsive-pub-copy/buildSrc, /Users/sophie/Responsive/responsive-pub-copy] as hierarchies to watch
Watching the file system is configured to be enabled if available
File system watching is active
Starting Build
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration detachedConfiguration2 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration2 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration detachedConfiguration2 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration2 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Settings evaluated using settings file '/Users/sophie/Responsive/responsive-pub-copy/settings.gradle.kts'.
Skipping generation of dependency accessors for libs as it is up-to-date.
Skipping generation of dependency accessors for testlibs as it is up-to-date.
Projects loaded. Root project using build file '/Users/sophie/Responsive/responsive-pub-copy/build.gradle.kts'.
Included projects: [root project 'responsive-pub', project ':controller-api', project ':kafka-client', project ':kafka-client-bootstrap', project ':kafka-client-examples', project ':operator', project ':responsive-spring', project ':responsive-test-utils', project ':tools', project ':kafka-client-examples:e2e-test', project ':kafka-client-examples:simple-example']

> Configure project :buildSrc
Evaluating project ':buildSrc' using build file '/Users/sophie/Responsive/responsive-pub-copy/buildSrc/build.gradle.kts'.
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :buildSrc:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :buildSrc:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :buildSrc:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :buildSrc:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Using Kotlin Gradle Plugin gradle76 variant
kotlin scripting plugin: created the scripting discovery configuration: kotlinScriptDef
kotlin scripting plugin: created the scripting discovery configuration: testKotlinScriptDef
file or directory '/Users/sophie/Responsive/responsive-pub-copy/buildSrc/src/main/java', not found
Caching disabled for Kotlin DSL accessors for project ':buildSrc' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':buildSrc' as it is up-to-date.
The configuration :buildSrc:mainSourceElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Resolve mutations for :buildSrc:generateExternalPluginSpecBuilders (Thread[Execution worker,5,main]) started.
:buildSrc:generateExternalPluginSpecBuilders (Thread[Execution worker Thread 6,5,main]) started.

> Task :buildSrc:generateExternalPluginSpecBuilders UP-TO-DATE
Caching disabled for task ':buildSrc:generateExternalPluginSpecBuilders' because:
  Build cache is disabled
Skipping task ':buildSrc:generateExternalPluginSpecBuilders' as it is up-to-date.
Resolve mutations for :buildSrc:extractPrecompiledScriptPluginPlugins (Thread[Execution worker Thread 6,5,main]) started.
:buildSrc:extractPrecompiledScriptPluginPlugins (Thread[Execution worker Thread 6,5,main]) started.

> Task :buildSrc:extractPrecompiledScriptPluginPlugins UP-TO-DATE
Caching disabled for task ':buildSrc:extractPrecompiledScriptPluginPlugins' because:
  Build cache is disabled
Skipping task ':buildSrc:extractPrecompiledScriptPluginPlugins' as it is up-to-date.
Resolve mutations for :buildSrc:compilePluginsBlocks (Thread[Execution worker Thread 6,5,main]) started.
:buildSrc:compilePluginsBlocks (Thread[Execution worker Thread 6,5,main]) started.

> Task :buildSrc:compilePluginsBlocks UP-TO-DATE
Caching disabled for task ':buildSrc:compilePluginsBlocks' because:
  Build cache is disabled
Skipping task ':buildSrc:compilePluginsBlocks' as it is up-to-date.
Resolve mutations for :buildSrc:generatePrecompiledScriptPluginAccessors (Thread[Execution worker Thread 6,5,main]) started.
:buildSrc:generatePrecompiledScriptPluginAccessors (Thread[Execution worker Thread 6,5,main]) started.

> Task :buildSrc:generatePrecompiledScriptPluginAccessors UP-TO-DATE
Caching disabled for task ':buildSrc:generatePrecompiledScriptPluginAccessors' because:
  Build cache is disabled
Skipping task ':buildSrc:generatePrecompiledScriptPluginAccessors' as it is up-to-date.
Resolve mutations for :buildSrc:generateScriptPluginAdapters (Thread[Execution worker Thread 6,5,main]) started.
:buildSrc:generateScriptPluginAdapters (Thread[Execution worker Thread 6,5,main]) started.

> Task :buildSrc:generateScriptPluginAdapters UP-TO-DATE
Caching disabled for task ':buildSrc:generateScriptPluginAdapters' because:
  Build cache is disabled
Skipping task ':buildSrc:generateScriptPluginAdapters' as it is up-to-date.
Resolve mutations for :buildSrc:compileKotlin (Thread[Execution worker Thread 6,5,main]) started.
:buildSrc:compileKotlin (Thread[Execution worker Thread 4,5,main]) started.

> Task :buildSrc:compileKotlin UP-TO-DATE
Custom actions are attached to task ':buildSrc:compileKotlin'.
Caching disabled for task ':buildSrc:compileKotlin' because:
  Build cache is disabled
Skipping task ':buildSrc:compileKotlin' as it is up-to-date.
Resolve mutations for :buildSrc:compileJava (Thread[Execution worker Thread 4,5,main]) started.
:buildSrc:compileJava (Thread[Execution worker Thread 4,5,main]) started.

> Task :buildSrc:compileJava NO-SOURCE
Skipping task ':buildSrc:compileJava' as it has no source files and no previous output files.
Resolve mutations for :buildSrc:compileGroovy (Thread[Execution worker Thread 4,5,main]) started.
:buildSrc:compileGroovy (Thread[Execution worker Thread 5,5,main]) started.

> Task :buildSrc:compileGroovy NO-SOURCE
Skipping task ':buildSrc:compileGroovy' as it has no source files and no previous output files.
Resolve mutations for :buildSrc:pluginDescriptors (Thread[Execution worker Thread 5,5,main]) started.
:buildSrc:pluginDescriptors (Thread[Execution worker Thread 5,5,main]) started.

> Task :buildSrc:pluginDescriptors UP-TO-DATE
Caching disabled for task ':buildSrc:pluginDescriptors' because:
  Build cache is disabled
  Not worth caching
Skipping task ':buildSrc:pluginDescriptors' as it is up-to-date.
Resolve mutations for :buildSrc:processResources (Thread[Execution worker Thread 5,5,main]) started.
:buildSrc:processResources (Thread[Execution worker Thread 5,5,main]) started.

> Task :buildSrc:processResources UP-TO-DATE
Caching disabled for task ':buildSrc:processResources' because:
  Build cache is disabled
  Not worth caching
Skipping task ':buildSrc:processResources' as it is up-to-date.
Resolve mutations for :buildSrc:classes (Thread[Execution worker Thread 5,5,main]) started.
:buildSrc:classes (Thread[Execution worker Thread 5,5,main]) started.

> Task :buildSrc:classes UP-TO-DATE
Skipping task ':buildSrc:classes' as it has no actions.
Resolve mutations for :buildSrc:jar (Thread[Execution worker Thread 5,5,main]) started.
:buildSrc:jar (Thread[Execution worker Thread 5,5,main]) started.

> Task :buildSrc:jar UP-TO-DATE
Caching disabled for task ':buildSrc:jar' because:
  Build cache is disabled
  Not worth caching
Skipping task ':buildSrc:jar' as it is up-to-date.
Resolve mutations for :buildSrc:inspectClassesForKotlinIC (Thread[Execution worker Thread 5,5,main]) started.
:buildSrc:inspectClassesForKotlinIC (Thread[Execution worker Thread 5,5,main]) started.

> Task :buildSrc:inspectClassesForKotlinIC UP-TO-DATE
Caching disabled for task ':buildSrc:inspectClassesForKotlinIC' because:
  Build cache is disabled
  Caching has been disabled for the task
Skipping task ':buildSrc:inspectClassesForKotlinIC' as it is up-to-date.

> Configure project :
Evaluating root project 'responsive-pub' using build file '/Users/sophie/Responsive/responsive-pub-copy/build.gradle.kts'.
The configuration :classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for root project 'responsive-pub' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for root project 'responsive-pub' as it is up-to-date.

> Configure project :controller-api
Evaluating project ':controller-api' using build file '/Users/sophie/Responsive/responsive-pub-copy/controller-api/build.gradle.kts'.
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :controller-api:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :controller-api:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :controller-api:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :controller-api:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The com.google.protobuf plugin was already applied to the project: :controller-api and will not be applied again after plugin: java-library
Caching disabled for Kotlin DSL accessors for project ':controller-api' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':controller-api' as it is up-to-date.
------------------------------------------------------------------------
Detecting the operating system and CPU architecture
------------------------------------------------------------------------
os.detected.name=osx
os.detected.arch=aarch_64
os.detected.bitness=64
os.detected.version=13.3
os.detected.version.major=13
os.detected.version.minor=3
os.detected.classifier=osx-aarch_64

> Configure project :kafka-client
Evaluating project ':kafka-client' using build file '/Users/sophie/Responsive/responsive-pub-copy/kafka-client/build.gradle.kts'.
The configuration :kafka-client:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':kafka-client' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':kafka-client' as it is up-to-date.

> Configure project :kafka-client-bootstrap
Evaluating project ':kafka-client-bootstrap' using build file '/Users/sophie/Responsive/responsive-pub-copy/kafka-client-bootstrap/build.gradle.kts'.
The configuration :kafka-client-bootstrap:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-bootstrap:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client-bootstrap:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-bootstrap:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':kafka-client-bootstrap' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':kafka-client-bootstrap' as it is up-to-date.

> Configure project :kafka-client-examples
Evaluating project ':kafka-client-examples' using build file '/Users/sophie/Responsive/responsive-pub-copy/kafka-client-examples/build.gradle'.

> Configure project :operator
Evaluating project ':operator' using build file '/Users/sophie/Responsive/responsive-pub-copy/operator/build.gradle.kts'.
The configuration :operator:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :operator:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :operator:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :operator:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':operator' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':operator' as it is up-to-date.

> Configure project :responsive-spring
Evaluating project ':responsive-spring' using build file '/Users/sophie/Responsive/responsive-pub-copy/responsive-spring/build.gradle.kts'.
The configuration :responsive-spring:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :responsive-spring:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :responsive-spring:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :responsive-spring:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':responsive-spring' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':responsive-spring' as it is up-to-date.

> Configure project :responsive-test-utils
Evaluating project ':responsive-test-utils' using build file '/Users/sophie/Responsive/responsive-pub-copy/responsive-test-utils/build.gradle.kts'.
The configuration :responsive-test-utils:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :responsive-test-utils:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :responsive-test-utils:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :responsive-test-utils:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':responsive-test-utils' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':responsive-test-utils' as it is up-to-date.
Starting process 'command '/usr/libexec/java_home''. Working directory: /Users/sophie/.gradle/daemon/8.1.1 Command: /usr/libexec/java_home -V
Successfully started process 'command '/usr/libexec/java_home''

> Configure project :tools
Evaluating project ':tools' using build file '/Users/sophie/Responsive/responsive-pub-copy/tools/build.gradle.kts'.
The configuration :tools:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :tools:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :tools:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :tools:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':tools' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':tools' as it is up-to-date.
The configuration :tools:javadocElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :tools:mainSourceElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :tools:signatures is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :tools:signatures is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :tools:sourcesElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.

> Configure project :kafka-client-examples:e2e-test
Evaluating project ':kafka-client-examples:e2e-test' using build file '/Users/sophie/Responsive/responsive-pub-copy/kafka-client-examples/e2e-test/build.gradle.kts'.
The configuration :kafka-client-examples:e2e-test:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-examples:e2e-test:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client-examples:e2e-test:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-examples:e2e-test:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':kafka-client-examples:e2e-test' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':kafka-client-examples:e2e-test' as it is up-to-date.
Starting process 'command 'git''. Working directory: /Users/sophie/Responsive/responsive-pub-copy Command: git rev-parse --short HEAD
Successfully started process 'command 'git''

> Configure project :kafka-client-examples:simple-example
Evaluating project ':kafka-client-examples:simple-example' using build file '/Users/sophie/Responsive/responsive-pub-copy/kafka-client-examples/simple-example/build.gradle.kts'.
The configuration :kafka-client-examples:simple-example:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-examples:simple-example:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client-examples:simple-example:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-examples:simple-example:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':kafka-client-examples:simple-example' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':kafka-client-examples:simple-example' as it is up-to-date.
All projects evaluated.
Task path 'kafka-client:test' matched project ':kafka-client'
Task name matched 'test'
Selected primary task 'test' from project :kafka-client
The configuration :kafka-client:javadocElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client:mainSourceElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client:signatures is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client:signatures is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client:sourcesElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Tasks to be executed: [task ':kafka-client:writeVersionPropertiesFile', task ':kafka-client:compileJava', task ':kafka-client:processResources', task ':kafka-client:classes', task ':kafka-client:compileTestJava', task ':kafka-client:processTestResources', task ':kafka-client:testClasses', task ':kafka-client:test']
Tasks that were excluded: []
Resolve mutations for :kafka-client:writeVersionPropertiesFile (Thread[Execution worker Thread 2,5,main]) started.
:kafka-client:writeVersionPropertiesFile (Thread[Execution worker Thread 2,5,main]) started.

> Task :kafka-client:writeVersionPropertiesFile UP-TO-DATE
Custom actions are attached to task ':kafka-client:writeVersionPropertiesFile'.
Caching disabled for task ':kafka-client:writeVersionPropertiesFile' because:
  Build cache is disabled
  Gradle would require more information to cache this task
Skipping task ':kafka-client:writeVersionPropertiesFile' as it is up-to-date.
Resolve mutations for :kafka-client:compileJava (Thread[Execution worker Thread 2,5,main]) started.
:kafka-client:compileJava (Thread[Execution worker Thread 2,5,main]) started.

> Task :kafka-client:compileJava UP-TO-DATE
Caching disabled for task ':kafka-client:compileJava' because:
  Build cache is disabled
Skipping task ':kafka-client:compileJava' as it is up-to-date.
Resolve mutations for :kafka-client:processResources (Thread[Execution worker Thread 2,5,main]) started.
:kafka-client:processResources (Thread[Execution worker Thread 2,5,main]) started.

> Task :kafka-client:processResources UP-TO-DATE
Caching disabled for task ':kafka-client:processResources' because:
  Build cache is disabled
  Not worth caching
Skipping task ':kafka-client:processResources' as it is up-to-date.
Resolve mutations for :kafka-client:classes (Thread[Execution worker Thread 2,5,main]) started.
:kafka-client:classes (Thread[Execution worker Thread 2,5,main]) started.

> Task :kafka-client:classes UP-TO-DATE
Skipping task ':kafka-client:classes' as it has no actions.
Resolve mutations for :kafka-client:compileTestJava (Thread[Execution worker Thread 2,5,main]) started.
:kafka-client:compileTestJava (Thread[Execution worker Thread 2,5,main]) started.
This JVM does not support getting OS memory, so no OS memory status updates will be broadcast

> Task :kafka-client:compileTestJava
Caching disabled for task ':kafka-client:compileTestJava' because:
  Build cache is disabled
Task ':kafka-client:compileTestJava' is not up-to-date because:
  Task has failed previously.
The input changes require a full rebuild for incremental task ':kafka-client:compileTestJava'.
Full recompilation is required because no incremental change information is available. This is usually caused by clean builds or changing compiler arguments.
Compiling with toolchain '/Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home'.
Starting process 'Gradle Worker Daemon 3'. Working directory: /Users/sophie/.gradle/workers Command: /Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home/bin/java @/Users/sophie/.gradle/.tmp/gradle-worker-classpath9808110368982609535txt -Xmx512m -Dfile.encoding=UTF-8 -Duser.country=US -Duser.language=en -Duser.variant worker.org.gradle.process.internal.worker.GradleWorkerMain 'Gradle Worker Daemon 3'
Successfully started process 'Gradle Worker Daemon 3'
Started Gradle worker daemon (0.298 secs) with fork options DaemonForkOptions{executable=/Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home/bin/java, minHeapSize=null, maxHeapSize=null, jvmArgs=[], keepAliveMode=SESSION}.
Compiling with JDK Java compiler API.
Class dependency analysis for incremental compilation took 0.045 secs.
Created classpath snapshot for incremental compilation in 0.09 secs.
Resolve mutations for :kafka-client:processTestResources (Thread[Execution worker Thread 2,5,main]) started.
:kafka-client:processTestResources (Thread[Execution worker Thread 2,5,main]) started.

> Task :kafka-client:processTestResources
Caching disabled for task ':kafka-client:processTestResources' because:
  Build cache is disabled
  Not worth caching
Task ':kafka-client:processTestResources' is not up-to-date because:
  Output property 'destinationDir' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/resources/test has been removed.
  Output property 'destinationDir' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/resources/test/CassandraDockerInit.cql has been removed.
  Output property 'destinationDir' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/resources/test/junit-platform.properties has been removed.
  Output property 'destinationDir' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/resources/test/log4j.properties has been removed.
  Output property 'destinationDir' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/resources/test/testcontainers.properties has been removed.
Resolve mutations for :kafka-client:testClasses (Thread[Execution worker Thread 2,5,main]) started.
:kafka-client:testClasses (Thread[Execution worker Thread 2,5,main]) started.

> Task :kafka-client:testClasses
Skipping task ':kafka-client:testClasses' as it has no actions.
Resolve mutations for :kafka-client:test (Thread[Execution worker Thread 2,5,main]) started.
:kafka-client:test (Thread[Execution worker Thread 2,5,main]) started.
Gradle Test Executor 4 started executing tests.

> Task :kafka-client:test
Custom actions are attached to task ':kafka-client:test'.
Caching disabled for task ':kafka-client:test' because:
  Build cache is disabled
Task ':kafka-client:test' is not up-to-date because:
  Output property 'binaryResultsDirectory' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/test-results/test/binary has been removed.
  Output property 'binaryResultsDirectory' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/test-results/test/binary/output.bin has been removed.
  Output property 'binaryResultsDirectory' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/test-results/test/binary/output.bin.idx has been removed.
  Output property 'binaryResultsDirectory' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/test-results/test/binary/results.bin has been removed.
  Output property 'reports.enabledReports.html.outputLocation' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/reports/tests/test has been removed.

Starting process 'Gradle Test Executor 4'. Working directory: /Users/sophie/Responsive/responsive-pub-copy/kafka-client Command: /Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home/bin/java -Dorg.gradle.internal.worker.tmpdir=/Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/tmp/test/work -Dorg.gradle.native=false @/Users/sophie/.gradle/.tmp/gradle-worker-classpath11800732997431402346txt -Xmx512m -Dfile.encoding=UTF-8 -Duser.country=US -Duser.language=en -Duser.variant -ea worker.org.gradle.process.internal.worker.GradleWorkerMain 'Gradle Test Executor 4'
Successfully started process 'Gradle Test Executor 4'

Gradle Test Executor 4 STANDARD_OUT

Gradle Test Executor 4 STANDARD_ERROR
    Test 1: creating ResponsiveExtension(backend=CASSANDRA) at 1731118687349ms (speed check)

AsyncProcessorIntegrationTest STANDARD_ERROR
    Test 1(dev.responsive.kafka.async.AsyncProcessorIntegrationTest): CASSANDRA setup begins at 1731118687360ms (speed check)

AsyncProcessorIntegrationTest STANDARD_OUT
      Server Version: 23.0.5
      API Version: 1.42
      Operating System: Docker Desktop
      Total Memory: 3933 MB (org.testcontainers.DockerClientFactory:205)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

AsyncProcessorIntegrationTest STANDARD_ERROR
    Test 1(dev.responsive.kafka.async.AsyncProcessorIntegrationTest): CASSANDRA setup ends at 1731118718183ms (duration: PT30.823S) (speed check)

AsyncProcessorIntegrationTest > shouldProcessStatefulEventsInOrderByKey() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-1
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InputRecordSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 5
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 56947
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 9223372036854775807
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldProcessStatefulEventsInOrderByKey
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 30000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 4
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatefulEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-2-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-2-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-2
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-2-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatefulEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-3-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-3-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-3
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-3-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatefulEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-4-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-4-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-4
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-4-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatefulEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    a571c833-445a-456c-a2fc-704321026e66: [shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-1-consumer-e4fa289b-bae0-41e4-bdd2-b8d6628e5108, shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-2-consumer-c09c3b95-e7c9-44d0-acbc-e552b765f760, shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-3-consumer-a231a78a-7ede-48d7-9b4c-6efc6b4515cc, shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-4-consumer-7d969556-126f-4c2f-b2f9-e8704159f218]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-1-consumer-e4fa289b-bae0-41e4-bdd2-b8d6628e5108=[], shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-2-consumer-c09c3b95-e7c9-44d0-acbc-e552b765f760=[], shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-3-consumer-a231a78a-7ede-48d7-9b4c-6efc6b4515cc=[], shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-4-consumer-7d969556-126f-4c2f-b2f9-e8704159f218=[]}
    	assigned active {shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-1-consumer-e4fa289b-bae0-41e4-bdd2-b8d6628e5108=[0_8, 0_4, 0_0], shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-2-consumer-c09c3b95-e7c9-44d0-acbc-e552b765f760=[0_9, 0_5, 0_1], shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-3-consumer-a231a78a-7ede-48d7-9b4c-6efc6b4515cc=[0_10, 0_6, 0_2], shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-4-consumer-7d969556-126f-4c2f-b2f9-e8704159f218=[0_11, 0_7, 0_3]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-3, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-7, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-11]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-3, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-7, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-11]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-0, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-4, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-0, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-4, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-1, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-5, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-9]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-1, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-5, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-9]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-2, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-6, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-10]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-2, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-6, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-10]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput, partition=8, offset=6, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput, partition=8, offset=6, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-5-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-5-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-5
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-5-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatefulEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.ProcessorStateException: stream-thread [shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-1] stream-task [0_8] Failed to flush cache of store shouldProcessStatefulEventsInOrderByKeya1
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:546)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent. (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:322)
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent. (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:322)
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent. (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:322)
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldProcessStatefulEventsInOrderByKey-shouldProcessStatefulEventsInOrderByKeya1-changelog for task 0_4 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:314)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.abort(ProducerBatch.java:200)
    	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortUndrainedBatches(RecordAccumulator.java:1160)
    	at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:473)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:337)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldProcessStatefulEventsInOrderByKey-shouldProcessStatefulEventsInOrderByKeya1-changelog for task 0_4 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.flushPendingEventsForCommit(AsyncProcessor.java:433)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPoolRegistration.lambda$flushAllAsyncEvents$1(AsyncThreadPoolRegistration.java:60)
    	at java.base/java.util.HashMap$Values.forEach(HashMap.java:977)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPoolRegistration.flushAllAsyncEvents(AsyncThreadPoolRegistration.java:57)
    	at dev.responsive.kafka.api.async.internals.stores.AsyncFlushingKeyValueStore.flushCache(AsyncFlushingKeyValueStore.java:102)
    	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:87)
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:536)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldProcessStatefulEventsInOrderByKey-shouldProcessStatefulEventsInOrderByKeya1-changelog for task 0_4 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:314)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.abort(ProducerBatch.java:200)
    	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortUndrainedBatches(RecordAccumulator.java:1160)
    	at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:473)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:337)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    org.apache.kafka.streams.errors.ProcessorStateException: stream-thread [shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-1] stream-task [0_4] Failed to flush cache of store shouldProcessStatefulEventsInOrderByKeya1
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:546)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldProcessStatefulEventsInOrderByKey-shouldProcessStatefulEventsInOrderByKeya1-changelog for task 0_4 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.flushPendingEventsForCommit(AsyncProcessor.java:433)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPoolRegistration.lambda$flushAllAsyncEvents$1(AsyncThreadPoolRegistration.java:60)
    	at java.base/java.util.HashMap$Values.forEach(HashMap.java:977)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPoolRegistration.flushAllAsyncEvents(AsyncThreadPoolRegistration.java:57)
    	at dev.responsive.kafka.api.async.internals.stores.AsyncFlushingKeyValueStore.flushCache(AsyncFlushingKeyValueStore.java:102)
    	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:87)
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:536)
    	... 9 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldProcessStatefulEventsInOrderByKey-shouldProcessStatefulEventsInOrderByKeya1-changelog for task 0_4 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:314)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.abort(ProducerBatch.java:200)
    	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortUndrainedBatches(RecordAccumulator.java:1160)
    	at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:473)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:337)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldProcessStatefulEventsInOrderByKey-shouldProcessStatefulEventsInOrderByKeyout-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:314)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.abort(ProducerBatch.java:200)
    	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortUndrainedBatches(RecordAccumulator.java:1160)
    	at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:473)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:337)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldProcessStatefulEventsInOrderByKey-shouldProcessStatefulEventsInOrderByKeyout-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.flushPendingEventsForCommit(AsyncProcessor.java:433)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPoolRegistration.lambda$flushAllAsyncEvents$1(AsyncThreadPoolRegistration.java:60)
    	at java.base/java.util.HashMap$Values.forEach(HashMap.java:977)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPoolRegistration.flushAllAsyncEvents(AsyncThreadPoolRegistration.java:57)
    	at dev.responsive.kafka.api.async.internals.stores.AsyncFlushingKeyValueStore.flushCache(AsyncFlushingKeyValueStore.java:102)
    	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:87)
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:536)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldProcessStatefulEventsInOrderByKey-shouldProcessStatefulEventsInOrderByKeyout-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:314)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.abort(ProducerBatch.java:200)
    	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortUndrainedBatches(RecordAccumulator.java:1160)
    	at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:473)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:337)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    org.apache.kafka.streams.errors.ProcessorStateException: stream-thread [shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-1] stream-task [0_0] Failed to flush cache of store shouldProcessStatefulEventsInOrderByKeya1
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:546)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldProcessStatefulEventsInOrderByKey-shouldProcessStatefulEventsInOrderByKeyout-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.flushPendingEventsForCommit(AsyncProcessor.java:433)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPoolRegistration.lambda$flushAllAsyncEvents$1(AsyncThreadPoolRegistration.java:60)
    	at java.base/java.util.HashMap$Values.forEach(HashMap.java:977)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPoolRegistration.flushAllAsyncEvents(AsyncThreadPoolRegistration.java:57)
    	at dev.responsive.kafka.api.async.internals.stores.AsyncFlushingKeyValueStore.flushCache(AsyncFlushingKeyValueStore.java:102)
    	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:87)
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:536)
    	... 9 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldProcessStatefulEventsInOrderByKey-shouldProcessStatefulEventsInOrderByKeyout-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:314)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.abort(ProducerBatch.java:200)
    	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortUndrainedBatches(RecordAccumulator.java:1160)
    	at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:473)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:337)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    a571c833-445a-456c-a2fc-704321026e66: [shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-2-consumer-c09c3b95-e7c9-44d0-acbc-e552b765f760, shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-3-consumer-a231a78a-7ede-48d7-9b4c-6efc6b4515cc, shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-4-consumer-7d969556-126f-4c2f-b2f9-e8704159f218, shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-5-consumer-58ac6a41-3c34-4c6d-9109-aa10a43a71bc]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-2-consumer-c09c3b95-e7c9-44d0-acbc-e552b765f760=[0_9, 0_5, 0_1], shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-3-consumer-a231a78a-7ede-48d7-9b4c-6efc6b4515cc=[0_10, 0_6, 0_2], shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-4-consumer-7d969556-126f-4c2f-b2f9-e8704159f218=[0_11, 0_7, 0_3]}
    	prev owned standby {shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-2-consumer-c09c3b95-e7c9-44d0-acbc-e552b765f760=[], shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-3-consumer-a231a78a-7ede-48d7-9b4c-6efc6b4515cc=[], shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-4-consumer-7d969556-126f-4c2f-b2f9-e8704159f218=[], shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-5-consumer-58ac6a41-3c34-4c6d-9109-aa10a43a71bc=[]}
    	assigned active {shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-2-consumer-c09c3b95-e7c9-44d0-acbc-e552b765f760=[0_9, 0_5, 0_1], shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-3-consumer-a231a78a-7ede-48d7-9b4c-6efc6b4515cc=[0_10, 0_6, 0_2], shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-4-consumer-7d969556-126f-4c2f-b2f9-e8704159f218=[0_11, 0_7, 0_3], shouldProcessStatefulEventsInOrderByKey-a571c833-445a-456c-a2fc-704321026e66-StreamThread-5-consumer-58ac6a41-3c34-4c6d-9109-aa10a43a71bc=[0_8, 0_4, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-3, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-7, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-11]
    	Current owned partitions:                  [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-3, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-7, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-11]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: [0_11, 0_7, 0_3]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-0, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-4, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-0, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-4, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-1, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-5, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-9]
    	Current owned partitions:                  [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-1, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-5, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-9]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-2, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-6, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-10]
    	Current owned partitions:                  [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-2, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-6, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-10]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: [0_10, 0_6, 0_2]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: [0_9, 0_5, 0_1]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-1
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
  [0K[39mdev.responsive.kafka.async.AsyncProcessorIntegrationTest[m

    [0K[32mâœ”[90m shouldProcessStatefulEventsInOrderByKey()[31m (51.6s)[m

AsyncProcessorIntegrationTest > shouldProcessStatelessEventsInOrderByKey() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-2
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InputRecordSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 5
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 56947
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 9223372036854775807
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldProcessStatelessEventsInOrderByKey
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 30000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 4
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatelessEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-2-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-2-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-2
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-2-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatelessEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-3-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-3-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-3
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-3-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatelessEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-4-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-4-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-4
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-4-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatelessEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    0952f12e-99d3-431e-bcf3-39c629e98187: [shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-1-consumer-765f14a4-dbb8-4741-ad1c-053ec112e8ed, shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-2-consumer-e0731498-f9a5-481d-b4f5-280a01cd8808, shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-4-consumer-2ffc5db2-37c0-486c-9754-21107140c75d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-1-consumer-765f14a4-dbb8-4741-ad1c-053ec112e8ed=[], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-2-consumer-e0731498-f9a5-481d-b4f5-280a01cd8808=[], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-4-consumer-2ffc5db2-37c0-486c-9754-21107140c75d=[]}
    	assigned active {shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-1-consumer-765f14a4-dbb8-4741-ad1c-053ec112e8ed=[0_9, 0_6, 0_3, 0_0], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-2-consumer-e0731498-f9a5-481d-b4f5-280a01cd8808=[0_10, 0_7, 0_4, 0_1], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-4-consumer-2ffc5db2-37c0-486c-9754-21107140c75d=[0_11, 0_8, 0_5, 0_2]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    0952f12e-99d3-431e-bcf3-39c629e98187: [shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-1-consumer-765f14a4-dbb8-4741-ad1c-053ec112e8ed, shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-2-consumer-e0731498-f9a5-481d-b4f5-280a01cd8808, shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-3-consumer-963f01e5-a256-4788-b94e-2c13fa43a0df, shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-4-consumer-2ffc5db2-37c0-486c-9754-21107140c75d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-1-consumer-765f14a4-dbb8-4741-ad1c-053ec112e8ed=[], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-2-consumer-e0731498-f9a5-481d-b4f5-280a01cd8808=[], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-3-consumer-963f01e5-a256-4788-b94e-2c13fa43a0df=[], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-4-consumer-2ffc5db2-37c0-486c-9754-21107140c75d=[]}
    	assigned active {shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-1-consumer-765f14a4-dbb8-4741-ad1c-053ec112e8ed=[0_8, 0_4, 0_0], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-2-consumer-e0731498-f9a5-481d-b4f5-280a01cd8808=[0_9, 0_5, 0_1], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-3-consumer-963f01e5-a256-4788-b94e-2c13fa43a0df=[0_10, 0_6, 0_2], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-4-consumer-2ffc5db2-37c0-486c-9754-21107140c75d=[0_11, 0_7, 0_3]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-3, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-7, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-11]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-3, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-7, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-11]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-0, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-4, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-0, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-4, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-2, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-6, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-10]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-2, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-6, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-10]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-1, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-5, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-9]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-1, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-5, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-9]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput, partition=8, offset=4, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatelessAsyncProcessor(AsyncProcessorIntegrationTest.java:675)
    	at dev.responsive.kafka.testutils.SimpleStatelessProcessorSupplier$SimpleStatelessProcessor.process(SimpleStatelessProcessorSupplier.java:65)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatelessAsyncProcessor(AsyncProcessorIntegrationTest.java:675)
    	at dev.responsive.kafka.testutils.SimpleStatelessProcessorSupplier$SimpleStatelessProcessor.process(SimpleStatelessProcessorSupplier.java:65)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput, partition=8, offset=4, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatelessAsyncProcessor(AsyncProcessorIntegrationTest.java:675)
    	at dev.responsive.kafka.testutils.SimpleStatelessProcessorSupplier$SimpleStatelessProcessor.process(SimpleStatelessProcessorSupplier.java:65)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatelessAsyncProcessor(AsyncProcessorIntegrationTest.java:675)
    	at dev.responsive.kafka.testutils.SimpleStatelessProcessorSupplier$SimpleStatelessProcessor.process(SimpleStatelessProcessorSupplier.java:65)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-5-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-5-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-5
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-5-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatelessEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    0952f12e-99d3-431e-bcf3-39c629e98187: [shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-2-consumer-e0731498-f9a5-481d-b4f5-280a01cd8808, shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-3-consumer-963f01e5-a256-4788-b94e-2c13fa43a0df, shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-4-consumer-2ffc5db2-37c0-486c-9754-21107140c75d, shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-5-consumer-408bb65a-0437-42a4-a68b-38d06da52035]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-2-consumer-e0731498-f9a5-481d-b4f5-280a01cd8808=[0_9, 0_5, 0_1], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-3-consumer-963f01e5-a256-4788-b94e-2c13fa43a0df=[0_10, 0_6, 0_2], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-4-consumer-2ffc5db2-37c0-486c-9754-21107140c75d=[0_11, 0_7, 0_3]}
    	prev owned standby {shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-2-consumer-e0731498-f9a5-481d-b4f5-280a01cd8808=[], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-3-consumer-963f01e5-a256-4788-b94e-2c13fa43a0df=[], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-4-consumer-2ffc5db2-37c0-486c-9754-21107140c75d=[], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-5-consumer-408bb65a-0437-42a4-a68b-38d06da52035=[]}
    	assigned active {shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-2-consumer-e0731498-f9a5-481d-b4f5-280a01cd8808=[0_9, 0_5, 0_1], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-3-consumer-963f01e5-a256-4788-b94e-2c13fa43a0df=[0_10, 0_6, 0_2], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-4-consumer-2ffc5db2-37c0-486c-9754-21107140c75d=[0_11, 0_7, 0_3], shouldProcessStatelessEventsInOrderByKey-0952f12e-99d3-431e-bcf3-39c629e98187-StreamThread-5-consumer-408bb65a-0437-42a4-a68b-38d06da52035=[0_8, 0_4, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-3, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-7, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-11]
    	Current owned partitions:                  [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-3, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-7, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-11]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-1, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-5, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-9]
    	Current owned partitions:                  [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-1, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-5, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-9]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-2, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-6, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-10]
    	Current owned partitions:                  [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-2, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-6, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-10]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: [0_9, 0_5, 0_1]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: [0_10, 0_6, 0_2]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: [0_11, 0_7, 0_3]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-0, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-4, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-0, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-4, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-2
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    [0K[32mâœ”[90m shouldProcessStatelessEventsInOrderByKey()[31m (41.1s)[m

AsyncProcessorIntegrationTest > shouldExecuteMultipleMixedAsyncProcessorsNoCaching() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-3
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InputRecordSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 5
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 56947
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 9223372036854775807
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 30000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 4
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-2-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-2-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-2
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-2-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-3-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-3-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-3
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-3-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-4-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-4-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-4
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-4-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    ac8f5ad3-6cfd-4f95-8ac6-387362de51b3: [shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-1-consumer-2deb5737-6890-4498-95d2-d93deaecb918, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-2-consumer-8561301e-17c5-4a80-be0d-c318702b78fb, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-3-consumer-35c7fb00-3e3f-4580-9073-2b3650e0c21a, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-4-consumer-d0ae40d6-9434-4d6f-ab50-09285f41579f]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-1-consumer-2deb5737-6890-4498-95d2-d93deaecb918=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-2-consumer-8561301e-17c5-4a80-be0d-c318702b78fb=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-3-consumer-35c7fb00-3e3f-4580-9073-2b3650e0c21a=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-4-consumer-d0ae40d6-9434-4d6f-ab50-09285f41579f=[]}
    	assigned active {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-1-consumer-2deb5737-6890-4498-95d2-d93deaecb918=[0_8, 0_4, 0_0], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-2-consumer-8561301e-17c5-4a80-be0d-c318702b78fb=[0_9, 0_5, 0_1], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-3-consumer-35c7fb00-3e3f-4580-9073-2b3650e0c21a=[0_10, 0_6, 0_2], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-4-consumer-d0ae40d6-9434-4d6f-ab50-09285f41579f=[0_11, 0_7, 0_3]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-0, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-4, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-0, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-4, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-1, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-5, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-9]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-1, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-5, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-9]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-3, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-7, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-11]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-3, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-7, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-11]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-2, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-6, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-10]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-2, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-6, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-10]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-3
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput, partition=8, offset=6, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput, partition=8, offset=6, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-5-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-5-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-5
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-5-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.ProcessorStateException: stream-thread [shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-1] stream-task [0_4] Failed to flush cache of store shouldExecuteMultipleMixedAsyncProcessorsNoCachinga1
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:546)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent. (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:322)
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent. (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:322)
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent. (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:322)
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.ProcessorStateException: stream-thread [shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-1] stream-task [0_8] Failed to flush cache of store shouldExecuteMultipleMixedAsyncProcessorsNoCachinga1
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:546)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldExecuteMultipleMixedAsyncProcessorsNoCaching-shouldExecuteMultipleMixedAsyncProcessorsNoCachinga1-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:314)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.abort(ProducerBatch.java:200)
    	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortUndrainedBatches(RecordAccumulator.java:1160)
    	at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:473)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:337)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldExecuteMultipleMixedAsyncProcessorsNoCaching-shouldExecuteMultipleMixedAsyncProcessorsNoCachinga1-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.flushPendingEventsForCommit(AsyncProcessor.java:433)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPoolRegistration.lambda$flushAllAsyncEvents$1(AsyncThreadPoolRegistration.java:60)
    	at java.base/java.util.HashMap$Values.forEach(HashMap.java:977)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPoolRegistration.flushAllAsyncEvents(AsyncThreadPoolRegistration.java:57)
    	at dev.responsive.kafka.api.async.internals.stores.AsyncFlushingKeyValueStore.flushCache(AsyncFlushingKeyValueStore.java:102)
    	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:87)
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:536)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldExecuteMultipleMixedAsyncProcessorsNoCaching-shouldExecuteMultipleMixedAsyncProcessorsNoCachinga1-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:314)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.abort(ProducerBatch.java:200)
    	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortUndrainedBatches(RecordAccumulator.java:1160)
    	at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:473)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:337)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldExecuteMultipleMixedAsyncProcessorsNoCaching-shouldExecuteMultipleMixedAsyncProcessorsNoCachinga1-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.flushPendingEventsForCommit(AsyncProcessor.java:433)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPoolRegistration.lambda$flushAllAsyncEvents$1(AsyncThreadPoolRegistration.java:60)
    	at java.base/java.util.HashMap$Values.forEach(HashMap.java:977)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPoolRegistration.flushAllAsyncEvents(AsyncThreadPoolRegistration.java:57)
    	at dev.responsive.kafka.api.async.internals.stores.AsyncFlushingKeyValueStore.flushCache(AsyncFlushingKeyValueStore.java:102)
    	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:87)
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:536)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldExecuteMultipleMixedAsyncProcessorsNoCaching-shouldExecuteMultipleMixedAsyncProcessorsNoCachinga1-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:314)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.abort(ProducerBatch.java:200)
    	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortUndrainedBatches(RecordAccumulator.java:1160)
    	at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:473)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:337)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldExecuteMultipleMixedAsyncProcessorsNoCaching-shouldExecuteMultipleMixedAsyncProcessorsNoCachinga1-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.flushPendingEventsForCommit(AsyncProcessor.java:433)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPoolRegistration.lambda$flushAllAsyncEvents$1(AsyncThreadPoolRegistration.java:60)
    	at java.base/java.util.HashMap$Values.forEach(HashMap.java:977)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPoolRegistration.flushAllAsyncEvents(AsyncThreadPoolRegistration.java:57)
    	at dev.responsive.kafka.api.async.internals.stores.AsyncFlushingKeyValueStore.flushCache(AsyncFlushingKeyValueStore.java:102)
    	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:87)
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:536)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldExecuteMultipleMixedAsyncProcessorsNoCaching-shouldExecuteMultipleMixedAsyncProcessorsNoCachinga1-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:314)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.abort(ProducerBatch.java:200)
    	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortUndrainedBatches(RecordAccumulator.java:1160)
    	at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:473)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:337)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    org.apache.kafka.streams.errors.ProcessorStateException: stream-thread [shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-1] stream-task [0_0] Failed to flush cache of store shouldExecuteMultipleMixedAsyncProcessorsNoCachinga1
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:546)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldExecuteMultipleMixedAsyncProcessorsNoCaching-shouldExecuteMultipleMixedAsyncProcessorsNoCachinga1-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.flushPendingEventsForCommit(AsyncProcessor.java:433)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPoolRegistration.lambda$flushAllAsyncEvents$1(AsyncThreadPoolRegistration.java:60)
    	at java.base/java.util.HashMap$Values.forEach(HashMap.java:977)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPoolRegistration.flushAllAsyncEvents(AsyncThreadPoolRegistration.java:57)
    	at dev.responsive.kafka.api.async.internals.stores.AsyncFlushingKeyValueStore.flushCache(AsyncFlushingKeyValueStore.java:102)
    	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:87)
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:536)
    	... 9 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldExecuteMultipleMixedAsyncProcessorsNoCaching-shouldExecuteMultipleMixedAsyncProcessorsNoCachinga1-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:314)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.abort(ProducerBatch.java:200)
    	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortUndrainedBatches(RecordAccumulator.java:1160)
    	at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:473)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:337)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    ac8f5ad3-6cfd-4f95-8ac6-387362de51b3: [shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-2-consumer-8561301e-17c5-4a80-be0d-c318702b78fb, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-3-consumer-35c7fb00-3e3f-4580-9073-2b3650e0c21a, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-4-consumer-d0ae40d6-9434-4d6f-ab50-09285f41579f, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-5-consumer-34f4d559-4fa8-4b99-8150-fc52265e739c]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-2-consumer-8561301e-17c5-4a80-be0d-c318702b78fb=[0_9, 0_5, 0_1], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-3-consumer-35c7fb00-3e3f-4580-9073-2b3650e0c21a=[0_10, 0_6, 0_2], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-4-consumer-d0ae40d6-9434-4d6f-ab50-09285f41579f=[0_11, 0_7, 0_3]}
    	prev owned standby {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-2-consumer-8561301e-17c5-4a80-be0d-c318702b78fb=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-3-consumer-35c7fb00-3e3f-4580-9073-2b3650e0c21a=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-4-consumer-d0ae40d6-9434-4d6f-ab50-09285f41579f=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-5-consumer-34f4d559-4fa8-4b99-8150-fc52265e739c=[]}
    	assigned active {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-2-consumer-8561301e-17c5-4a80-be0d-c318702b78fb=[0_9, 0_5, 0_1], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-3-consumer-35c7fb00-3e3f-4580-9073-2b3650e0c21a=[0_10, 0_6, 0_2], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-4-consumer-d0ae40d6-9434-4d6f-ab50-09285f41579f=[0_11, 0_7, 0_3], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-ac8f5ad3-6cfd-4f95-8ac6-387362de51b3-StreamThread-5-consumer-34f4d559-4fa8-4b99-8150-fc52265e739c=[0_8, 0_4, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-2, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-6, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-10]
    	Current owned partitions:                  [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-2, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-6, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-10]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-3, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-7, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-11]
    	Current owned partitions:                  [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-3, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-7, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-11]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-0, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-4, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-0, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-4, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-1, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-5, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-9]
    	Current owned partitions:                  [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-1, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-5, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-9]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: [0_9, 0_5, 0_1]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: [0_11, 0_7, 0_3]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: [0_10, 0_6, 0_2]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    [0K[32mâœ”[90m shouldExecuteMultipleMixedAsyncProcessorsNoCaching()[31m (43.4s)[m

AsyncProcessorIntegrationTest > shouldThrowIfStoresNotConnectedCorrectly() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 5
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 56947
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 9223372036854775807
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldThrowIfStoresNotConnectedCorrectly
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 30000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 4
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldThrowIfStoresNotConnectedCorrectly
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-2-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-2-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-2
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-2-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldThrowIfStoresNotConnectedCorrectly
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-3-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-3-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-3
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-3-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldThrowIfStoresNotConnectedCorrectly
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-4-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-4-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-4
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:56965]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-4-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldThrowIfStoresNotConnectedCorrectly
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    c4896462-357a-4b8e-9791-dc29a73b885d: [shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-3-consumer-61c96f85-4013-4148-b374-ce544801e458]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-3-consumer-61c96f85-4013-4148-b374-ce544801e458=[]}
    	assigned active {shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-3-consumer-61c96f85-4013-4148-b374-ce544801e458=[0_11, 0_10, 0_9, 0_8, 0_7, 0_6, 0_5, 0_4, 0_3, 0_2, 0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    c4896462-357a-4b8e-9791-dc29a73b885d: [shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-1-consumer-a4d90e7b-22c5-4fb4-a6e6-51bce56d30a0, shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-2-consumer-dbba5a23-ade2-4546-9b23-468b2575c790, shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-3-consumer-61c96f85-4013-4148-b374-ce544801e458, shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-4-consumer-a5ce8974-e6de-4c9b-a2fb-1f5c21e383f4]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-1-consumer-a4d90e7b-22c5-4fb4-a6e6-51bce56d30a0=[], shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-2-consumer-dbba5a23-ade2-4546-9b23-468b2575c790=[], shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-3-consumer-61c96f85-4013-4148-b374-ce544801e458=[], shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-4-consumer-a5ce8974-e6de-4c9b-a2fb-1f5c21e383f4=[]}
    	assigned active {shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-1-consumer-a4d90e7b-22c5-4fb4-a6e6-51bce56d30a0=[0_8, 0_4, 0_0], shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-2-consumer-dbba5a23-ade2-4546-9b23-468b2575c790=[0_9, 0_5, 0_1], shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-3-consumer-61c96f85-4013-4148-b374-ce544801e458=[0_10, 0_6, 0_2], shouldThrowIfStoresNotConnectedCorrectly-c4896462-357a-4b8e-9791-dc29a73b885d-StreamThread-4-consumer-a5ce8974-e6de-4c9b-a2fb-1f5c21e383f4=[0_11, 0_7, 0_3]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-1, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-5, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-9]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-1, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-5, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-9]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-2, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-6, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-10]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-2, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-6, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-10]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-0, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-4, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-0, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-4, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-3, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-7, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-11]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-3, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-7, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-11]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.streams.errors.StreamsException: failed to initialize processor AsyncProcessor
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.init(ProcessorNode.java:110)
    	at org.apache.kafka.streams.processor.internals.StreamTask.initializeTopology(StreamTask.java:1023)
    	at org.apache.kafka.streams.processor.internals.StreamTask.completeRestoration(StreamTask.java:287)
    	at org.apache.kafka.streams.processor.internals.TaskManager.tryToCompleteRestoration(TaskManager.java:752)
    	at org.apache.kafka.streams.processor.internals.StreamThread.initializeAndRestorePhase(StreamThread.java:1117)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:921)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: java.lang.IllegalStateException: Processor initialized some stores that were not connected via the ProcessorSupplier, please connect stores for async processors by implementing the ProcessorSupplier#storesNames method
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.verifyConnectedStateStores(AsyncProcessor.java:756)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.completeInitialization(AsyncProcessor.java:251)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.init(AsyncProcessor.java:177)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.init(ProcessorNode.java:107)
    	... 7 more
    org.apache.kafka.streams.errors.StreamsException: failed to initialize processor AsyncProcessor
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.init(ProcessorNode.java:110)
    	at org.apache.kafka.streams.processor.internals.StreamTask.initializeTopology(StreamTask.java:1023)
    	at org.apache.kafka.streams.processor.internals.StreamTask.completeRestoration(StreamTask.java:287)
    	at org.apache.kafka.streams.processor.internals.TaskManager.tryToCompleteRestoration(TaskManager.java:752)
    	at org.apache.kafka.streams.processor.internals.StreamThread.initializeAndRestorePhase(StreamThread.java:1117)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:921)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: java.lang.IllegalStateException: Processor initialized some stores that were not connected via the ProcessorSupplier, please connect stores for async processors by implementing the ProcessorSupplier#storesNames method
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.verifyConnectedStateStores(AsyncProcessor.java:756)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.completeInitialization(AsyncProcessor.java:251)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.init(AsyncProcessor.java:177)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.init(ProcessorNode.java:107)
    	... 7 more
    [0K[32mâœ”[90m shouldThrowIfStoresNotConnectedCorrectly()[31m (6.5s)[m

AsyncProcessorIntegrationTest STANDARD_ERROR
    Test 1(dev.responsive.kafka.async.AsyncProcessorIntegrationTest): CASSANDRA teardown begins at 1731118860969ms (speed check)

AsyncProcessorIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

AsyncProcessorIntegrationTest STANDARD_ERROR
    Test 1(dev.responsive.kafka.async.AsyncProcessorIntegrationTest): CASSANDRA teardown ends at 1731118864758ms (duration: PT3.789S) (speed check)
    Test 1(dev.responsive.kafka.async.AsyncProcessorIntegrationTest): CASSANDRA test total runtime=PT2M57.409S) (speed check)

Gradle Test Executor 4 STANDARD_ERROR
    Test 2: creating ResponsiveExtension(backend=CASSANDRA) at 1731118864760ms (speed check)

  [0K[39mdev.responsive.kafka.bootstrap.ChangelogMigrationToolIntegrationTest[m

    [0K[36m- testFactStore()[m

ChangelogMigrationToolIntegrationTest > testFactStore() SKIPPED
    [0K[36m- test()[m

ChangelogMigrationToolIntegrationTest > test() SKIPPED

Gradle Test Executor 4 STANDARD_ERROR
    Test 2: creating ResponsiveExtension(empty) at 1731118864763ms (speed check)

GlobalStoreIntegrationTest STANDARD_ERROR
    Test 2(dev.responsive.kafka.integration.GlobalStoreIntegrationTest): CASSANDRA setup begins at 1731118864764ms (speed check)

GlobalStoreIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57282]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

GlobalStoreIntegrationTest STANDARD_ERROR
    Test 2(dev.responsive.kafka.integration.GlobalStoreIntegrationTest): CASSANDRA setup ends at 1731118881954ms (duration: PT17.19S) (speed check)

GlobalStoreIntegrationTest > shouldUseGlobalTable() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57282]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-4
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 57241
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57282]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldUseGlobalTable
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:57282]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 0
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57282]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-383b9a13-ca39-49df-bd0b-626102c7186b-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57282]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-383b9a13-ca39-49df-bd0b-626102c7186b-global-consumer
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57282]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-383b9a13-ca39-49df-bd0b-626102c7186b-global-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldUseGlobalTable-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57282]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-383b9a13-ca39-49df-bd0b-626102c7186b-global-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldUseGlobalTable-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:57282]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-383b9a13-ca39-49df-bd0b-626102c7186b-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57282]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57282]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-383b9a13-ca39-49df-bd0b-626102c7186b-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57282]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-383b9a13-ca39-49df-bd0b-626102c7186b-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldUseGlobalTable
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    383b9a13-ca39-49df-bd0b-626102c7186b: [shouldUseGlobalTable-383b9a13-ca39-49df-bd0b-626102c7186b-StreamThread-1-consumer-0ea1a849-30e7-439c-90de-a4782039e130]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [1_0, 1_1] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldUseGlobalTable-383b9a13-ca39-49df-bd0b-626102c7186b-StreamThread-1-consumer-0ea1a849-30e7-439c-90de-a4782039e130=[]}
    	assigned active {shouldUseGlobalTable-383b9a13-ca39-49df-bd0b-626102c7186b-StreamThread-1-consumer-0ea1a849-30e7-439c-90de-a4782039e130=[1_0, 1_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [input-0, input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [input-0, input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 1_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:57282]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-4
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.GlobalStoreIntegrationTest[m

    [0K[32mâœ”[90m shouldUseGlobalTable()[31m (7.4s)[m

GlobalStoreIntegrationTest STANDARD_ERROR
    Test 2(dev.responsive.kafka.integration.GlobalStoreIntegrationTest): CASSANDRA teardown begins at 1731118889376ms (speed check)

GlobalStoreIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

GlobalStoreIntegrationTest STANDARD_ERROR
    Test 2(dev.responsive.kafka.integration.GlobalStoreIntegrationTest): CASSANDRA teardown ends at 1731118892313ms (duration: PT2.937S) (speed check)
    Test 2(dev.responsive.kafka.integration.GlobalStoreIntegrationTest): CASSANDRA test total runtime=PT27.55S) (speed check)

Gradle Test Executor 4 STANDARD_ERROR
    Test 3: creating ResponsiveExtension(backend=MONGO_DB) at 1731118892316ms (speed check)

  [0K[39mdev.responsive.kafka.integration.MinimalIntegrationTest[m

    [0K[36m- test()[m

MinimalIntegrationTest > test() SKIPPED

Gradle Test Executor 4 STANDARD_ERROR
    Test 3: creating ResponsiveExtension(backend=MONGO_DB) at 1731118892320ms (speed check)

ResponsiveForeignKeyJoinIntegrationTest STANDARD_ERROR
    Test 3(dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest): MONGO_DB setup begins at 1731118892322ms (speed check)

ResponsiveForeignKeyJoinIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

ResponsiveForeignKeyJoinIntegrationTest STANDARD_ERROR
    Test 3(dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest): MONGO_DB setup ends at 1731118902379ms (duration: PT10.057S) (speed check)

ResponsiveForeignKeyJoinIntegrationTest > shouldComputeForeignKeyJoinsCorrectly() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-5
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$JsonSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-6
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$JsonSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:57366
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = CFKJC-1552608929
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 2000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = CFKJC-1552608929
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    c368a4b3-28c1-42a6-9a7f-be340ac425ba: [CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-StreamThread-1-consumer-1ab26273-e66b-41a4-866d-8fa9bc76e33d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-StreamThread-1-consumer-1ab26273-e66b-41a4-866d-8fa9bc76e33d=[]}
    	assigned active {CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-StreamThread-1-consumer-1ab26273-e66b-41a4-866d-8fa9bc76e33d=[1_0, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [CFKJC-1552608929-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC-1552608929-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC-1552608929.inventory-0, CFKJC-1552608929.merchant-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [CFKJC-1552608929-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC-1552608929-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC-1552608929.inventory-0, CFKJC-1552608929.merchant-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    c368a4b3-28c1-42a6-9a7f-be340ac425ba: [CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-StreamThread-1-consumer-1ab26273-e66b-41a4-866d-8fa9bc76e33d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-StreamThread-1-consumer-1ab26273-e66b-41a4-866d-8fa9bc76e33d=[1_0, 0_0]}
    	prev owned standby {CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-StreamThread-1-consumer-1ab26273-e66b-41a4-866d-8fa9bc76e33d=[]}
    	assigned active {CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-StreamThread-1-consumer-1ab26273-e66b-41a4-866d-8fa9bc76e33d=[1_0, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [CFKJC-1552608929-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC-1552608929-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC-1552608929.inventory-0, CFKJC-1552608929.merchant-0]
    	Current owned partitions:                  [CFKJC-1552608929-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC-1552608929-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC-1552608929.inventory-0, CFKJC-1552608929.merchant-0]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 0_0]
    	New standby tasks: []
    	Existing active tasks: [1_0, 0_0]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-5
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$EnrichedDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-7
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$JsonSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-8
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$JsonSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:57366
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = CFKJC-1552608929
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 2000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = CFKJC-1552608929
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    c368a4b3-28c1-42a6-9a7f-be340ac425ba: [CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-StreamThread-1-consumer-e6a5a32a-2b6e-457d-ad48-28d42e25f08c]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-StreamThread-1-consumer-e6a5a32a-2b6e-457d-ad48-28d42e25f08c=[1_0]}
    	assigned active {CFKJC-1552608929-c368a4b3-28c1-42a6-9a7f-be340ac425ba-StreamThread-1-consumer-e6a5a32a-2b6e-457d-ad48-28d42e25f08c=[1_0, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [CFKJC-1552608929-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC-1552608929-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC-1552608929.inventory-0, CFKJC-1552608929.merchant-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [CFKJC-1552608929-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC-1552608929-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC-1552608929.inventory-0, CFKJC-1552608929.merchant-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:57385]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-6
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$EnrichedDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest[m

    [0K[32mâœ”[90m shouldComputeForeignKeyJoinsCorrectly()[31m (23.6s)[m

ResponsiveForeignKeyJoinIntegrationTest STANDARD_ERROR
    Test 3(dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest): MONGO_DB teardown begins at 1731118925988ms (speed check)

ResponsiveForeignKeyJoinIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

ResponsiveForeignKeyJoinIntegrationTest STANDARD_ERROR
    Test 3(dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest): MONGO_DB teardown ends at 1731118927693ms (duration: PT1.705S) (speed check)
    Test 3(dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest): MONGO_DB test total runtime=PT35.373S) (speed check)

Gradle Test Executor 4 STANDARD_ERROR
    Test 4: creating ResponsiveExtension(backend=MONGO_DB) at 1731118927696ms (speed check)

ResponsiveKafkaStreamsIntegrationTest STANDARD_ERROR
    Test 4(dev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest): MONGO_DB setup begins at 1731118927698ms (speed check)

ResponsiveKafkaStreamsIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57612]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

ResponsiveKafkaStreamsIntegrationTest STANDARD_ERROR
    Test 4(dev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest): MONGO_DB setup ends at 1731118941084ms (duration: PT13.386S) (speed check)

ResponsiveKafkaStreamsIntegrationTest > shouldDefaultToResponsiveStoresWhenUsingDsl() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57612]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-9
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:57578
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57612]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldDefaultToResponsiveStoresWhenUsingDsl--2086653335
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:57612]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57612]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDefaultToResponsiveStoresWhenUsingDsl--2086653335-eb866fe3-0f13-4780-8d17-049e6b758a10-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:57612]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDefaultToResponsiveStoresWhenUsingDsl--2086653335-eb866fe3-0f13-4780-8d17-049e6b758a10-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57612]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57612]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDefaultToResponsiveStoresWhenUsingDsl--2086653335-eb866fe3-0f13-4780-8d17-049e6b758a10-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57612]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDefaultToResponsiveStoresWhenUsingDsl--2086653335-eb866fe3-0f13-4780-8d17-049e6b758a10-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldDefaultToResponsiveStoresWhenUsingDsl--2086653335
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    eb866fe3-0f13-4780-8d17-049e6b758a10: [shouldDefaultToResponsiveStoresWhenUsingDsl--2086653335-eb866fe3-0f13-4780-8d17-049e6b758a10-StreamThread-1-consumer-36e6c639-4729-4c6d-b975-ac6e5e668631]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldDefaultToResponsiveStoresWhenUsingDsl--2086653335-eb866fe3-0f13-4780-8d17-049e6b758a10-StreamThread-1-consumer-36e6c639-4729-4c6d-b975-ac6e5e668631=[]}
    	assigned active {shouldDefaultToResponsiveStoresWhenUsingDsl--2086653335-eb866fe3-0f13-4780-8d17-049e6b758a10-StreamThread-1-consumer-36e6c639-4729-4c6d-b975-ac6e5e668631=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldDefaultToResponsiveStoresWhenUsingDsl--2086653335.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldDefaultToResponsiveStoresWhenUsingDsl--2086653335.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    Pinged your deployment. You successfully connected to MongoDB!

  [0K[39mdev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest[m

    [0K[32mâœ”[90m shouldDefaultToResponsiveStoresWhenUsingDsl()[31m (3.6s)[m

ResponsiveKafkaStreamsIntegrationTest STANDARD_ERROR
    Test 4(dev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest): MONGO_DB teardown begins at 1731118944765ms (speed check)

ResponsiveKafkaStreamsIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

ResponsiveKafkaStreamsIntegrationTest STANDARD_ERROR
    Test 4(dev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest): MONGO_DB teardown ends at 1731118947824ms (duration: PT3.059S) (speed check)
    Test 4(dev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest): MONGO_DB test total runtime=PT20.128S) (speed check)

Gradle Test Executor 4 STANDARD_ERROR
    Test 5: creating ResponsiveExtension(empty) at 1731118947830ms (speed check)

ResponsiveKeyValueStoreEosIntegrationTest STANDARD_ERROR
    Test 5(dev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest): CASSANDRA setup begins at 1731118947837ms (speed check)

ResponsiveKeyValueStoreEosIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

ResponsiveKeyValueStoreEosIntegrationTest STANDARD_ERROR
    Test 5(dev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest): CASSANDRA setup ends at 1731118969328ms (duration: PT21.491S) (speed check)

ResponsiveKeyValueStoreEosIntegrationTest STANDARD_OUT

ResponsiveKeyValueStoreEosIntegrationTest > shouldMaintainStateOnEosFailOverAndFenceOldClient(KVSchema) > [1] KEY_VALUE STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-10
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 57771
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue
    	application.server = a:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 20000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-a38b6931-fbb4-40dc-8555-0509c0a8b946-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-a38b6931-fbb4-40dc-8555-0509c0a8b946-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-a38b6931-fbb4-40dc-8555-0509c0a8b946-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-a38b6931-fbb4-40dc-8555-0509c0a8b946-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-a38b6931-fbb4-40dc-8555-0509c0a8b946-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 57771
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue
    	application.server = b:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 20000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-7a69f6f2-de65-425b-96e6-a426343ba41e-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-7a69f6f2-de65-425b-96e6-a426343ba41e-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-7a69f6f2-de65-425b-96e6-a426343ba41e-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-7a69f6f2-de65-425b-96e6-a426343ba41e-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-7a69f6f2-de65-425b-96e6-a426343ba41e-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    a38b6931-fbb4-40dc-8555-0509c0a8b946: [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-a38b6931-fbb4-40dc-8555-0509c0a8b946-StreamThread-1-consumer-facbf9c7-d67f-4e3e-a153-d597bda9caf0]
    7a69f6f2-de65-425b-96e6-a426343ba41e: [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-7a69f6f2-de65-425b-96e6-a426343ba41e-StreamThread-1-consumer-9df01064-9141-47a8-b644-86dd95c23c1f]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    7a69f6f2-de65-425b-96e6-a426343ba41e=[activeTasks: ([0_1]) standbyTasks: ([])] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:671)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-a38b6931-fbb4-40dc-8555-0509c0a8b946-StreamThread-1-consumer-facbf9c7-d67f-4e3e-a153-d597bda9caf0=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-a38b6931-fbb4-40dc-8555-0509c0a8b946-StreamThread-1-consumer-facbf9c7-d67f-4e3e-a153-d597bda9caf0=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-7a69f6f2-de65-425b-96e6-a426343ba41e-StreamThread-1-consumer-9df01064-9141-47a8-b644-86dd95c23c1f=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-7a69f6f2-de65-425b-96e6-a426343ba41e-StreamThread-1-consumer-9df01064-9141-47a8-b644-86dd95c23c1f=[0_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-7
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    7a69f6f2-de65-425b-96e6-a426343ba41e: [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-7a69f6f2-de65-425b-96e6-a426343ba41e-StreamThread-1-consumer-9df01064-9141-47a8-b644-86dd95c23c1f]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-7a69f6f2-de65-425b-96e6-a426343ba41e-StreamThread-1-consumer-9df01064-9141-47a8-b644-86dd95c23c1f=[0_1]}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-7a69f6f2-de65-425b-96e6-a426343ba41e-StreamThread-1-consumer-9df01064-9141-47a8-b644-86dd95c23c1f=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-7a69f6f2-de65-425b-96e6-a426343ba41e-StreamThread-1-consumer-9df01064-9141-47a8-b644-86dd95c23c1f=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0, shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Current owned partitions:                  [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: [0_1]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-8
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-9
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:322)
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:303)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:273)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeExceptionally(ProducerBatch.java:237)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:830)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:819)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:771)
    	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:702)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$null$1(Sender.java:627)
    	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:612)
    	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
    	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:612)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$8(Sender.java:917)
    	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:154)
    	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:608)
    	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:600)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:349)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-a38b6931-fbb4-40dc-8555-0509c0a8b946-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-a38b6931-fbb4-40dc-8555-0509c0a8b946-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	lost active tasks: []
    	lost assigned standby tasks: []
     (org.apache.kafka.streams.processor.internals.StreamThread:104)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-a38b6931-fbb4-40dc-8555-0509c0a8b946-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-a38b6931-fbb4-40dc-8555-0509c0a8b946-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    a38b6931-fbb4-40dc-8555-0509c0a8b946: [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-a38b6931-fbb4-40dc-8555-0509c0a8b946-StreamThread-1-consumer-6e79ffce-d3dd-4dec-940d-c739304b3a35]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-a38b6931-fbb4-40dc-8555-0509c0a8b946-StreamThread-1-consumer-6e79ffce-d3dd-4dec-940d-c739304b3a35=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-a38b6931-fbb4-40dc-8555-0509c0a8b946-StreamThread-1-consumer-6e79ffce-d3dd-4dec-940d-c739304b3a35=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0, shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0, shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)

  [0K[39mdev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest[m

    [0K[39mshouldMaintainStateOnEosFailOverAndFenceOldClient(KVSchema)[m

      [0K[32mâœ”[90m [1] KEY_VALUE[31m (32.5s)[m

ResponsiveKeyValueStoreEosIntegrationTest > shouldMaintainStateOnEosFailOverAndFenceOldClient(KVSchema) > [2] FACT STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-11
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 57771
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldmaintainstateoneosfailoverandfenceoldclientfact
    	application.server = a:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 20000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-fd145019-8b6f-45ea-852c-6897d3ed64c1-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-fd145019-8b6f-45ea-852c-6897d3ed64c1-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-fd145019-8b6f-45ea-852c-6897d3ed64c1-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-fd145019-8b6f-45ea-852c-6897d3ed64c1-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-fd145019-8b6f-45ea-852c-6897d3ed64c1-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldmaintainstateoneosfailoverandfenceoldclientfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 57771
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldmaintainstateoneosfailoverandfenceoldclientfact
    	application.server = b:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 20000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-d299e755-53ac-4e1b-98ec-bc36feb68de8-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-d299e755-53ac-4e1b-98ec-bc36feb68de8-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-d299e755-53ac-4e1b-98ec-bc36feb68de8-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-d299e755-53ac-4e1b-98ec-bc36feb68de8-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-d299e755-53ac-4e1b-98ec-bc36feb68de8-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldmaintainstateoneosfailoverandfenceoldclientfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    d299e755-53ac-4e1b-98ec-bc36feb68de8: [shouldmaintainstateoneosfailoverandfenceoldclientfact-d299e755-53ac-4e1b-98ec-bc36feb68de8-StreamThread-1-consumer-5b7a4d25-ed8d-44c9-9bc2-4d920d81e9c2]
    fd145019-8b6f-45ea-852c-6897d3ed64c1: [shouldmaintainstateoneosfailoverandfenceoldclientfact-fd145019-8b6f-45ea-852c-6897d3ed64c1-StreamThread-1-consumer-9675825f-d814-404b-9e9b-44ee1628c489]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    fd145019-8b6f-45ea-852c-6897d3ed64c1=[activeTasks: ([0_0]) standbyTasks: ([])] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:671)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientfact-fd145019-8b6f-45ea-852c-6897d3ed64c1-StreamThread-1-consumer-9675825f-d814-404b-9e9b-44ee1628c489=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientfact-fd145019-8b6f-45ea-852c-6897d3ed64c1-StreamThread-1-consumer-9675825f-d814-404b-9e9b-44ee1628c489=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientfact-d299e755-53ac-4e1b-98ec-bc36feb68de8-StreamThread-1-consumer-5b7a4d25-ed8d-44c9-9bc2-4d920d81e9c2=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientfact-d299e755-53ac-4e1b-98ec-bc36feb68de8-StreamThread-1-consumer-5b7a4d25-ed8d-44c9-9bc2-4d920d81e9c2=[0_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-10
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    d299e755-53ac-4e1b-98ec-bc36feb68de8: [shouldmaintainstateoneosfailoverandfenceoldclientfact-d299e755-53ac-4e1b-98ec-bc36feb68de8-StreamThread-1-consumer-5b7a4d25-ed8d-44c9-9bc2-4d920d81e9c2]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldmaintainstateoneosfailoverandfenceoldclientfact-d299e755-53ac-4e1b-98ec-bc36feb68de8-StreamThread-1-consumer-5b7a4d25-ed8d-44c9-9bc2-4d920d81e9c2=[0_1]}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientfact-d299e755-53ac-4e1b-98ec-bc36feb68de8-StreamThread-1-consumer-5b7a4d25-ed8d-44c9-9bc2-4d920d81e9c2=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientfact-d299e755-53ac-4e1b-98ec-bc36feb68de8-StreamThread-1-consumer-5b7a4d25-ed8d-44c9-9bc2-4d920d81e9c2=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-0, shouldmaintainstateoneosfailoverandfenceoldclientfact.input-1]
    	Current owned partitions:                  [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-1]
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: [0_1]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-11
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-12
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:322)
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic shouldmaintainstateoneosfailoverandfenceoldclientfact-shouldmaintainstateoneosfailoverandfenceoldclientfact-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:303)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:273)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeExceptionally(ProducerBatch.java:237)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:830)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:819)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:771)
    	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:702)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$null$1(Sender.java:627)
    	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:612)
    	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
    	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:612)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$8(Sender.java:917)
    	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:154)
    	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:608)
    	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:600)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:349)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-fd145019-8b6f-45ea-852c-6897d3ed64c1-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-fd145019-8b6f-45ea-852c-6897d3ed64c1-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	lost active tasks: []
    	lost assigned standby tasks: []
     (org.apache.kafka.streams.processor.internals.StreamThread:104)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:57865]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-fd145019-8b6f-45ea-852c-6897d3ed64c1-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-fd145019-8b6f-45ea-852c-6897d3ed64c1-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    fd145019-8b6f-45ea-852c-6897d3ed64c1: [shouldmaintainstateoneosfailoverandfenceoldclientfact-fd145019-8b6f-45ea-852c-6897d3ed64c1-StreamThread-1-consumer-29a01d58-1618-4542-84fe-77f1ca051fe5]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientfact-fd145019-8b6f-45ea-852c-6897d3ed64c1-StreamThread-1-consumer-29a01d58-1618-4542-84fe-77f1ca051fe5=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientfact-fd145019-8b6f-45ea-852c-6897d3ed64c1-StreamThread-1-consumer-29a01d58-1618-4542-84fe-77f1ca051fe5=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-0, shouldmaintainstateoneosfailoverandfenceoldclientfact.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-0, shouldmaintainstateoneosfailoverandfenceoldclientfact.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
      [0K[32mâœ”[90m [2] FACT[31m (32.3s)[m

ResponsiveKeyValueStoreEosIntegrationTest STANDARD_ERROR
    Test 5(dev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest): CASSANDRA teardown begins at 1731119034272ms (speed check)

ResponsiveKeyValueStoreEosIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

ResponsiveKeyValueStoreEosIntegrationTest STANDARD_ERROR
    Test 5(dev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest): CASSANDRA teardown ends at 1731119037730ms (duration: PT3.458S) (speed check)
    Test 5(dev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest): CASSANDRA test total runtime=PT1M29.9S) (speed check)

Gradle Test Executor 4 STANDARD_ERROR
    Test 6: creating ResponsiveExtension(backend=MONGO_DB) at 1731119037735ms (speed check)

ResponsiveKeyValueStoreIntegrationTest STANDARD_ERROR
    Test 6(dev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest): MONGO_DB setup begins at 1731119037747ms (speed check)

ResponsiveKeyValueStoreIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58450]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

ResponsiveKeyValueStoreIntegrationTest STANDARD_ERROR
    Test 6(dev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest): MONGO_DB setup ends at 1731119048892ms (duration: PT11.145S) (speed check)

ResponsiveKeyValueStoreIntegrationTest > shouldMatchRocksDB() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58450]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-12
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:58414
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58450]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldMatchRocksDB--47037426
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:58450]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58450]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldMatchRocksDB--47037426-e9b82a1c-d356-489d-9316-ba3bee65c506-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:58450]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldMatchRocksDB--47037426-e9b82a1c-d356-489d-9316-ba3bee65c506-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58450]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58450]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldMatchRocksDB--47037426-e9b82a1c-d356-489d-9316-ba3bee65c506-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:58450]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldMatchRocksDB--47037426-e9b82a1c-d356-489d-9316-ba3bee65c506-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldMatchRocksDB--47037426
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    e9b82a1c-d356-489d-9316-ba3bee65c506: [shouldMatchRocksDB--47037426-e9b82a1c-d356-489d-9316-ba3bee65c506-StreamThread-1-consumer-d890e9ff-b77a-430f-ae6e-ea2968be5719]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldMatchRocksDB--47037426-e9b82a1c-d356-489d-9316-ba3bee65c506-StreamThread-1-consumer-d890e9ff-b77a-430f-ae6e-ea2968be5719=[]}
    	assigned active {shouldMatchRocksDB--47037426-e9b82a1c-d356-489d-9316-ba3bee65c506-StreamThread-1-consumer-d890e9ff-b77a-430f-ae6e-ea2968be5719=[1_0, 0_1, 0_0, 1_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldMatchRocksDB--47037426-shouldMatchRocksDB--47037426-repartition-0, shouldMatchRocksDB--47037426-shouldMatchRocksDB--47037426-repartition-1, shouldMatchRocksDB--47037426.input-0, shouldMatchRocksDB--47037426.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldMatchRocksDB--47037426-shouldMatchRocksDB--47037426-repartition-0, shouldMatchRocksDB--47037426-shouldMatchRocksDB--47037426-repartition-1, shouldMatchRocksDB--47037426.input-0, shouldMatchRocksDB--47037426.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 0_1, 0_0, 1_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    e9b82a1c-d356-489d-9316-ba3bee65c506: [shouldMatchRocksDB--47037426-e9b82a1c-d356-489d-9316-ba3bee65c506-StreamThread-1-consumer-d890e9ff-b77a-430f-ae6e-ea2968be5719]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldMatchRocksDB--47037426-e9b82a1c-d356-489d-9316-ba3bee65c506-StreamThread-1-consumer-d890e9ff-b77a-430f-ae6e-ea2968be5719=[1_0, 0_1, 1_1, 0_0]}
    	prev owned standby {shouldMatchRocksDB--47037426-e9b82a1c-d356-489d-9316-ba3bee65c506-StreamThread-1-consumer-d890e9ff-b77a-430f-ae6e-ea2968be5719=[]}
    	assigned active {shouldMatchRocksDB--47037426-e9b82a1c-d356-489d-9316-ba3bee65c506-StreamThread-1-consumer-d890e9ff-b77a-430f-ae6e-ea2968be5719=[1_0, 0_1, 0_0, 1_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldMatchRocksDB--47037426-shouldMatchRocksDB--47037426-repartition-0, shouldMatchRocksDB--47037426-shouldMatchRocksDB--47037426-repartition-1, shouldMatchRocksDB--47037426.input-0, shouldMatchRocksDB--47037426.input-1]
    	Current owned partitions:                  [shouldMatchRocksDB--47037426-shouldMatchRocksDB--47037426-repartition-0, shouldMatchRocksDB--47037426-shouldMatchRocksDB--47037426-repartition-1, shouldMatchRocksDB--47037426.input-0, shouldMatchRocksDB--47037426.input-1]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 0_1, 0_0, 1_1]
    	New standby tasks: []
    	Existing active tasks: [1_0, 0_1, 1_1, 0_0]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)

  [0K[39mdev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest[m

    [0K[32mâœ”[90m shouldMatchRocksDB()[31m (3.4s)[m

ResponsiveKeyValueStoreIntegrationTest STANDARD_ERROR
    Test 6(dev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest): MONGO_DB teardown begins at 1731119052318ms (speed check)

ResponsiveKeyValueStoreIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

ResponsiveKeyValueStoreIntegrationTest STANDARD_ERROR
    Test 6(dev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest): MONGO_DB teardown ends at 1731119055160ms (duration: PT2.842S) (speed check)
    Test 6(dev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest): MONGO_DB test total runtime=PT17.425S) (speed check)

Gradle Test Executor 4 STANDARD_ERROR
    Test 7: creating ResponsiveExtension(backend=CASSANDRA) at 1731119055164ms (speed check)

ResponsiveKeyValueStoreRestoreIntegrationTest STANDARD_ERROR
    Test 7(dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest): CASSANDRA setup begins at 1731119055167ms (speed check)

ResponsiveKeyValueStoreRestoreIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

ResponsiveKeyValueStoreRestoreIntegrationTest STANDARD_ERROR
    Test 7(dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest): CASSANDRA setup ends at 1731119074202ms (duration: PT19.035S) (speed check)

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldRestoreUnflushedChangelog(KVSchema) > [1] KEY_VALUE STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-13
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 58590
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogkeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-7113eab8-115f-4836-a900-6b41295aa21a-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-7113eab8-115f-4836-a900-6b41295aa21a-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-7113eab8-115f-4836-a900-6b41295aa21a-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogkeyvalue-7113eab8-115f-4836-a900-6b41295aa21a-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-7113eab8-115f-4836-a900-6b41295aa21a-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    7113eab8-115f-4836-a900-6b41295aa21a: [shouldrestoreunflushedchangelogkeyvalue-7113eab8-115f-4836-a900-6b41295aa21a-StreamThread-1-consumer-6f9e9eb6-4bc2-43ec-8b40-11c3af52a660]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogkeyvalue-7113eab8-115f-4836-a900-6b41295aa21a-StreamThread-1-consumer-6f9e9eb6-4bc2-43ec-8b40-11c3af52a660=[]}
    	assigned active {shouldrestoreunflushedchangelogkeyvalue-7113eab8-115f-4836-a900-6b41295aa21a-StreamThread-1-consumer-6f9e9eb6-4bc2-43ec-8b40-11c3af52a660=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 58590
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogkeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-43211938-3829-40b3-ae55-5577b2044ec9-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-43211938-3829-40b3-ae55-5577b2044ec9-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-43211938-3829-40b3-ae55-5577b2044ec9-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogkeyvalue-43211938-3829-40b3-ae55-5577b2044ec9-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-43211938-3829-40b3-ae55-5577b2044ec9-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    43211938-3829-40b3-ae55-5577b2044ec9: [shouldrestoreunflushedchangelogkeyvalue-43211938-3829-40b3-ae55-5577b2044ec9-StreamThread-1-consumer-fadb7b89-eb00-4ea6-9a92-16fd84f29b06]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogkeyvalue-43211938-3829-40b3-ae55-5577b2044ec9-StreamThread-1-consumer-fadb7b89-eb00-4ea6-9a92-16fd84f29b06=[]}
    	assigned active {shouldrestoreunflushedchangelogkeyvalue-43211938-3829-40b3-ae55-5577b2044ec9-StreamThread-1-consumer-fadb7b89-eb00-4ea6-9a92-16fd84f29b06=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.streams.errors.StreamsException: java.lang.RuntimeException: oops
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:729)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: java.lang.RuntimeException: oops
    	at dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest.shouldRestoreUnflushedChangelog(ResponsiveKeyValueStoreRestoreIntegrationTest.java:304)
    	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
    	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:727)
    	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
    	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
    	at org.junit.jupiter.engine.extension.SameThreadTimeoutInvocation.proceed(SameThreadTimeoutInvocation.java:45)
    	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156)
    	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:147)
    	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestTemplateMethod(TimeoutExtension.java:94)
    	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103)
    	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)
    	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
    	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
    	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
    	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
    	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)
    	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86)
    	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:217)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:213)
    	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:138)
    	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:68)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:204)
    	at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:142)
    	at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.lambda$execute$2(TestTemplateTestDescriptor.java:110)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
    	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
    	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
    	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
    	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
    	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
    	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
    	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:274)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
    	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
    	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
    	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
    	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
    	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
    	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:274)
    	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
    	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
    	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
    	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
    	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
    	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
    	at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:110)
    	at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:44)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
    	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
    	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
    	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
    	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
    	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
    	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
    	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
    	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
    	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
    	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
    	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
    	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
    	at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.processAllTestClasses(JUnitPlatformTestClassProcessor.java:110)
    	at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.access$000(JUnitPlatformTestClassProcessor.java:90)
    	at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor.stop(JUnitPlatformTestClassProcessor.java:85)
    	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:62)
    	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
    	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
    	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
    	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)
    	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)
    	at com.sun.proxy.$Proxy2.stop(Unknown Source)
    	at org.gradle.api.internal.tasks.testing.worker.TestWorker$3.run(TestWorker.java:193)
    	at org.gradle.api.internal.tasks.testing.worker.TestWorker.executeAndMaintainThreadName(TestWorker.java:129)
    	at org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:100)
    	at org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:60)
    	at org.gradle.process.internal.worker.child.ActionExecutionWorker.execute(ActionExecutionWorker.java:56)
    	at org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:113)
    	at org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:65)
    	at worker.org.gradle.process.internal.worker.GradleWorkerMain.run(GradleWorkerMain.java:69)
    	at worker.org.gradle.process.internal.worker.GradleWorkerMain.main(GradleWorkerMain.java:74)
    Using Scylla optimized driver!!!
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 58590
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogkeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-61d5b71c-b1a5-476d-8ad2-cbfb9f5b1e8c-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-61d5b71c-b1a5-476d-8ad2-cbfb9f5b1e8c-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-61d5b71c-b1a5-476d-8ad2-cbfb9f5b1e8c-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogkeyvalue-61d5b71c-b1a5-476d-8ad2-cbfb9f5b1e8c-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-61d5b71c-b1a5-476d-8ad2-cbfb9f5b1e8c-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    61d5b71c-b1a5-476d-8ad2-cbfb9f5b1e8c: [shouldrestoreunflushedchangelogkeyvalue-61d5b71c-b1a5-476d-8ad2-cbfb9f5b1e8c-StreamThread-1-consumer-a8ecebb6-d68b-4900-9bda-ad9dd45af05c]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogkeyvalue-61d5b71c-b1a5-476d-8ad2-cbfb9f5b1e8c-StreamThread-1-consumer-a8ecebb6-d68b-4900-9bda-ad9dd45af05c=[]}
    	assigned active {shouldrestoreunflushedchangelogkeyvalue-61d5b71c-b1a5-476d-8ad2-cbfb9f5b1e8c-StreamThread-1-consumer-a8ecebb6-d68b-4900-9bda-ad9dd45af05c=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-13
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest[m

    [0K[39mshouldRestoreUnflushedChangelog(KVSchema)[m

      [0K[32mâœ”[90m [1] KEY_VALUE[31m (20.8s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldRestoreUnflushedChangelog(KVSchema) > [2] FACT STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-14
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 58590
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogfact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-78ea5def-7566-4023-8e56-26449f7d7b6e-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-78ea5def-7566-4023-8e56-26449f7d7b6e-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-78ea5def-7566-4023-8e56-26449f7d7b6e-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogfact-78ea5def-7566-4023-8e56-26449f7d7b6e-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-78ea5def-7566-4023-8e56-26449f7d7b6e-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    78ea5def-7566-4023-8e56-26449f7d7b6e: [shouldrestoreunflushedchangelogfact-78ea5def-7566-4023-8e56-26449f7d7b6e-StreamThread-1-consumer-b17714ed-0fd4-4e1f-9ba0-b30c1ed021b7]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogfact-78ea5def-7566-4023-8e56-26449f7d7b6e-StreamThread-1-consumer-b17714ed-0fd4-4e1f-9ba0-b30c1ed021b7=[]}
    	assigned active {shouldrestoreunflushedchangelogfact-78ea5def-7566-4023-8e56-26449f7d7b6e-StreamThread-1-consumer-b17714ed-0fd4-4e1f-9ba0-b30c1ed021b7=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	lost active tasks: [0_0]
    	lost assigned standby tasks: []
     (org.apache.kafka.streams.processor.internals.StreamThread:104)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-78ea5def-7566-4023-8e56-26449f7d7b6e-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogfact-78ea5def-7566-4023-8e56-26449f7d7b6e-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    78ea5def-7566-4023-8e56-26449f7d7b6e: [shouldrestoreunflushedchangelogfact-78ea5def-7566-4023-8e56-26449f7d7b6e-StreamThread-1-consumer-e36453a6-3c30-4a47-bb59-548577fcc0a4]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogfact-78ea5def-7566-4023-8e56-26449f7d7b6e-StreamThread-1-consumer-e36453a6-3c30-4a47-bb59-548577fcc0a4=[]}
    	assigned active {shouldrestoreunflushedchangelogfact-78ea5def-7566-4023-8e56-26449f7d7b6e-StreamThread-1-consumer-e36453a6-3c30-4a47-bb59-548577fcc0a4=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 58590
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogfact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-9b58269b-c32a-4a74-a2b4-0a7623921774-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-9b58269b-c32a-4a74-a2b4-0a7623921774-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-9b58269b-c32a-4a74-a2b4-0a7623921774-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogfact-9b58269b-c32a-4a74-a2b4-0a7623921774-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-9b58269b-c32a-4a74-a2b4-0a7623921774-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    9b58269b-c32a-4a74-a2b4-0a7623921774: [shouldrestoreunflushedchangelogfact-9b58269b-c32a-4a74-a2b4-0a7623921774-StreamThread-1-consumer-4967fee1-28a3-444b-8cb4-2ffa85fa0f13]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogfact-9b58269b-c32a-4a74-a2b4-0a7623921774-StreamThread-1-consumer-4967fee1-28a3-444b-8cb4-2ffa85fa0f13=[]}
    	assigned active {shouldrestoreunflushedchangelogfact-9b58269b-c32a-4a74-a2b4-0a7623921774-StreamThread-1-consumer-4967fee1-28a3-444b-8cb4-2ffa85fa0f13=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    Using Scylla optimized driver!!!
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 58590
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogfact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-0f41d32f-4282-4b04-89b8-67ec70770c90-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-0f41d32f-4282-4b04-89b8-67ec70770c90-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-0f41d32f-4282-4b04-89b8-67ec70770c90-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogfact-0f41d32f-4282-4b04-89b8-67ec70770c90-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-0f41d32f-4282-4b04-89b8-67ec70770c90-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    0f41d32f-4282-4b04-89b8-67ec70770c90: [shouldrestoreunflushedchangelogfact-0f41d32f-4282-4b04-89b8-67ec70770c90-StreamThread-1-consumer-c3cd02ad-11f4-489f-9d02-9e55d565f3a8]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogfact-0f41d32f-4282-4b04-89b8-67ec70770c90-StreamThread-1-consumer-c3cd02ad-11f4-489f-9d02-9e55d565f3a8=[]}
    	assigned active {shouldrestoreunflushedchangelogfact-0f41d32f-4282-4b04-89b8-67ec70770c90-StreamThread-1-consumer-c3cd02ad-11f4-489f-9d02-9e55d565f3a8=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-14
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
      [0K[32mâœ”[90m [2] FACT[31m (24.9s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldFlushStoresBeforeClose(KVSchema) > [1] KEY_VALUE STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-15
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 58590
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldflushstoresbeforeclosekeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosekeyvalue-69d6a387-c115-417f-8053-5b16f6f8b398-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosekeyvalue-69d6a387-c115-417f-8053-5b16f6f8b398-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosekeyvalue-69d6a387-c115-417f-8053-5b16f6f8b398-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldflushstoresbeforeclosekeyvalue-69d6a387-c115-417f-8053-5b16f6f8b398-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosekeyvalue-69d6a387-c115-417f-8053-5b16f6f8b398-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldflushstoresbeforeclosekeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    69d6a387-c115-417f-8053-5b16f6f8b398: [shouldflushstoresbeforeclosekeyvalue-69d6a387-c115-417f-8053-5b16f6f8b398-StreamThread-1-consumer-bee1e746-32f6-4727-86d1-e7ca6dc83f95]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldflushstoresbeforeclosekeyvalue-69d6a387-c115-417f-8053-5b16f6f8b398-StreamThread-1-consumer-bee1e746-32f6-4727-86d1-e7ca6dc83f95=[]}
    	assigned active {shouldflushstoresbeforeclosekeyvalue-69d6a387-c115-417f-8053-5b16f6f8b398-StreamThread-1-consumer-bee1e746-32f6-4727-86d1-e7ca6dc83f95=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldflushstoresbeforeclosekeyvalue.input-0, shouldflushstoresbeforeclosekeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldflushstoresbeforeclosekeyvalue.input-0, shouldflushstoresbeforeclosekeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    Using Scylla optimized driver!!!
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-15
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

    [0K[39mshouldFlushStoresBeforeClose(KVSchema)[m

      [0K[32mâœ”[90m [1] KEY_VALUE[31m (8.3s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldFlushStoresBeforeClose(KVSchema) > [2] FACT STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-16
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 58590
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldflushstoresbeforeclosefact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosefact-6ea64d5b-850b-4647-b465-ed4d51f0230b-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosefact-6ea64d5b-850b-4647-b465-ed4d51f0230b-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosefact-6ea64d5b-850b-4647-b465-ed4d51f0230b-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldflushstoresbeforeclosefact-6ea64d5b-850b-4647-b465-ed4d51f0230b-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosefact-6ea64d5b-850b-4647-b465-ed4d51f0230b-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldflushstoresbeforeclosefact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    6ea64d5b-850b-4647-b465-ed4d51f0230b: [shouldflushstoresbeforeclosefact-6ea64d5b-850b-4647-b465-ed4d51f0230b-StreamThread-1-consumer-f70dc1e4-c261-4afe-9f9e-dbcab81a2352]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldflushstoresbeforeclosefact-6ea64d5b-850b-4647-b465-ed4d51f0230b-StreamThread-1-consumer-f70dc1e4-c261-4afe-9f9e-dbcab81a2352=[]}
    	assigned active {shouldflushstoresbeforeclosefact-6ea64d5b-850b-4647-b465-ed4d51f0230b-StreamThread-1-consumer-f70dc1e4-c261-4afe-9f9e-dbcab81a2352=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldflushstoresbeforeclosefact.input-0, shouldflushstoresbeforeclosefact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldflushstoresbeforeclosefact.input-0, shouldflushstoresbeforeclosefact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	lost active tasks: [0_0]
    	lost assigned standby tasks: []
     (org.apache.kafka.streams.processor.internals.StreamThread:104)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosefact-6ea64d5b-850b-4647-b465-ed4d51f0230b-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldflushstoresbeforeclosefact-6ea64d5b-850b-4647-b465-ed4d51f0230b-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    6ea64d5b-850b-4647-b465-ed4d51f0230b: [shouldflushstoresbeforeclosefact-6ea64d5b-850b-4647-b465-ed4d51f0230b-StreamThread-1-consumer-d4a53d52-4589-4a92-8597-741d3c092677]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldflushstoresbeforeclosefact-6ea64d5b-850b-4647-b465-ed4d51f0230b-StreamThread-1-consumer-d4a53d52-4589-4a92-8597-741d3c092677=[]}
    	assigned active {shouldflushstoresbeforeclosefact-6ea64d5b-850b-4647-b465-ed4d51f0230b-StreamThread-1-consumer-d4a53d52-4589-4a92-8597-741d3c092677=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldflushstoresbeforeclosefact.input-0, shouldflushstoresbeforeclosefact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldflushstoresbeforeclosefact.input-0, shouldflushstoresbeforeclosefact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    Using Scylla optimized driver!!!
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-16
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
      [0K[32mâœ”[90m [2] FACT[31m (10.8s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldRepairOffsetsIfOutOfRangeAndConfigured(KVSchema) > [1] KEY_VALUE STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-17
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 58590
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = true
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-367d2a83-dd10-4c19-a2b9-b069fbc247de-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-367d2a83-dd10-4c19-a2b9-b069fbc247de-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-367d2a83-dd10-4c19-a2b9-b069fbc247de-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-367d2a83-dd10-4c19-a2b9-b069fbc247de-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-367d2a83-dd10-4c19-a2b9-b069fbc247de-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    367d2a83-dd10-4c19-a2b9-b069fbc247de: [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-367d2a83-dd10-4c19-a2b9-b069fbc247de-StreamThread-1-consumer-f269fadd-9e77-4364-acca-f653e2ccaf80]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-367d2a83-dd10-4c19-a2b9-b069fbc247de-StreamThread-1-consumer-f269fadd-9e77-4364-acca-f653e2ccaf80=[]}
    	assigned active {shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-367d2a83-dd10-4c19-a2b9-b069fbc247de-StreamThread-1-consumer-f269fadd-9e77-4364-acca-f653e2ccaf80=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input-0, shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input-0, shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-17
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 58590
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = true
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-a0a97a0f-8d84-4fbc-8af5-ae10abb41f45-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-a0a97a0f-8d84-4fbc-8af5-ae10abb41f45-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-a0a97a0f-8d84-4fbc-8af5-ae10abb41f45-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-a0a97a0f-8d84-4fbc-8af5-ae10abb41f45-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-a0a97a0f-8d84-4fbc-8af5-ae10abb41f45-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    a0a97a0f-8d84-4fbc-8af5-ae10abb41f45: [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-a0a97a0f-8d84-4fbc-8af5-ae10abb41f45-StreamThread-1-consumer-48be80d7-a705-4a67-8bef-2cafb9f4b1e9]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-a0a97a0f-8d84-4fbc-8af5-ae10abb41f45-StreamThread-1-consumer-48be80d7-a705-4a67-8bef-2cafb9f4b1e9=[]}
    	assigned active {shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-a0a97a0f-8d84-4fbc-8af5-ae10abb41f45-StreamThread-1-consumer-48be80d7-a705-4a67-8bef-2cafb9f4b1e9=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input-0, shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input-0, shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.clients.consumer.OffsetOutOfRangeException: Fetch position FetchPosition{offset=198, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:58700 (id: 1 rack: null)], epoch=0}} is out of range for partition shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-shouldrepairoffsetsifoutofrangeandconfiguredkeyvalueagg-changelog-0
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.handleInitializeErrors(FetchCollector.java:348)
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.initialize(FetchCollector.java:230)
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.collectFetch(FetchCollector.java:110)
    	at org.apache.kafka.clients.consumer.internals.Fetcher.collectFetch(Fetcher.java:145)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.pollForFetches(LegacyKafkaConsumer.java:693)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.poll(LegacyKafkaConsumer.java:617)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.poll(LegacyKafkaConsumer.java:590)
    	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:874)
    	at dev.responsive.kafka.internal.clients.DelegatingConsumer.poll(DelegatingConsumer.java:95)
    	at dev.responsive.kafka.internal.clients.ResponsiveRestoreConsumer.poll(ResponsiveRestoreConsumer.java:111)
    	at org.apache.kafka.streams.processor.internals.StoreChangelogReader.pollRecordsFromRestoreConsumer(StoreChangelogReader.java:494)
    	at org.apache.kafka.streams.processor.internals.StoreChangelogReader.restore(StoreChangelogReader.java:450)
    	at org.apache.kafka.streams.processor.internals.StreamThread.initializeAndRestorePhase(StreamThread.java:1134)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:921)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-18
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

    [0K[39mshouldRepairOffsetsIfOutOfRangeAndConfigured(KVSchema)[m

      [0K[32mâœ”[90m [1] KEY_VALUE[31m (17.8s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldRepairOffsetsIfOutOfRangeAndConfigured(KVSchema) STANDARD_OUT

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldRepairOffsetsIfOutOfRangeAndConfigured(KVSchema) > [2] FACT STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-18
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 58590
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = true
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrepairoffsetsifoutofrangeandconfiguredfact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-ae10a384-ea0d-46a2-ae52-5c96a0f5a0ea-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-ae10a384-ea0d-46a2-ae52-5c96a0f5a0ea-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-ae10a384-ea0d-46a2-ae52-5c96a0f5a0ea-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-ae10a384-ea0d-46a2-ae52-5c96a0f5a0ea-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-ae10a384-ea0d-46a2-ae52-5c96a0f5a0ea-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrepairoffsetsifoutofrangeandconfiguredfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    ae10a384-ea0d-46a2-ae52-5c96a0f5a0ea: [shouldrepairoffsetsifoutofrangeandconfiguredfact-ae10a384-ea0d-46a2-ae52-5c96a0f5a0ea-StreamThread-1-consumer-f2c3ac20-3eaa-47d9-9fd7-1abc16857eef]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrepairoffsetsifoutofrangeandconfiguredfact-ae10a384-ea0d-46a2-ae52-5c96a0f5a0ea-StreamThread-1-consumer-f2c3ac20-3eaa-47d9-9fd7-1abc16857eef=[]}
    	assigned active {shouldrepairoffsetsifoutofrangeandconfiguredfact-ae10a384-ea0d-46a2-ae52-5c96a0f5a0ea-StreamThread-1-consumer-f2c3ac20-3eaa-47d9-9fd7-1abc16857eef=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	lost active tasks: [0_0]
    	lost assigned standby tasks: []
     (org.apache.kafka.streams.processor.internals.StreamThread:104)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-ae10a384-ea0d-46a2-ae52-5c96a0f5a0ea-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-ae10a384-ea0d-46a2-ae52-5c96a0f5a0ea-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    ae10a384-ea0d-46a2-ae52-5c96a0f5a0ea: [shouldrepairoffsetsifoutofrangeandconfiguredfact-ae10a384-ea0d-46a2-ae52-5c96a0f5a0ea-StreamThread-1-consumer-6772f0a2-42fb-4b81-bd5b-9c5b8b94b16a]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrepairoffsetsifoutofrangeandconfiguredfact-ae10a384-ea0d-46a2-ae52-5c96a0f5a0ea-StreamThread-1-consumer-6772f0a2-42fb-4b81-bd5b-9c5b8b94b16a=[]}
    	assigned active {shouldrepairoffsetsifoutofrangeandconfiguredfact-ae10a384-ea0d-46a2-ae52-5c96a0f5a0ea-StreamThread-1-consumer-6772f0a2-42fb-4b81-bd5b-9c5b8b94b16a=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-19
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 58590
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = true
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrepairoffsetsifoutofrangeandconfiguredfact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-d2db870a-d355-4e6b-9afd-213ad5d0e742-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-d2db870a-d355-4e6b-9afd-213ad5d0e742-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-d2db870a-d355-4e6b-9afd-213ad5d0e742-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-d2db870a-d355-4e6b-9afd-213ad5d0e742-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-d2db870a-d355-4e6b-9afd-213ad5d0e742-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrepairoffsetsifoutofrangeandconfiguredfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    d2db870a-d355-4e6b-9afd-213ad5d0e742: [shouldrepairoffsetsifoutofrangeandconfiguredfact-d2db870a-d355-4e6b-9afd-213ad5d0e742-StreamThread-1-consumer-6e63bba1-de2b-45dd-adad-c6304c1592ae]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrepairoffsetsifoutofrangeandconfiguredfact-d2db870a-d355-4e6b-9afd-213ad5d0e742-StreamThread-1-consumer-6e63bba1-de2b-45dd-adad-c6304c1592ae=[]}
    	assigned active {shouldrepairoffsetsifoutofrangeandconfiguredfact-d2db870a-d355-4e6b-9afd-213ad5d0e742-StreamThread-1-consumer-6e63bba1-de2b-45dd-adad-c6304c1592ae=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.clients.consumer.OffsetOutOfRangeException: Fetch position FetchPosition{offset=198, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:58700 (id: 1 rack: null)], epoch=0}} is out of range for partition shouldrepairoffsetsifoutofrangeandconfiguredfact-shouldrepairoffsetsifoutofrangeandconfiguredfactagg-changelog-0
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.handleInitializeErrors(FetchCollector.java:348)
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.initialize(FetchCollector.java:230)
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.collectFetch(FetchCollector.java:110)
    	at org.apache.kafka.clients.consumer.internals.Fetcher.collectFetch(Fetcher.java:145)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.pollForFetches(LegacyKafkaConsumer.java:693)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.poll(LegacyKafkaConsumer.java:617)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.poll(LegacyKafkaConsumer.java:590)
    	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:874)
    	at dev.responsive.kafka.internal.clients.DelegatingConsumer.poll(DelegatingConsumer.java:95)
    	at dev.responsive.kafka.internal.clients.ResponsiveRestoreConsumer.poll(ResponsiveRestoreConsumer.java:111)
    	at org.apache.kafka.streams.processor.internals.StoreChangelogReader.pollRecordsFromRestoreConsumer(StoreChangelogReader.java:494)
    	at org.apache.kafka.streams.processor.internals.StoreChangelogReader.restore(StoreChangelogReader.java:450)
    	at org.apache.kafka.streams.processor.internals.StreamThread.initializeAndRestorePhase(StreamThread.java:1134)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:921)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:58700]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-20
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
      [0K[32mâœ”[90m [2] FACT[31m (17.6s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest STANDARD_ERROR
    Test 7(dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest): CASSANDRA teardown begins at 1731119174772ms (speed check)

ResponsiveKeyValueStoreRestoreIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

ResponsiveKeyValueStoreRestoreIntegrationTest STANDARD_ERROR
    Test 7(dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest): CASSANDRA teardown ends at 1731119179154ms (duration: PT4.382S) (speed check)
    Test 7(dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest): CASSANDRA test total runtime=PT2M3.99S) (speed check)

Gradle Test Executor 4 STANDARD_OUT

Gradle Test Executor 4 STANDARD_ERROR
    Test 8: creating ResponsiveExtension(backend=MONGO_DB) at 1731119179158ms (speed check)

ResponsiveSessionStoreIntegrationTest STANDARD_ERROR
    Test 8(dev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest): MONGO_DB setup begins at 1731119179167ms (speed check)

ResponsiveSessionStoreIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:59997]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

ResponsiveSessionStoreIntegrationTest STANDARD_ERROR
    Test 8(dev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest): MONGO_DB setup ends at 1731119190856ms (duration: PT11.689S) (speed check)

ResponsiveSessionStoreIntegrationTest > shouldComputeSessionAggregate() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:59997]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-19
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:59937
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:59997]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldComputeSessionAggregate--924695479
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:59997]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:59997]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeSessionAggregate--924695479-846ccfe6-ca5e-4c11-a759-11c5d8408a51-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:59997]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeSessionAggregate--924695479-846ccfe6-ca5e-4c11-a759-11c5d8408a51-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:59997]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:59997]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeSessionAggregate--924695479-846ccfe6-ca5e-4c11-a759-11c5d8408a51-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:59997]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeSessionAggregate--924695479-846ccfe6-ca5e-4c11-a759-11c5d8408a51-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldComputeSessionAggregate--924695479
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    846ccfe6-ca5e-4c11-a759-11c5d8408a51: [shouldComputeSessionAggregate--924695479-846ccfe6-ca5e-4c11-a759-11c5d8408a51-StreamThread-1-consumer-72d6dd68-04ff-4de4-a91f-8c6d2032f48f]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldComputeSessionAggregate--924695479-846ccfe6-ca5e-4c11-a759-11c5d8408a51-StreamThread-1-consumer-72d6dd68-04ff-4de4-a91f-8c6d2032f48f=[]}
    	assigned active {shouldComputeSessionAggregate--924695479-846ccfe6-ca5e-4c11-a759-11c5d8408a51-StreamThread-1-consumer-72d6dd68-04ff-4de4-a91f-8c6d2032f48f=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldComputeSessionAggregate--924695479.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldComputeSessionAggregate--924695479.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)

  [0K[39mdev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest[m

    [0K[32mâœ”[90m shouldComputeSessionAggregate()[33m (1.6s)[m

ResponsiveSessionStoreIntegrationTest STANDARD_ERROR
    Test 8(dev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest): MONGO_DB teardown begins at 1731119192529ms (speed check)

ResponsiveSessionStoreIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

ResponsiveSessionStoreIntegrationTest STANDARD_ERROR
    Test 8(dev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest): MONGO_DB teardown ends at 1731119193687ms (duration: PT1.158S) (speed check)
    Test 8(dev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest): MONGO_DB test total runtime=PT14.529S) (speed check)

Gradle Test Executor 4 STANDARD_ERROR
    Test 9: creating ResponsiveExtension(backend=MONGO_DB) at 1731119193690ms (speed check)

ResponsiveWindowStoreIntegrationTest STANDARD_ERROR
    Test 9(dev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest): MONGO_DB setup begins at 1731119193694ms (speed check)

ResponsiveWindowStoreIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

ResponsiveWindowStoreIntegrationTest STANDARD_ERROR
    Test 9(dev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest): MONGO_DB setup ends at 1731119203830ms (duration: PT10.136S) (speed check)

ResponsiveWindowStoreIntegrationTest > shouldDoStreamStreamJoin() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-20
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:60180
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 1
    	responsive.window.bloom.filter.expected.keys = 10
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldDoStreamStreamJoin-1335328226
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDoStreamStreamJoin-1335328226-03399a45-2d3e-492f-a505-e144e5d97326-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDoStreamStreamJoin-1335328226-03399a45-2d3e-492f-a505-e144e5d97326-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDoStreamStreamJoin-1335328226-03399a45-2d3e-492f-a505-e144e5d97326-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDoStreamStreamJoin-1335328226-03399a45-2d3e-492f-a505-e144e5d97326-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldDoStreamStreamJoin-1335328226
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    03399a45-2d3e-492f-a505-e144e5d97326: [shouldDoStreamStreamJoin-1335328226-03399a45-2d3e-492f-a505-e144e5d97326-StreamThread-1-consumer-1b790e71-4835-41fa-813c-07dee34b3d72]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldDoStreamStreamJoin-1335328226-03399a45-2d3e-492f-a505-e144e5d97326-StreamThread-1-consumer-1b790e71-4835-41fa-813c-07dee34b3d72=[]}
    	assigned active {shouldDoStreamStreamJoin-1335328226-03399a45-2d3e-492f-a505-e144e5d97326-StreamThread-1-consumer-1b790e71-4835-41fa-813c-07dee34b3d72=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldDoStreamStreamJoin-1335328226.input-0, shouldDoStreamStreamJoin-1335328226.other-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldDoStreamStreamJoin-1335328226.input-0, shouldDoStreamStreamJoin-1335328226.other-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    Joining: L:a, R:a
    Joining: L:a2, R:a
    Joining: L:a3, R:a
    Joining: L:b, R:b
    Joining: L:b, R:b2
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-21
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest[m

    [0K[32mâœ”[90m shouldDoStreamStreamJoin()[33m (1.9s)[m

ResponsiveWindowStoreIntegrationTest > shouldComputeHoppingWindowAggregateWithRetention() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-21
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:60180
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 1
    	responsive.window.bloom.filter.expected.keys = 10
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldComputeHoppingWindowAggregateWithRetention--1335035712
    	application.server = host1:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeHoppingWindowAggregateWithRetention--1335035712-1b23d1af-148e-4a7e-a4a2-f541ae715c34-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeHoppingWindowAggregateWithRetention--1335035712-1b23d1af-148e-4a7e-a4a2-f541ae715c34-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeHoppingWindowAggregateWithRetention--1335035712-1b23d1af-148e-4a7e-a4a2-f541ae715c34-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeHoppingWindowAggregateWithRetention--1335035712-1b23d1af-148e-4a7e-a4a2-f541ae715c34-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldComputeHoppingWindowAggregateWithRetention--1335035712
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    1b23d1af-148e-4a7e-a4a2-f541ae715c34: [shouldComputeHoppingWindowAggregateWithRetention--1335035712-1b23d1af-148e-4a7e-a4a2-f541ae715c34-StreamThread-1-consumer-985ea4eb-b284-4a80-8ba3-8261295f3a09]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldComputeHoppingWindowAggregateWithRetention--1335035712-1b23d1af-148e-4a7e-a4a2-f541ae715c34-StreamThread-1-consumer-985ea4eb-b284-4a80-8ba3-8261295f3a09=[]}
    	assigned active {shouldComputeHoppingWindowAggregateWithRetention--1335035712-1b23d1af-148e-4a7e-a4a2-f541ae715c34-StreamThread-1-consumer-985ea4eb-b284-4a80-8ba3-8261295f3a09=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldComputeHoppingWindowAggregateWithRetention--1335035712.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldComputeHoppingWindowAggregateWithRetention--1335035712.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    [0K[32mâœ”[90m shouldComputeHoppingWindowAggregateWithRetention()[31m (1m 1s)[m

ResponsiveWindowStoreIntegrationTest > shouldComputeTumblingWindowAggregateWithRetention() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:60180
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 1
    	responsive.window.bloom.filter.expected.keys = 10
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldComputeTumblingWindowAggregateWithRetention--1460444849
    	application.server = host1:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention--1460444849-a9701286-c2ce-45ef-bd05-666238c95b8f-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention--1460444849-a9701286-c2ce-45ef-bd05-666238c95b8f-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention--1460444849-a9701286-c2ce-45ef-bd05-666238c95b8f-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention--1460444849-a9701286-c2ce-45ef-bd05-666238c95b8f-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldComputeTumblingWindowAggregateWithRetention--1460444849
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-22
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    a9701286-c2ce-45ef-bd05-666238c95b8f: [shouldComputeTumblingWindowAggregateWithRetention--1460444849-a9701286-c2ce-45ef-bd05-666238c95b8f-StreamThread-1-consumer-dcab951e-c953-409c-ad5a-1c84e5334c34]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldComputeTumblingWindowAggregateWithRetention--1460444849-a9701286-c2ce-45ef-bd05-666238c95b8f-StreamThread-1-consumer-dcab951e-c953-409c-ad5a-1c84e5334c34=[]}
    	assigned active {shouldComputeTumblingWindowAggregateWithRetention--1460444849-a9701286-c2ce-45ef-bd05-666238c95b8f-StreamThread-1-consumer-dcab951e-c953-409c-ad5a-1c84e5334c34=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldComputeTumblingWindowAggregateWithRetention--1460444849.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldComputeTumblingWindowAggregateWithRetention--1460444849.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:60180
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 1
    	responsive.window.bloom.filter.expected.keys = 10
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldComputeTumblingWindowAggregateWithRetention--1460444849
    	application.server = host2:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention--1460444849-7a966ffe-d809-47aa-a694-0643b8cfb001-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention--1460444849-7a966ffe-d809-47aa-a694-0643b8cfb001-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention--1460444849-7a966ffe-d809-47aa-a694-0643b8cfb001-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention--1460444849-7a966ffe-d809-47aa-a694-0643b8cfb001-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldComputeTumblingWindowAggregateWithRetention--1460444849
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-23
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    7a966ffe-d809-47aa-a694-0643b8cfb001: [shouldComputeTumblingWindowAggregateWithRetention--1460444849-7a966ffe-d809-47aa-a694-0643b8cfb001-StreamThread-1-consumer-304996c3-7a16-4e09-b5a1-9ebbb6c6a51b]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldComputeTumblingWindowAggregateWithRetention--1460444849-7a966ffe-d809-47aa-a694-0643b8cfb001-StreamThread-1-consumer-304996c3-7a16-4e09-b5a1-9ebbb6c6a51b=[]}
    	assigned active {shouldComputeTumblingWindowAggregateWithRetention--1460444849-7a966ffe-d809-47aa-a694-0643b8cfb001-StreamThread-1-consumer-304996c3-7a16-4e09-b5a1-9ebbb6c6a51b=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldComputeTumblingWindowAggregateWithRetention--1460444849.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldComputeTumblingWindowAggregateWithRetention--1460444849.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    [0K[32mâœ”[90m shouldComputeTumblingWindowAggregateWithRetention()[31m (3m 7s)[m

ResponsiveWindowStoreIntegrationTest STANDARD_OUT

ResponsiveWindowStoreIntegrationTest > shouldComputeMultipleWindowsPerSegment() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:60180
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 1
    	responsive.window.bloom.filter.expected.keys = 10
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldComputeMultipleWindowsPerSegment--115275975
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeMultipleWindowsPerSegment--115275975-5664d3dd-224f-4b0c-9497-3665b52425db-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeMultipleWindowsPerSegment--115275975-5664d3dd-224f-4b0c-9497-3665b52425db-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeMultipleWindowsPerSegment--115275975-5664d3dd-224f-4b0c-9497-3665b52425db-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeMultipleWindowsPerSegment--115275975-5664d3dd-224f-4b0c-9497-3665b52425db-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldComputeMultipleWindowsPerSegment--115275975
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:60233]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-24
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    5664d3dd-224f-4b0c-9497-3665b52425db: [shouldComputeMultipleWindowsPerSegment--115275975-5664d3dd-224f-4b0c-9497-3665b52425db-StreamThread-1-consumer-c2fc60df-2665-4907-8ea6-22583349cbe7]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldComputeMultipleWindowsPerSegment--115275975-5664d3dd-224f-4b0c-9497-3665b52425db-StreamThread-1-consumer-c2fc60df-2665-4907-8ea6-22583349cbe7=[]}
    	assigned active {shouldComputeMultipleWindowsPerSegment--115275975-5664d3dd-224f-4b0c-9497-3665b52425db-StreamThread-1-consumer-c2fc60df-2665-4907-8ea6-22583349cbe7=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldComputeMultipleWindowsPerSegment--115275975.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldComputeMultipleWindowsPerSegment--115275975.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    [0K[32mâœ”[90m shouldComputeMultipleWindowsPerSegment()[31m (1m 1s)[m

ResponsiveWindowStoreIntegrationTest STANDARD_ERROR
    Test 9(dev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest): MONGO_DB teardown begins at 1731119515874ms (speed check)

ResponsiveWindowStoreIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

ResponsiveWindowStoreIntegrationTest STANDARD_ERROR
    Test 9(dev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest): MONGO_DB teardown ends at 1731119519998ms (duration: PT4.124S) (speed check)
    Test 9(dev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest): MONGO_DB test total runtime=PT5M26.308S) (speed check)

Gradle Test Executor 4 STANDARD_ERROR
    Test 10: creating ResponsiveExtension(backend=CASSANDRA) at 1731119520029ms (speed check)

RowLevelTtlIntegrationTest STANDARD_ERROR
    Test 10(dev.responsive.kafka.integration.RowLevelTtlIntegrationTest): CASSANDRA setup begins at 1731119520052ms (speed check)

RowLevelTtlIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:49480]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

RowLevelTtlIntegrationTest STANDARD_ERROR
    Test 10(dev.responsive.kafka.integration.RowLevelTtlIntegrationTest): CASSANDRA setup ends at 1731119539061ms (duration: PT19.009S) (speed check)

RowLevelTtlIntegrationTest > shouldApplyRowLevelTtlForKeyAndValue() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:49480]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-25
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 49286
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = maxIdleTimeMs=60000
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:49480]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldApplyRowLevelTtlForKeyAndValue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:49480]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:49480]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldApplyRowLevelTtlForKeyAndValue-dc2aa612-6fdf-4f2b-a604-777ebe41bda5-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:49480]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldApplyRowLevelTtlForKeyAndValue-dc2aa612-6fdf-4f2b-a604-777ebe41bda5-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:49480]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:49480]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldApplyRowLevelTtlForKeyAndValue-dc2aa612-6fdf-4f2b-a604-777ebe41bda5-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:49480]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldApplyRowLevelTtlForKeyAndValue-dc2aa612-6fdf-4f2b-a604-777ebe41bda5-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldApplyRowLevelTtlForKeyAndValue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    dc2aa612-6fdf-4f2b-a604-777ebe41bda5: [shouldApplyRowLevelTtlForKeyAndValue-dc2aa612-6fdf-4f2b-a604-777ebe41bda5-StreamThread-1-consumer-5cd44d9b-4915-40e4-bcf8-dea9df5ee81d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldApplyRowLevelTtlForKeyAndValue-dc2aa612-6fdf-4f2b-a604-777ebe41bda5-StreamThread-1-consumer-5cd44d9b-4915-40e4-bcf8-dea9df5ee81d=[]}
    	assigned active {shouldApplyRowLevelTtlForKeyAndValue-dc2aa612-6fdf-4f2b-a604-777ebe41bda5-StreamThread-1-consumer-5cd44d9b-4915-40e4-bcf8-dea9df5ee81d=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldApplyRowLevelTtlForKeyAndValue.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldApplyRowLevelTtlForKeyAndValue.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:49480]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-22
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.RowLevelTtlIntegrationTest[m

    [0K[32mâœ”[90m shouldApplyRowLevelTtlForKeyAndValue()[31m (6.4s)[m

RowLevelTtlIntegrationTest STANDARD_ERROR
    Test 10(dev.responsive.kafka.integration.RowLevelTtlIntegrationTest): CASSANDRA teardown begins at 1731119545487ms (speed check)

RowLevelTtlIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

RowLevelTtlIntegrationTest STANDARD_ERROR
    Test 10(dev.responsive.kafka.integration.RowLevelTtlIntegrationTest): CASSANDRA teardown ends at 1731119548484ms (duration: PT2.997S) (speed check)
    Test 10(dev.responsive.kafka.integration.RowLevelTtlIntegrationTest): CASSANDRA test total runtime=PT28.455S) (speed check)

Gradle Test Executor 4 STANDARD_ERROR
    Test 11: creating ResponsiveExtension(backend=CASSANDRA) at 1731119548493ms (speed check)

StoreQueryIntegrationTest STANDARD_ERROR
    Test 11(dev.responsive.kafka.integration.StoreQueryIntegrationTest): CASSANDRA setup begins at 1731119548497ms (speed check)

StoreQueryIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

StoreQueryIntegrationTest STANDARD_ERROR
    Test 11(dev.responsive.kafka.integration.StoreQueryIntegrationTest): CASSANDRA setup ends at 1731119566846ms (duration: PT18.349S) (speed check)

StoreQueryIntegrationTest > shouldAggregateAcrossAllKeysUsingAllQuery() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-26
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 49808
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldAggregateAcrossAllKeysUsingAllQuery
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAcrossAllKeysUsingAllQuery-8ab849be-f415-4be8-9ec5-4be3d220504f-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAcrossAllKeysUsingAllQuery-8ab849be-f415-4be8-9ec5-4be3d220504f-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAcrossAllKeysUsingAllQuery-8ab849be-f415-4be8-9ec5-4be3d220504f-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAcrossAllKeysUsingAllQuery-8ab849be-f415-4be8-9ec5-4be3d220504f-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldAggregateAcrossAllKeysUsingAllQuery
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    8ab849be-f415-4be8-9ec5-4be3d220504f: [shouldAggregateAcrossAllKeysUsingAllQuery-8ab849be-f415-4be8-9ec5-4be3d220504f-StreamThread-1-consumer-b8f90b6c-fb01-40ea-98db-e84b4fbadea7]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldAggregateAcrossAllKeysUsingAllQuery-8ab849be-f415-4be8-9ec5-4be3d220504f-StreamThread-1-consumer-b8f90b6c-fb01-40ea-98db-e84b4fbadea7=[]}
    	assigned active {shouldAggregateAcrossAllKeysUsingAllQuery-8ab849be-f415-4be8-9ec5-4be3d220504f-StreamThread-1-consumer-b8f90b6c-fb01-40ea-98db-e84b4fbadea7=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldAggregateAcrossAllKeysUsingAllQuery.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldAggregateAcrossAllKeysUsingAllQuery.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-23
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.StoreQueryIntegrationTest[m

    [0K[32mâœ”[90m shouldAggregateAcrossAllKeysUsingAllQuery()[31m (4.8s)[m

StoreQueryIntegrationTest > shouldAggregateAllCapitalLettersUsingRangeQuery() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-27
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 49808
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldAggregateAllCapitalLettersUsingRangeQuery
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAllCapitalLettersUsingRangeQuery-716b0cf9-221a-4f28-beb5-f468fc70554e-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAllCapitalLettersUsingRangeQuery-716b0cf9-221a-4f28-beb5-f468fc70554e-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAllCapitalLettersUsingRangeQuery-716b0cf9-221a-4f28-beb5-f468fc70554e-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAllCapitalLettersUsingRangeQuery-716b0cf9-221a-4f28-beb5-f468fc70554e-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldAggregateAllCapitalLettersUsingRangeQuery
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    716b0cf9-221a-4f28-beb5-f468fc70554e: [shouldAggregateAllCapitalLettersUsingRangeQuery-716b0cf9-221a-4f28-beb5-f468fc70554e-StreamThread-1-consumer-a915ea29-4253-40ce-ba6c-23d544b281bb]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldAggregateAllCapitalLettersUsingRangeQuery-716b0cf9-221a-4f28-beb5-f468fc70554e-StreamThread-1-consumer-a915ea29-4253-40ce-ba6c-23d544b281bb=[]}
    	assigned active {shouldAggregateAllCapitalLettersUsingRangeQuery-716b0cf9-221a-4f28-beb5-f468fc70554e-StreamThread-1-consumer-a915ea29-4253-40ce-ba6c-23d544b281bb=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldAggregateAllCapitalLettersUsingRangeQuery.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldAggregateAllCapitalLettersUsingRangeQuery.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:49999]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-24
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    [0K[32mâœ”[90m shouldAggregateAllCapitalLettersUsingRangeQuery()[31m (4.6s)[m

StoreQueryIntegrationTest STANDARD_ERROR
    Test 11(dev.responsive.kafka.integration.StoreQueryIntegrationTest): CASSANDRA teardown begins at 1731119576383ms (speed check)

StoreQueryIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

StoreQueryIntegrationTest STANDARD_ERROR
    Test 11(dev.responsive.kafka.integration.StoreQueryIntegrationTest): CASSANDRA teardown ends at 1731119578966ms (duration: PT2.583S) (speed check)
    Test 11(dev.responsive.kafka.integration.StoreQueryIntegrationTest): CASSANDRA test total runtime=PT30.473S) (speed check)

Gradle Test Executor 4 STANDARD_ERROR
    Test 12: creating ResponsiveExtension(empty) at 1731119578969ms (speed check)

Gradle Test Executor 4 STANDARD_OUT

TablePartitionerIntegrationTest STANDARD_ERROR
    Test 12(dev.responsive.kafka.integration.TablePartitionerIntegrationTest): CASSANDRA setup begins at 1731119578973ms (speed check)

TablePartitionerIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

TablePartitionerIntegrationTest STANDARD_ERROR
    Test 12(dev.responsive.kafka.integration.TablePartitionerIntegrationTest): CASSANDRA setup ends at 1731119601653ms (duration: PT22.68S) (speed check)

TablePartitionerIntegrationTest STANDARD_OUT

TablePartitionerIntegrationTest > shouldFlushToRemoteTableWithSubpartitions() STANDARD_OUT
    Using Scylla optimized driver!!!
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-28
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = 32
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 50416
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.integration.TablePartitionerIntegrationTest$LongBytesHasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldFlushToRemoteTableWithSubpartitions
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 100
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithSubpartitions-6e201db1-e6e4-4cd6-abc3-59c32d9b5694-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithSubpartitions-6e201db1-e6e4-4cd6-abc3-59c32d9b5694-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithSubpartitions-6e201db1-e6e4-4cd6-abc3-59c32d9b5694-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 10000
    	transactional.id = shouldFlushToRemoteTableWithSubpartitions-6e201db1-e6e4-4cd6-abc3-59c32d9b5694-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithSubpartitions-6e201db1-e6e4-4cd6-abc3-59c32d9b5694-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldFlushToRemoteTableWithSubpartitions
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    6e201db1-e6e4-4cd6-abc3-59c32d9b5694: [shouldFlushToRemoteTableWithSubpartitions-6e201db1-e6e4-4cd6-abc3-59c32d9b5694-StreamThread-1-consumer-73d89cc3-93c9-4173-a94c-e84b935dcb5d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldFlushToRemoteTableWithSubpartitions-6e201db1-e6e4-4cd6-abc3-59c32d9b5694-StreamThread-1-consumer-73d89cc3-93c9-4173-a94c-e84b935dcb5d=[]}
    	assigned active {shouldFlushToRemoteTableWithSubpartitions-6e201db1-e6e4-4cd6-abc3-59c32d9b5694-StreamThread-1-consumer-73d89cc3-93c9-4173-a94c-e84b935dcb5d=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldFlushToRemoteTableWithSubpartitions.input-0, shouldFlushToRemoteTableWithSubpartitions.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldFlushToRemoteTableWithSubpartitions.input-0, shouldFlushToRemoteTableWithSubpartitions.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-25
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.TablePartitionerIntegrationTest[m

    [0K[32mâœ”[90m shouldFlushToRemoteTableWithSubpartitions()[31m (9.8s)[m

TablePartitionerIntegrationTest > shouldFlushToRemoteTableWithoutSubpartitions() STANDARD_OUT
    Using Scylla optimized driver!!!
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-29
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = 32
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 50416
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.integration.TablePartitionerIntegrationTest$LongBytesHasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldFlushToRemoteTableWithoutSubpartitions
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 100
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithoutSubpartitions-452c1b2c-9542-441f-8206-94a865eee2c8-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithoutSubpartitions-452c1b2c-9542-441f-8206-94a865eee2c8-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithoutSubpartitions-452c1b2c-9542-441f-8206-94a865eee2c8-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 10000
    	transactional.id = shouldFlushToRemoteTableWithoutSubpartitions-452c1b2c-9542-441f-8206-94a865eee2c8-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithoutSubpartitions-452c1b2c-9542-441f-8206-94a865eee2c8-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldFlushToRemoteTableWithoutSubpartitions
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    452c1b2c-9542-441f-8206-94a865eee2c8: [shouldFlushToRemoteTableWithoutSubpartitions-452c1b2c-9542-441f-8206-94a865eee2c8-StreamThread-1-consumer-dcdb791f-929b-4dd1-9be7-667e9306eb18]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldFlushToRemoteTableWithoutSubpartitions-452c1b2c-9542-441f-8206-94a865eee2c8-StreamThread-1-consumer-dcdb791f-929b-4dd1-9be7-667e9306eb18=[]}
    	assigned active {shouldFlushToRemoteTableWithoutSubpartitions-452c1b2c-9542-441f-8206-94a865eee2c8-StreamThread-1-consumer-dcdb791f-929b-4dd1-9be7-667e9306eb18=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldFlushToRemoteTableWithoutSubpartitions.input-0, shouldFlushToRemoteTableWithoutSubpartitions.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldFlushToRemoteTableWithoutSubpartitions.input-0, shouldFlushToRemoteTableWithoutSubpartitions.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:50685]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-26
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    [0K[32mâœ”[90m shouldFlushToRemoteTableWithoutSubpartitions()[31m (8.3s)[m

TablePartitionerIntegrationTest STANDARD_ERROR
    Test 12(dev.responsive.kafka.integration.TablePartitionerIntegrationTest): CASSANDRA teardown begins at 1731119619814ms (speed check)

TablePartitionerIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

TablePartitionerIntegrationTest STANDARD_ERROR
    Test 12(dev.responsive.kafka.integration.TablePartitionerIntegrationTest): CASSANDRA teardown ends at 1731119623401ms (duration: PT3.587S) (speed check)
    Test 12(dev.responsive.kafka.integration.TablePartitionerIntegrationTest): CASSANDRA test total runtime=PT44.432S) (speed check)

Gradle Test Executor 4 STANDARD_OUT

Gradle Test Executor 4 STANDARD_ERROR
    Test 13: creating ResponsiveExtension(empty) at 1731119623403ms (speed check)

CassandraFactTableIntegrationTest STANDARD_ERROR
    Test 13(dev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest): CASSANDRA setup begins at 1731119623407ms (speed check)

CassandraFactTableIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:51653]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

CassandraFactTableIntegrationTest STANDARD_ERROR
    Test 13(dev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest): CASSANDRA setup ends at 1731119643006ms (duration: PT19.599S) (speed check)

CassandraFactTableIntegrationTest > shouldRespectSemanticKeyBasedTtl() STANDARD_OUT
    Using Scylla optimized driver!!!

  [0K[39mdev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest[m

    [0K[32mâœ”[90m shouldRespectSemanticKeyBasedTtl()[31m (3.4s)[m

CassandraFactTableIntegrationTest STANDARD_OUT

CassandraFactTableIntegrationTest > shouldRespectOverridesWithValueBasedTtl() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldRespectOverridesWithValueBasedTtl()[31m (3.3s)[m

CassandraFactTableIntegrationTest > shouldInsertAndDelete() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldInsertAndDelete()[31m (3.4s)[m

CassandraFactTableIntegrationTest > shouldInitializeWithCorrectMetadata() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldInitializeWithCorrectMetadata()[31m (3.4s)[m

CassandraFactTableIntegrationTest > shouldRespectSemanticDefaultOnlyTtl() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldRespectSemanticDefaultOnlyTtl()[31m (2.9s)[m

CassandraFactTableIntegrationTest > shouldConfigureDefaultTtl() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldConfigureDefaultTtl()[31m (2.7s)[m

CassandraFactTableIntegrationTest > shouldRespectSemanticKeyValueBasedTtl() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldRespectSemanticKeyValueBasedTtl()[31m (2.8s)[m

CassandraFactTableIntegrationTest STANDARD_ERROR
    Test 13(dev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest): CASSANDRA teardown begins at 1731119665403ms (speed check)

CassandraFactTableIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

CassandraFactTableIntegrationTest STANDARD_ERROR
    Test 13(dev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest): CASSANDRA teardown ends at 1731119668890ms (duration: PT3.487S) (speed check)
    Test 13(dev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest): CASSANDRA test total runtime=PT45.487S) (speed check)

Gradle Test Executor 4 STANDARD_ERROR
    Test 14: creating ResponsiveExtension(empty) at 1731119668894ms (speed check)

CassandraKVTableIntegrationTest STANDARD_ERROR
    Test 14(dev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest): CASSANDRA setup begins at 1731119668901ms (speed check)

CassandraKVTableIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:52911]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

CassandraKVTableIntegrationTest STANDARD_ERROR
    Test 14(dev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest): CASSANDRA setup ends at 1731119693805ms (duration: PT24.904S) (speed check)

CassandraKVTableIntegrationTest > shouldSupportDataKeyThatEqualsMetadataKey() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 52468
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!

  [0K[39mdev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest[m

    [0K[32mâœ”[90m shouldSupportDataKeyThatEqualsMetadataKey()[33m (1.5s)[m

CassandraKVTableIntegrationTest > shouldReturnRangeKeysInLexicalOrderAcrossMultipleSubPartitions() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 52468
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldReturnRangeKeysInLexicalOrderAcrossMultipleSubPartitions()[33m (1.5s)[m

CassandraKVTableIntegrationTest > shouldRespectSemanticDefaultOnlyTtlForRangeQueries() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 52468
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldRespectSemanticDefaultOnlyTtlForRangeQueries()[33m (1.6s)[m

CassandraKVTableIntegrationTest > shouldRespectSemanticDefaultOnlyTtlForLookups() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 52468
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldRespectSemanticDefaultOnlyTtlForLookups()[33m (1.3s)[m

CassandraKVTableIntegrationTest > shouldConfigureDefaultTtl() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 52468
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldConfigureDefaultTtl()[33m (1.6s)[m

CassandraKVTableIntegrationTest > shouldReturnAllKeysInLexicalOrderAcrossMultipleSubPartitions() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 52468
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldReturnAllKeysInLexicalOrderAcrossMultipleSubPartitions()[33m (1.5s)[m

CassandraKVTableIntegrationTest > shouldRespectSemanticDefaultOnlyTtlForAllQueries() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 52468
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32mâœ”[90m shouldRespectSemanticDefaultOnlyTtlForAllQueries()[33m (1.5s)[m

CassandraKVTableIntegrationTest STANDARD_ERROR
    Test 14(dev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest): CASSANDRA teardown begins at 1731119704639ms (speed check)

CassandraKVTableIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

CassandraKVTableIntegrationTest STANDARD_ERROR
    Test 14(dev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest): CASSANDRA teardown ends at 1731119707361ms (duration: PT2.722S) (speed check)
    Test 14(dev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest): CASSANDRA test total runtime=PT38.467S) (speed check)

CassandraKVTableIntegrationTest STANDARD_OUT

Gradle Test Executor 4 STANDARD_ERROR
    Test 15: creating ResponsiveExtension(empty) at 1731119707367ms (speed check)

Gradle Test Executor 4 STANDARD_OUT

GlobalStreamThreadIntegrationTest STANDARD_ERROR
    Test 15(org.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest): CASSANDRA setup begins at 1731119707380ms (speed check)

GlobalStreamThreadIntegrationTest STANDARD_OUT
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (ðŸ³ [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

GlobalStreamThreadIntegrationTest STANDARD_ERROR
    Test 15(org.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest): CASSANDRA setup ends at 1731119729920ms (duration: PT22.54S) (speed check)

GlobalStreamThreadIntegrationTest > shouldRestoreWithSharedPartitionsAcrossApps() STANDARD_OUT
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-30
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldRestoreWithSharedPartitionsAcrossApps-global-27
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldRestoreWithSharedPartitionsAcrossApps-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldRestoreWithSharedPartitionsAcrossApps-global-28
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldRestoreWithSharedPartitionsAcrossApps-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acceptable.recovery.lag = 10000
    	application.id = shouldRestoreWithSharedPartitionsAcrossAppstestAppId
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 5000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	dsl.store.suppliers.class = class org.apache.kafka.streams.state.BuiltInDslStoreSuppliers$RocksDBDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 2000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T/junit8606917264152432141
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldRestoreWithSharedPartitionsAcrossApps-global-29
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldRestoreWithSharedPartitionsAcrossApps-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldRestoreWithSharedPartitionsAcrossApps-global-30
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldRestoreWithSharedPartitionsAcrossApps-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acceptable.recovery.lag = 10000
    	application.id = shouldRestoreWithSharedPartitionsAcrossAppstestAppId
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 5000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	dsl.store.suppliers.class = class org.apache.kafka.streams.state.BuiltInDslStoreSuppliers$RocksDBDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 2000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T/junit459886481728152875
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)

  [0K[39morg.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest[m

    [0K[32mâœ”[90m shouldRestoreWithSharedPartitionsAcrossApps()[31m (3.2s)[m

GlobalStreamThreadIntegrationTest > shouldShareWorkInSteadyState() STANDARD_OUT
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-31
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldShareWorkInSteadyState-global-31
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldShareWorkInSteadyState-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldShareWorkInSteadyState-global-32
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldShareWorkInSteadyState-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acceptable.recovery.lag = 10000
    	application.id = shouldShareWorkInSteadyStatetestAppId
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 5000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	dsl.store.suppliers.class = class org.apache.kafka.streams.state.BuiltInDslStoreSuppliers$RocksDBDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 2000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T/junit18083961367455050919
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldShareWorkInSteadyState-global-33
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldShareWorkInSteadyState-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldShareWorkInSteadyState-global-34
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldShareWorkInSteadyState-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acceptable.recovery.lag = 10000
    	application.id = shouldShareWorkInSteadyStatetestAppId
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:53682]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 5000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	dsl.store.suppliers.class = class org.apache.kafka.streams.state.BuiltInDslStoreSuppliers$RocksDBDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 2000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T/junit11010847153180636437
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    [0K[32mâœ”[90m shouldShareWorkInSteadyState()[31m (3.9s)[m

GlobalStreamThreadIntegrationTest STANDARD_ERROR
    Test 15(org.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest): CASSANDRA teardown begins at 1731119737175ms (speed check)

GlobalStreamThreadIntegrationTest STANDARD_OUT
    org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata

GlobalStreamThreadIntegrationTest STANDARD_ERROR
    Test 15(org.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest): CASSANDRA teardown ends at 1731119741797ms (duration: PT4.622S) (speed check)
    Test 15(org.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest): CASSANDRA test total runtime=PT34.43S) (speed check)

Gradle Test Executor 4 finished executing tests.

> Task :kafka-client:test

  [0K[32m42 passing [90m(17m 35s)
  [0K[36m3 pending[m

Finished generating test XML results (0.399 secs) into: /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/test-results/test
Generating HTML test report...
Finished generating test html results (0.299 secs) into: /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/reports/tests/test

BUILD SUCCESSFUL in 17m 43s
16 actionable tasks: 3 executed, 13 up-to-date
Watched directory hierarchies: [/Users/sophie/Responsive/responsive-pub-copy]
Stopped 1 worker daemon(s).
