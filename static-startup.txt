Initialized native services in: /Users/sophie/.gradle/native
Initialized jansi services in: /Users/sophie/.gradle/native
Received JVM installation metadata from '/Users/sophie/Library/Java/JavaVirtualMachines/corretto-17.0.7/Contents/Home': {JAVA_HOME=/Users/sophie/Library/Java/JavaVirtualMachines/corretto-17.0.7/Contents/Home, JAVA_VERSION=17.0.7, JAVA_VENDOR=Amazon.com Inc., RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=17.0.7+7-LTS, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=17.0.7+7-LTS, VM_VENDOR=Amazon.com Inc., OS_ARCH=aarch64}
The client will now receive all logging from the daemon (pid: 90041). The daemon log file: /Users/sophie/.gradle/daemon/8.1.1/daemon-90041.out.log
Starting 18th build in daemon [uptime: 1 hrs 18 mins 59.668 secs, performance: 100%, GC rate: 0.00/s, heap usage: 0% of 512 MiB, non-heap usage: 27% of 384 MiB]
Using 8 worker leases.
Now considering [/Users/sophie/Responsive/responsive-pub-copy, /Users/sophie/Responsive/responsive-pub-copy/buildSrc] as hierarchies to watch
Now considering [/Users/sophie/Responsive/responsive-pub-copy/buildSrc, /Users/sophie/Responsive/responsive-pub-copy] as hierarchies to watch
Watching the file system is configured to be enabled if available
File system watching is active
Starting Build
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration detachedConfiguration2 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration2 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration detachedConfiguration2 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration2 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Settings evaluated using settings file '/Users/sophie/Responsive/responsive-pub-copy/settings.gradle.kts'.
Skipping generation of dependency accessors for libs as it is up-to-date.
Skipping generation of dependency accessors for testlibs as it is up-to-date.
Projects loaded. Root project using build file '/Users/sophie/Responsive/responsive-pub-copy/build.gradle.kts'.
Included projects: [root project 'responsive-pub', project ':controller-api', project ':kafka-client', project ':kafka-client-bootstrap', project ':kafka-client-examples', project ':operator', project ':responsive-spring', project ':responsive-test-utils', project ':tools', project ':kafka-client-examples:e2e-test', project ':kafka-client-examples:simple-example']

> Configure project :buildSrc
Evaluating project ':buildSrc' using build file '/Users/sophie/Responsive/responsive-pub-copy/buildSrc/build.gradle.kts'.
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :buildSrc:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :buildSrc:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :buildSrc:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :buildSrc:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Using Kotlin Gradle Plugin gradle76 variant
kotlin scripting plugin: created the scripting discovery configuration: kotlinScriptDef
kotlin scripting plugin: created the scripting discovery configuration: testKotlinScriptDef
file or directory '/Users/sophie/Responsive/responsive-pub-copy/buildSrc/src/main/java', not found
Caching disabled for Kotlin DSL accessors for project ':buildSrc' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':buildSrc' as it is up-to-date.
The configuration :buildSrc:mainSourceElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Resolve mutations for :buildSrc:generateExternalPluginSpecBuilders (Thread[Execution worker,5,main]) started.
:buildSrc:generateExternalPluginSpecBuilders (Thread[Execution worker,5,main]) started.

> Task :buildSrc:generateExternalPluginSpecBuilders UP-TO-DATE
Caching disabled for task ':buildSrc:generateExternalPluginSpecBuilders' because:
  Build cache is disabled
Skipping task ':buildSrc:generateExternalPluginSpecBuilders' as it is up-to-date.
Resolve mutations for :buildSrc:extractPrecompiledScriptPluginPlugins (Thread[Execution worker,5,main]) started.
:buildSrc:extractPrecompiledScriptPluginPlugins (Thread[Execution worker,5,main]) started.

> Task :buildSrc:extractPrecompiledScriptPluginPlugins UP-TO-DATE
Caching disabled for task ':buildSrc:extractPrecompiledScriptPluginPlugins' because:
  Build cache is disabled
Skipping task ':buildSrc:extractPrecompiledScriptPluginPlugins' as it is up-to-date.
Resolve mutations for :buildSrc:compilePluginsBlocks (Thread[Execution worker,5,main]) started.
:buildSrc:compilePluginsBlocks (Thread[Execution worker,5,main]) started.

> Task :buildSrc:compilePluginsBlocks UP-TO-DATE
Caching disabled for task ':buildSrc:compilePluginsBlocks' because:
  Build cache is disabled
Skipping task ':buildSrc:compilePluginsBlocks' as it is up-to-date.
Resolve mutations for :buildSrc:generatePrecompiledScriptPluginAccessors (Thread[Execution worker,5,main]) started.
:buildSrc:generatePrecompiledScriptPluginAccessors (Thread[Execution worker,5,main]) started.

> Task :buildSrc:generatePrecompiledScriptPluginAccessors UP-TO-DATE
Caching disabled for task ':buildSrc:generatePrecompiledScriptPluginAccessors' because:
  Build cache is disabled
Skipping task ':buildSrc:generatePrecompiledScriptPluginAccessors' as it is up-to-date.
Resolve mutations for :buildSrc:generateScriptPluginAdapters (Thread[Execution worker,5,main]) started.
:buildSrc:generateScriptPluginAdapters (Thread[Execution worker,5,main]) started.

> Task :buildSrc:generateScriptPluginAdapters UP-TO-DATE
Caching disabled for task ':buildSrc:generateScriptPluginAdapters' because:
  Build cache is disabled
Skipping task ':buildSrc:generateScriptPluginAdapters' as it is up-to-date.
Resolve mutations for :buildSrc:compileKotlin (Thread[Execution worker,5,main]) started.
:buildSrc:compileKotlin (Thread[Execution worker,5,main]) started.

> Task :buildSrc:compileKotlin UP-TO-DATE
Custom actions are attached to task ':buildSrc:compileKotlin'.
Caching disabled for task ':buildSrc:compileKotlin' because:
  Build cache is disabled
Skipping task ':buildSrc:compileKotlin' as it is up-to-date.
Resolve mutations for :buildSrc:compileJava (Thread[Execution worker,5,main]) started.
:buildSrc:compileJava (Thread[Execution worker,5,main]) started.

> Task :buildSrc:compileJava NO-SOURCE
Skipping task ':buildSrc:compileJava' as it has no source files and no previous output files.
Resolve mutations for :buildSrc:compileGroovy (Thread[Execution worker,5,main]) started.
:buildSrc:compileGroovy (Thread[Execution worker,5,main]) started.

> Task :buildSrc:compileGroovy NO-SOURCE
Skipping task ':buildSrc:compileGroovy' as it has no source files and no previous output files.
Resolve mutations for :buildSrc:pluginDescriptors (Thread[Execution worker,5,main]) started.
:buildSrc:pluginDescriptors (Thread[Execution worker,5,main]) started.

> Task :buildSrc:pluginDescriptors UP-TO-DATE
Caching disabled for task ':buildSrc:pluginDescriptors' because:
  Build cache is disabled
  Not worth caching
Skipping task ':buildSrc:pluginDescriptors' as it is up-to-date.
Resolve mutations for :buildSrc:processResources (Thread[Execution worker,5,main]) started.
:buildSrc:processResources (Thread[Execution worker,5,main]) started.

> Task :buildSrc:processResources UP-TO-DATE
Caching disabled for task ':buildSrc:processResources' because:
  Build cache is disabled
  Not worth caching
Skipping task ':buildSrc:processResources' as it is up-to-date.
Resolve mutations for :buildSrc:classes (Thread[Execution worker,5,main]) started.
:buildSrc:classes (Thread[Execution worker,5,main]) started.

> Task :buildSrc:classes UP-TO-DATE
Skipping task ':buildSrc:classes' as it has no actions.
Resolve mutations for :buildSrc:jar (Thread[Execution worker,5,main]) started.
:buildSrc:jar (Thread[Execution worker,5,main]) started.

> Task :buildSrc:jar UP-TO-DATE
Caching disabled for task ':buildSrc:jar' because:
  Build cache is disabled
  Not worth caching
Skipping task ':buildSrc:jar' as it is up-to-date.
Resolve mutations for :buildSrc:inspectClassesForKotlinIC (Thread[Execution worker,5,main]) started.
:buildSrc:inspectClassesForKotlinIC (Thread[Execution worker,5,main]) started.

> Task :buildSrc:inspectClassesForKotlinIC UP-TO-DATE
Caching disabled for task ':buildSrc:inspectClassesForKotlinIC' because:
  Build cache is disabled
  Caching has been disabled for the task
Skipping task ':buildSrc:inspectClassesForKotlinIC' as it is up-to-date.

> Configure project :
Evaluating root project 'responsive-pub' using build file '/Users/sophie/Responsive/responsive-pub-copy/build.gradle.kts'.
The configuration :classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for root project 'responsive-pub' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for root project 'responsive-pub' as it is up-to-date.

> Configure project :controller-api
Evaluating project ':controller-api' using build file '/Users/sophie/Responsive/responsive-pub-copy/controller-api/build.gradle.kts'.
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration detachedConfiguration1 is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration detachedConfiguration1 is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :controller-api:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :controller-api:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :controller-api:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :controller-api:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The com.google.protobuf plugin was already applied to the project: :controller-api and will not be applied again after plugin: java-library
Caching disabled for Kotlin DSL accessors for project ':controller-api' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':controller-api' as it is up-to-date.
------------------------------------------------------------------------
Detecting the operating system and CPU architecture
------------------------------------------------------------------------
os.detected.name=osx
os.detected.arch=aarch_64
os.detected.bitness=64
os.detected.version=13.3
os.detected.version.major=13
os.detected.version.minor=3
os.detected.classifier=osx-aarch_64

> Configure project :kafka-client
Evaluating project ':kafka-client' using build file '/Users/sophie/Responsive/responsive-pub-copy/kafka-client/build.gradle.kts'.
The configuration :kafka-client:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':kafka-client' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':kafka-client' as it is up-to-date.

> Configure project :kafka-client-bootstrap
Evaluating project ':kafka-client-bootstrap' using build file '/Users/sophie/Responsive/responsive-pub-copy/kafka-client-bootstrap/build.gradle.kts'.
The configuration :kafka-client-bootstrap:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-bootstrap:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client-bootstrap:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-bootstrap:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':kafka-client-bootstrap' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':kafka-client-bootstrap' as it is up-to-date.

> Configure project :kafka-client-examples
Evaluating project ':kafka-client-examples' using build file '/Users/sophie/Responsive/responsive-pub-copy/kafka-client-examples/build.gradle'.

> Configure project :operator
Evaluating project ':operator' using build file '/Users/sophie/Responsive/responsive-pub-copy/operator/build.gradle.kts'.
The configuration :operator:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :operator:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :operator:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :operator:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':operator' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':operator' as it is up-to-date.

> Configure project :responsive-spring
Evaluating project ':responsive-spring' using build file '/Users/sophie/Responsive/responsive-pub-copy/responsive-spring/build.gradle.kts'.
The configuration :responsive-spring:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :responsive-spring:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :responsive-spring:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :responsive-spring:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':responsive-spring' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':responsive-spring' as it is up-to-date.

> Configure project :responsive-test-utils
Evaluating project ':responsive-test-utils' using build file '/Users/sophie/Responsive/responsive-pub-copy/responsive-test-utils/build.gradle.kts'.
The configuration :responsive-test-utils:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :responsive-test-utils:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :responsive-test-utils:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :responsive-test-utils:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':responsive-test-utils' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':responsive-test-utils' as it is up-to-date.
Starting process 'command '/usr/libexec/java_home''. Working directory: /Users/sophie/.gradle/daemon/8.1.1 Command: /usr/libexec/java_home -V
Successfully started process 'command '/usr/libexec/java_home''

> Configure project :tools
Evaluating project ':tools' using build file '/Users/sophie/Responsive/responsive-pub-copy/tools/build.gradle.kts'.
The configuration :tools:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :tools:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :tools:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :tools:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':tools' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':tools' as it is up-to-date.
The configuration :tools:javadocElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :tools:mainSourceElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :tools:signatures is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :tools:signatures is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :tools:sourcesElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.

> Configure project :kafka-client-examples:e2e-test
Evaluating project ':kafka-client-examples:e2e-test' using build file '/Users/sophie/Responsive/responsive-pub-copy/kafka-client-examples/e2e-test/build.gradle.kts'.
The configuration :kafka-client-examples:e2e-test:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-examples:e2e-test:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client-examples:e2e-test:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-examples:e2e-test:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':kafka-client-examples:e2e-test' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':kafka-client-examples:e2e-test' as it is up-to-date.
Starting process 'command 'git''. Working directory: /Users/sophie/Responsive/responsive-pub-copy Command: git rev-parse --short HEAD
Successfully started process 'command 'git''

> Configure project :kafka-client-examples:simple-example
Evaluating project ':kafka-client-examples:simple-example' using build file '/Users/sophie/Responsive/responsive-pub-copy/kafka-client-examples/simple-example/build.gradle.kts'.
The configuration :kafka-client-examples:simple-example:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-examples:simple-example:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client-examples:simple-example:classpath is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client-examples:simple-example:classpath is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Caching disabled for Kotlin DSL accessors for project ':kafka-client-examples:simple-example' because:
  Build cache is disabled
Skipping Kotlin DSL accessors for project ':kafka-client-examples:simple-example' as it is up-to-date.
All projects evaluated.
Task path 'kafka-client:test' matched project ':kafka-client'
Task name matched 'test'
Selected primary task 'test' from project :kafka-client
The configuration :kafka-client:javadocElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client:mainSourceElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client:signatures is both resolvable and consumable. This is considered a legacy configuration and it will eventually only be possible to be one of these.
The configuration :kafka-client:signatures is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
The configuration :kafka-client:sourcesElements is both consumable and declarable. This combination is incorrect, only one of these flags should be set.
Tasks to be executed: [task ':kafka-client:writeVersionPropertiesFile', task ':kafka-client:compileJava', task ':kafka-client:processResources', task ':kafka-client:classes', task ':kafka-client:compileTestJava', task ':kafka-client:processTestResources', task ':kafka-client:testClasses', task ':kafka-client:test']
Tasks that were excluded: []
Resolve mutations for :kafka-client:writeVersionPropertiesFile (Thread[Execution worker Thread 2,5,main]) started.
:kafka-client:writeVersionPropertiesFile (Thread[Execution worker Thread 2,5,main]) started.

> Task :kafka-client:writeVersionPropertiesFile UP-TO-DATE
Custom actions are attached to task ':kafka-client:writeVersionPropertiesFile'.
Caching disabled for task ':kafka-client:writeVersionPropertiesFile' because:
  Build cache is disabled
  Gradle would require more information to cache this task
Skipping task ':kafka-client:writeVersionPropertiesFile' as it is up-to-date.
Resolve mutations for :kafka-client:compileJava (Thread[Execution worker Thread 2,5,main]) started.
:kafka-client:compileJava (Thread[Execution worker Thread 2,5,main]) started.

> Task :kafka-client:compileJava UP-TO-DATE
Caching disabled for task ':kafka-client:compileJava' because:
  Build cache is disabled
Skipping task ':kafka-client:compileJava' as it is up-to-date.
Resolve mutations for :kafka-client:processResources (Thread[Execution worker Thread 2,5,main]) started.
:kafka-client:processResources (Thread[Execution worker Thread 2,5,main]) started.

> Task :kafka-client:processResources UP-TO-DATE
Caching disabled for task ':kafka-client:processResources' because:
  Build cache is disabled
  Not worth caching
Skipping task ':kafka-client:processResources' as it is up-to-date.
Resolve mutations for :kafka-client:classes (Thread[Execution worker Thread 2,5,main]) started.
:kafka-client:classes (Thread[Execution worker Thread 2,5,main]) started.

> Task :kafka-client:classes UP-TO-DATE
Skipping task ':kafka-client:classes' as it has no actions.
Resolve mutations for :kafka-client:compileTestJava (Thread[Execution worker Thread 2,5,main]) started.
:kafka-client:compileTestJava (Thread[Execution worker Thread 2,5,main]) started.
This JVM does not support getting OS memory, so no OS memory status updates will be broadcast

> Task :kafka-client:compileTestJava
Caching disabled for task ':kafka-client:compileTestJava' because:
  Build cache is disabled
Task ':kafka-client:compileTestJava' is not up-to-date because:
  Output property 'destinationDirectory' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/classes/java/test has been removed.
  Output property 'destinationDirectory' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/classes/java/test/dev has been removed.
  Output property 'destinationDirectory' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/classes/java/test/dev/responsive has been removed.
  Output property 'destinationDirectory' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/classes/java/test/org has been removed.
  Output property 'options.generatedSourceOutputDirectory' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/generated/sources/annotationProcessor/java/test has been removed.
The input changes require a full rebuild for incremental task ':kafka-client:compileTestJava'.
Full recompilation is required because no incremental change information is available. This is usually caused by clean builds or changing compiler arguments.
Compiling with toolchain '/Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home'.
Starting process 'Gradle Worker Daemon 9'. Working directory: /Users/sophie/.gradle/workers Command: /Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home/bin/java @/Users/sophie/.gradle/.tmp/gradle-worker-classpath526971371318988036txt -Xmx512m -Dfile.encoding=UTF-8 -Duser.country=US -Duser.language=en -Duser.variant worker.org.gradle.process.internal.worker.GradleWorkerMain 'Gradle Worker Daemon 9'
Successfully started process 'Gradle Worker Daemon 9'
Started Gradle worker daemon (0.273 secs) with fork options DaemonForkOptions{executable=/Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home/bin/java, minHeapSize=null, maxHeapSize=null, jvmArgs=[], keepAliveMode=SESSION}.
Compiling with JDK Java compiler API.
Class dependency analysis for incremental compilation took 0.032 secs.
Created classpath snapshot for incremental compilation in 0.031 secs.
Resolve mutations for :kafka-client:processTestResources (Thread[Execution worker Thread 2,5,main]) started.
:kafka-client:processTestResources (Thread[Execution worker Thread 3,5,main]) started.

> Task :kafka-client:processTestResources
Caching disabled for task ':kafka-client:processTestResources' because:
  Build cache is disabled
  Not worth caching
Task ':kafka-client:processTestResources' is not up-to-date because:
  Output property 'destinationDir' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/resources/test has been removed.
  Output property 'destinationDir' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/resources/test/CassandraDockerInit.cql has been removed.
  Output property 'destinationDir' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/resources/test/junit-platform.properties has been removed.
  Output property 'destinationDir' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/resources/test/log4j.properties has been removed.
  Output property 'destinationDir' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/resources/test/testcontainers.properties has been removed.
Resolve mutations for :kafka-client:testClasses (Thread[Execution worker Thread 3,5,main]) started.
:kafka-client:testClasses (Thread[Execution worker Thread 3,5,main]) started.

> Task :kafka-client:testClasses
Skipping task ':kafka-client:testClasses' as it has no actions.
Resolve mutations for :kafka-client:test (Thread[Execution worker Thread 3,5,main]) started.
:kafka-client:test (Thread[Execution worker Thread 3,5,main]) started.
Gradle Test Executor 10 started executing tests.

> Task :kafka-client:test
Custom actions are attached to task ':kafka-client:test'.
Caching disabled for task ':kafka-client:test' because:
  Build cache is disabled
Task ':kafka-client:test' is not up-to-date because:
  Output property 'binaryResultsDirectory' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/test-results/test/binary has been removed.
  Output property 'binaryResultsDirectory' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/test-results/test/binary/output.bin has been removed.
  Output property 'binaryResultsDirectory' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/test-results/test/binary/output.bin.idx has been removed.
  Output property 'binaryResultsDirectory' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/test-results/test/binary/results.bin has been removed.
  Output property 'reports.enabledReports.html.outputLocation' file /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/reports/tests/test has been removed.

Starting process 'Gradle Test Executor 10'. Working directory: /Users/sophie/Responsive/responsive-pub-copy/kafka-client Command: /Users/sophie/Library/Java/JavaVirtualMachines/corretto-11.0.18/Contents/Home/bin/java -Dorg.gradle.internal.worker.tmpdir=/Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/tmp/test/work -Dorg.gradle.native=false @/Users/sophie/.gradle/.tmp/gradle-worker-classpath10159029677607584367txt -Xmx512m -Dfile.encoding=UTF-8 -Duser.country=US -Duser.language=en -Duser.variant -ea worker.org.gradle.process.internal.worker.GradleWorkerMain 'Gradle Test Executor 10'
Successfully started process 'Gradle Test Executor 10'

Gradle Test Executor 10 STANDARD_OUT

Gradle Test Executor 10 STANDARD_ERROR
    Starting up containers at 1731122441551ms (speed check)

Gradle Test Executor 10 STANDARD_OUT
      Server Version: 23.0.5
      API Version: 1.42
      Operating System: Docker Desktop
      Total Memory: 3933 MB (org.testcontainers.DockerClientFactory:205)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (🐳 [cassandra:4.1.0]:409)
    To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/sophie/.testcontainers.properties (🐳 [confluentinc/cp-kafka:7.3.2]:409)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)

Gradle Test Executor 10 STANDARD_ERROR
    Test 1: creating ResponsiveExtension(backend=CASSANDRA) at 1731122470408ms (speed check)

AsyncProcessorIntegrationTest STANDARD_ERROR
    SOPHIE: speed check version 1
    Test 1(dev.responsive.kafka.async.AsyncProcessorIntegrationTest): CASSANDRA setup begins at 1731122470437ms (speed check)
    Test 1(dev.responsive.kafka.async.AsyncProcessorIntegrationTest): CASSANDRA setup ends at 1731122470437ms (duration: PT0S) (speed check)

AsyncProcessorIntegrationTest > shouldProcessStatefulEventsInOrderByKey() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-1
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InputRecordSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 5
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 9223372036854775807
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldProcessStatefulEventsInOrderByKey
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 30000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 4
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatefulEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-2-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-2-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-2
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-2-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatefulEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-3-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-3-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-3
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-3-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatefulEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-4-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-4-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-4
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-4-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatefulEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    9690668f-060d-4b31-b9a5-197b7276859c: [shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-1-consumer-6e3f925c-08f8-452f-84c0-c41c21309349, shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-2-consumer-669c00d2-7d9f-4c9d-8c79-57ac96f6fd96, shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-3-consumer-606abb09-78ad-44bf-8b88-73ff4b5cf740, shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-4-consumer-1f381894-2615-4177-a708-2d9259c28d5d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-1-consumer-6e3f925c-08f8-452f-84c0-c41c21309349=[], shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-2-consumer-669c00d2-7d9f-4c9d-8c79-57ac96f6fd96=[], shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-3-consumer-606abb09-78ad-44bf-8b88-73ff4b5cf740=[], shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-4-consumer-1f381894-2615-4177-a708-2d9259c28d5d=[]}
    	assigned active {shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-1-consumer-6e3f925c-08f8-452f-84c0-c41c21309349=[0_8, 0_4, 0_0], shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-2-consumer-669c00d2-7d9f-4c9d-8c79-57ac96f6fd96=[0_9, 0_5, 0_1], shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-3-consumer-606abb09-78ad-44bf-8b88-73ff4b5cf740=[0_10, 0_6, 0_2], shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-4-consumer-1f381894-2615-4177-a708-2d9259c28d5d=[0_11, 0_7, 0_3]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-3, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-7, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-11]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-3, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-7, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-11]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-0, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-4, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-0, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-4, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-1, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-5, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-9]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-1, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-5, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-9]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-2, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-6, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-10]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-2, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-6, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-10]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput, partition=8, offset=6, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput, partition=8, offset=6, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-5-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-5-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-5
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-5-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatefulEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.ProcessorStateException: stream-thread [shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-1] stream-task [0_0] Failed to flush cache of store shouldProcessStatefulEventsInOrderByKeya1
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:546)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.ProcessorStateException: stream-thread [shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-1] stream-task [0_4] Failed to flush cache of store shouldProcessStatefulEventsInOrderByKeya1
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:546)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.ProcessorStateException: stream-thread [shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-1] stream-task [0_8] Failed to flush cache of store shouldProcessStatefulEventsInOrderByKeya1
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:546)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatefulAsyncProcessor(AsyncProcessorIntegrationTest.java:701)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    9690668f-060d-4b31-b9a5-197b7276859c: [shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-2-consumer-669c00d2-7d9f-4c9d-8c79-57ac96f6fd96, shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-3-consumer-606abb09-78ad-44bf-8b88-73ff4b5cf740, shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-4-consumer-1f381894-2615-4177-a708-2d9259c28d5d, shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-5-consumer-a79d3c49-aca7-4aca-b49b-16c9d5bf6af8]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-2-consumer-669c00d2-7d9f-4c9d-8c79-57ac96f6fd96=[0_9, 0_5, 0_1], shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-3-consumer-606abb09-78ad-44bf-8b88-73ff4b5cf740=[0_10, 0_6, 0_2], shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-4-consumer-1f381894-2615-4177-a708-2d9259c28d5d=[0_11, 0_7, 0_3]}
    	prev owned standby {shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-2-consumer-669c00d2-7d9f-4c9d-8c79-57ac96f6fd96=[], shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-3-consumer-606abb09-78ad-44bf-8b88-73ff4b5cf740=[], shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-4-consumer-1f381894-2615-4177-a708-2d9259c28d5d=[], shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-5-consumer-a79d3c49-aca7-4aca-b49b-16c9d5bf6af8=[]}
    	assigned active {shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-2-consumer-669c00d2-7d9f-4c9d-8c79-57ac96f6fd96=[0_9, 0_5, 0_1], shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-3-consumer-606abb09-78ad-44bf-8b88-73ff4b5cf740=[0_10, 0_6, 0_2], shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-4-consumer-1f381894-2615-4177-a708-2d9259c28d5d=[0_11, 0_7, 0_3], shouldProcessStatefulEventsInOrderByKey-9690668f-060d-4b31-b9a5-197b7276859c-StreamThread-5-consumer-a79d3c49-aca7-4aca-b49b-16c9d5bf6af8=[0_8, 0_4, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-3, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-7, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-11]
    	Current owned partitions:                  [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-3, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-7, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-11]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: [0_11, 0_7, 0_3]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-2, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-6, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-10]
    	Current owned partitions:                  [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-2, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-6, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-10]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: [0_10, 0_6, 0_2]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-1, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-5, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-9]
    	Current owned partitions:                  [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-1, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-5, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-9]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: [0_9, 0_5, 0_1]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-0, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-4, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-0, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-4, shouldProcessStatefulEventsInOrderByKey.shouldProcessStatefulEventsInOrderByKeyinput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-1
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
  [0K[39mdev.responsive.kafka.async.AsyncProcessorIntegrationTest[m

    [0K[32m✔[90m shouldProcessStatefulEventsInOrderByKey()[31m (52.4s)[m

AsyncProcessorIntegrationTest > shouldProcessStatelessEventsInOrderByKey() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-2
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InputRecordSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 5
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 9223372036854775807
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldProcessStatelessEventsInOrderByKey
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 30000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 4
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatelessEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-2-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-2-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-2
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-2-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatelessEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-3-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-3-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-3
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-3-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatelessEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-4-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-4-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-4
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-4-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatelessEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    92134eae-30ff-43aa-b203-aa463eb35458: [shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-2-consumer-94d86598-ca1f-42d6-8448-a4671c98e767]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-2-consumer-94d86598-ca1f-42d6-8448-a4671c98e767=[]}
    	assigned active {shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-2-consumer-94d86598-ca1f-42d6-8448-a4671c98e767=[0_11, 0_10, 0_9, 0_8, 0_7, 0_6, 0_5, 0_4, 0_3, 0_2, 0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    92134eae-30ff-43aa-b203-aa463eb35458: [shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-1-consumer-e25019a1-a3d6-46a0-84e4-abc32f826338, shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-2-consumer-94d86598-ca1f-42d6-8448-a4671c98e767, shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-3-consumer-aa539954-5126-4873-88db-26c4a9bf6894, shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-4-consumer-1f79e6ef-f8b3-4d08-896f-7628c2c94bb6]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-1-consumer-e25019a1-a3d6-46a0-84e4-abc32f826338=[], shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-2-consumer-94d86598-ca1f-42d6-8448-a4671c98e767=[], shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-3-consumer-aa539954-5126-4873-88db-26c4a9bf6894=[], shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-4-consumer-1f79e6ef-f8b3-4d08-896f-7628c2c94bb6=[]}
    	assigned active {shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-1-consumer-e25019a1-a3d6-46a0-84e4-abc32f826338=[0_8, 0_4, 0_0], shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-2-consumer-94d86598-ca1f-42d6-8448-a4671c98e767=[0_9, 0_5, 0_1], shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-3-consumer-aa539954-5126-4873-88db-26c4a9bf6894=[0_10, 0_6, 0_2], shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-4-consumer-1f79e6ef-f8b3-4d08-896f-7628c2c94bb6=[0_11, 0_7, 0_3]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-3, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-7, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-11]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-3, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-7, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-11]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-1, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-5, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-9]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-1, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-5, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-9]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-0, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-4, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-0, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-4, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-2, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-6, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-10]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-2, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-6, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-10]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput, partition=8, offset=4, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatelessAsyncProcessor(AsyncProcessorIntegrationTest.java:675)
    	at dev.responsive.kafka.testutils.SimpleStatelessProcessorSupplier$SimpleStatelessProcessor.process(SimpleStatelessProcessorSupplier.java:65)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatelessAsyncProcessor(AsyncProcessorIntegrationTest.java:675)
    	at dev.responsive.kafka.testutils.SimpleStatelessProcessorSupplier$SimpleStatelessProcessor.process(SimpleStatelessProcessorSupplier.java:65)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput, partition=8, offset=4, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatelessAsyncProcessor(AsyncProcessorIntegrationTest.java:675)
    	at dev.responsive.kafka.testutils.SimpleStatelessProcessorSupplier$SimpleStatelessProcessor.process(SimpleStatelessProcessorSupplier.java:65)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:216)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:101)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.computeNewValueForSingleStatelessAsyncProcessor(AsyncProcessorIntegrationTest.java:675)
    	at dev.responsive.kafka.testutils.SimpleStatelessProcessorSupplier$SimpleStatelessProcessor.process(SimpleStatelessProcessorSupplier.java:65)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-5-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-5-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-5
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-5-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldProcessStatelessEventsInOrderByKey
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent. (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:322)
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent. (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:322)
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldProcessStatelessEventsInOrderByKey-shouldProcessStatelessEventsInOrderByKeyin-changelog for task 0_4 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:314)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.abort(ProducerBatch.java:200)
    	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortUndrainedBatches(RecordAccumulator.java:1160)
    	at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:473)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:337)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    org.apache.kafka.streams.errors.StreamsException: Error encountered sending record to topic shouldProcessStatelessEventsInOrderByKey-shouldProcessStatelessEventsInOrderByKeyin-changelog for task 0_8 due to:
    org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    Exception handler choose to FAIL the processing, no more records would be sent.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:314)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.abort(ProducerBatch.java:200)
    	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortUndrainedBatches(RecordAccumulator.java:1160)
    	at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:473)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:337)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.TransactionAbortedException: Failing batch since transaction was aborted
    92134eae-30ff-43aa-b203-aa463eb35458: [shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-2-consumer-94d86598-ca1f-42d6-8448-a4671c98e767, shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-3-consumer-aa539954-5126-4873-88db-26c4a9bf6894, shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-4-consumer-1f79e6ef-f8b3-4d08-896f-7628c2c94bb6, shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-5-consumer-5ed7fef7-66fa-4326-8064-6de12b6e304e]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-2-consumer-94d86598-ca1f-42d6-8448-a4671c98e767=[0_9, 0_5, 0_1], shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-3-consumer-aa539954-5126-4873-88db-26c4a9bf6894=[0_10, 0_6, 0_2], shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-4-consumer-1f79e6ef-f8b3-4d08-896f-7628c2c94bb6=[0_11, 0_7, 0_3]}
    	prev owned standby {shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-2-consumer-94d86598-ca1f-42d6-8448-a4671c98e767=[], shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-3-consumer-aa539954-5126-4873-88db-26c4a9bf6894=[], shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-4-consumer-1f79e6ef-f8b3-4d08-896f-7628c2c94bb6=[], shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-5-consumer-5ed7fef7-66fa-4326-8064-6de12b6e304e=[]}
    	assigned active {shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-2-consumer-94d86598-ca1f-42d6-8448-a4671c98e767=[0_9, 0_5, 0_1], shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-3-consumer-aa539954-5126-4873-88db-26c4a9bf6894=[0_10, 0_6, 0_2], shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-4-consumer-1f79e6ef-f8b3-4d08-896f-7628c2c94bb6=[0_11, 0_7, 0_3], shouldProcessStatelessEventsInOrderByKey-92134eae-30ff-43aa-b203-aa463eb35458-StreamThread-5-consumer-5ed7fef7-66fa-4326-8064-6de12b6e304e=[0_8, 0_4, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-3, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-7, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-11]
    	Current owned partitions:                  [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-3, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-7, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-11]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: [0_11, 0_7, 0_3]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-1, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-5, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-9]
    	Current owned partitions:                  [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-1, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-5, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-9]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-2, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-6, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-10]
    	Current owned partitions:                  [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-2, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-6, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-10]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-0, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-4, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-0, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-4, shouldProcessStatelessEventsInOrderByKey.shouldProcessStatelessEventsInOrderByKeyinput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: [0_10, 0_6, 0_2]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: [0_9, 0_5, 0_1]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-2
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    [0K[32m✔[90m shouldProcessStatelessEventsInOrderByKey()[31m (44.5s)[m

AsyncProcessorIntegrationTest > shouldExecuteMultipleMixedAsyncProcessorsNoCaching() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-3
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InputRecordSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 5
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 9223372036854775807
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 30000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 4
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-2-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-2-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-2
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-2-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-3-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-3-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-3
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-3-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-4-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-4-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-4
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-4-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    3cd1b0d3-45f6-4201-a04c-428a989a2112: [shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-2-consumer-3ea48db6-b56f-4b42-b43d-912cc4f0fe38, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-3-consumer-5c4e5c6a-d2f7-4330-b4d6-1921c8ac7c4c]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-2-consumer-3ea48db6-b56f-4b42-b43d-912cc4f0fe38=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-3-consumer-5c4e5c6a-d2f7-4330-b4d6-1921c8ac7c4c=[]}
    	assigned active {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-2-consumer-3ea48db6-b56f-4b42-b43d-912cc4f0fe38=[0_10, 0_8, 0_6, 0_4, 0_2, 0_0], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-3-consumer-5c4e5c6a-d2f7-4330-b4d6-1921c8ac7c4c=[0_11, 0_9, 0_7, 0_5, 0_3, 0_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    3cd1b0d3-45f6-4201-a04c-428a989a2112: [shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-1-consumer-17030f93-ab6c-473a-a094-2a373b37c76f, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-2-consumer-3ea48db6-b56f-4b42-b43d-912cc4f0fe38, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-3-consumer-5c4e5c6a-d2f7-4330-b4d6-1921c8ac7c4c, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-4-consumer-d1a99615-be46-49d4-a579-ec96e07ab4b0]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-1-consumer-17030f93-ab6c-473a-a094-2a373b37c76f=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-2-consumer-3ea48db6-b56f-4b42-b43d-912cc4f0fe38=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-3-consumer-5c4e5c6a-d2f7-4330-b4d6-1921c8ac7c4c=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-4-consumer-d1a99615-be46-49d4-a579-ec96e07ab4b0=[]}
    	assigned active {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-1-consumer-17030f93-ab6c-473a-a094-2a373b37c76f=[0_8, 0_4, 0_0], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-2-consumer-3ea48db6-b56f-4b42-b43d-912cc4f0fe38=[0_9, 0_5, 0_1], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-3-consumer-5c4e5c6a-d2f7-4330-b4d6-1921c8ac7c4c=[0_10, 0_6, 0_2], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-4-consumer-d1a99615-be46-49d4-a579-ec96e07ab4b0=[0_11, 0_7, 0_3]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-0, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-4, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-0, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-4, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-2, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-6, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-10]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-2, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-6, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-10]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-1, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-5, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-9]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-1, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-5, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-9]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-3, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-7, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-11]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-3, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-7, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-11]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-3
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput, partition=8, offset=11, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.StreamsException: Exception caught in process. taskId=0_8, processor=KSTREAM-SOURCE-0000000000, topic=shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput, partition=8, offset=11, stacktrace=dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more

    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:804)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	... 6 more
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-5-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-5-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-5
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-5-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldExecuteMultipleMixedAsyncProcessorsNoCaching
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.ProcessorStateException: stream-thread [shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-1] stream-task [0_0] Failed to flush cache of store shouldExecuteMultipleMixedAsyncProcessorsNoCachinga1
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:546)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.ProcessorStateException: stream-thread [shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-1] stream-task [0_4] Failed to flush cache of store shouldExecuteMultipleMixedAsyncProcessorsNoCachinga1
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:546)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    org.apache.kafka.streams.errors.ProcessorStateException: stream-thread [shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-1] stream-task [0_8] Failed to flush cache of store shouldExecuteMultipleMixedAsyncProcessorsNoCachinga1
    	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:546)
    	at org.apache.kafka.streams.processor.internals.StreamTask.flush(StreamTask.java:413)
    	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:437)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:1326)
    	at org.apache.kafka.streams.processor.internals.TaskManager.closeAndCleanUpTasks(TaskManager.java:1488)
    	at org.apache.kafka.streams.processor.internals.TaskManager.lambda$shutdown$5(TaskManager.java:1372)
    	at org.apache.kafka.streams.processor.internals.TaskManager.executeAndMaybeSwallow(TaskManager.java:2042)
    	at org.apache.kafka.streams.processor.internals.TaskManager.shutdown(TaskManager.java:1370)
    	at org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown(StreamThread.java:1403)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:652)
    Caused by: dev.responsive.kafka.api.async.internals.FatalAsyncException: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.processNewAsyncEvent(AsyncProcessor.java:340)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.process(AsyncProcessor.java:318)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:154)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:291)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:270)
    	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:229)
    	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84)
    	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$doProcess$1(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:872)
    	at org.apache.kafka.streams.processor.internals.StreamTask.doProcess(StreamTask.java:847)
    	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:778)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.processTask(TaskExecutor.java:97)
    	at org.apache.kafka.streams.processor.internals.TaskExecutor.process(TaskExecutor.java:78)
    	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1938)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:953)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: org.apache.kafka.streams.errors.StreamsException: Exception caught during async processing
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:301)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:266)
    	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
    	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedException
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest$InjectedFault.maybeInject(AsyncProcessorIntegrationTest.java:870)
    	at dev.responsive.kafka.async.AsyncProcessorIntegrationTest.lambda$shouldExecuteMultipleMixedAsyncProcessorsNoCaching$1(AsyncProcessorIntegrationTest.java:257)
    	at dev.responsive.kafka.testutils.SimpleStatefulProcessor.process(SimpleStatefulProcessor.java:97)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.lambda$process$1(AsyncProcessor.java:314)
    	at dev.responsive.kafka.api.async.internals.AsyncThreadPool$AsyncEventTask.get(AsyncThreadPool.java:299)
    	... 5 more
    3cd1b0d3-45f6-4201-a04c-428a989a2112: [shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-2-consumer-3ea48db6-b56f-4b42-b43d-912cc4f0fe38, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-3-consumer-5c4e5c6a-d2f7-4330-b4d6-1921c8ac7c4c, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-4-consumer-d1a99615-be46-49d4-a579-ec96e07ab4b0, shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-5-consumer-187ea991-1f7f-4485-ba51-4bee01afaa3a]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-2-consumer-3ea48db6-b56f-4b42-b43d-912cc4f0fe38=[0_9, 0_5, 0_1], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-3-consumer-5c4e5c6a-d2f7-4330-b4d6-1921c8ac7c4c=[0_10, 0_6, 0_2], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-4-consumer-d1a99615-be46-49d4-a579-ec96e07ab4b0=[0_11, 0_7, 0_3]}
    	prev owned standby {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-2-consumer-3ea48db6-b56f-4b42-b43d-912cc4f0fe38=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-3-consumer-5c4e5c6a-d2f7-4330-b4d6-1921c8ac7c4c=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-4-consumer-d1a99615-be46-49d4-a579-ec96e07ab4b0=[], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-5-consumer-187ea991-1f7f-4485-ba51-4bee01afaa3a=[]}
    	assigned active {shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-2-consumer-3ea48db6-b56f-4b42-b43d-912cc4f0fe38=[0_9, 0_5, 0_1], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-3-consumer-5c4e5c6a-d2f7-4330-b4d6-1921c8ac7c4c=[0_10, 0_6, 0_2], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-4-consumer-d1a99615-be46-49d4-a579-ec96e07ab4b0=[0_11, 0_7, 0_3], shouldExecuteMultipleMixedAsyncProcessorsNoCaching-3cd1b0d3-45f6-4201-a04c-428a989a2112-StreamThread-5-consumer-187ea991-1f7f-4485-ba51-4bee01afaa3a=[0_8, 0_4, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-2, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-6, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-10]
    	Current owned partitions:                  [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-2, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-6, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-10]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-1, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-5, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-9]
    	Current owned partitions:                  [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-1, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-5, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-9]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: [0_9, 0_5, 0_1]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-3, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-7, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-11]
    	Current owned partitions:                  [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-3, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-7, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-11]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-0, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-4, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-0, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-4, shouldExecuteMultipleMixedAsyncProcessorsNoCaching.shouldExecuteMultipleMixedAsyncProcessorsNoCachinginput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: [0_11, 0_7, 0_3]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: [0_10, 0_6, 0_2]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    [0K[32m✔[90m shouldExecuteMultipleMixedAsyncProcessorsNoCaching()[31m (44.4s)[m

AsyncProcessorIntegrationTest > shouldThrowIfStoresNotConnectedCorrectly() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 5
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 9223372036854775807
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldThrowIfStoresNotConnectedCorrectly
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 30000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 4
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldThrowIfStoresNotConnectedCorrectly
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-2-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-2-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-2
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-2-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldThrowIfStoresNotConnectedCorrectly
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-3-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-3-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-3
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-3-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldThrowIfStoresNotConnectedCorrectly
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-4-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-4-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-4
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-4-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldThrowIfStoresNotConnectedCorrectly
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    d5b7b86e-e72f-4765-a5be-b57190ffc60e: [shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-1-consumer-dd4303dc-77aa-4da7-a633-1333feae261d, shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-3-consumer-34465f47-3ec2-4bbe-99f9-d4d36497f268, shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-4-consumer-425b68c2-4d5f-4a3f-b2b9-e9de616c1f42]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-1-consumer-dd4303dc-77aa-4da7-a633-1333feae261d=[], shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-3-consumer-34465f47-3ec2-4bbe-99f9-d4d36497f268=[], shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-4-consumer-425b68c2-4d5f-4a3f-b2b9-e9de616c1f42=[]}
    	assigned active {shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-1-consumer-dd4303dc-77aa-4da7-a633-1333feae261d=[0_9, 0_6, 0_3, 0_0], shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-3-consumer-34465f47-3ec2-4bbe-99f9-d4d36497f268=[0_10, 0_7, 0_4, 0_1], shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-4-consumer-425b68c2-4d5f-4a3f-b2b9-e9de616c1f42=[0_11, 0_8, 0_5, 0_2]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    d5b7b86e-e72f-4765-a5be-b57190ffc60e: [shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-1-consumer-dd4303dc-77aa-4da7-a633-1333feae261d, shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-2-consumer-7bdb4eb5-a2a7-4731-9c29-081ae93b4c6f, shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-3-consumer-34465f47-3ec2-4bbe-99f9-d4d36497f268, shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-4-consumer-425b68c2-4d5f-4a3f-b2b9-e9de616c1f42]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-1-consumer-dd4303dc-77aa-4da7-a633-1333feae261d=[], shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-2-consumer-7bdb4eb5-a2a7-4731-9c29-081ae93b4c6f=[], shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-3-consumer-34465f47-3ec2-4bbe-99f9-d4d36497f268=[], shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-4-consumer-425b68c2-4d5f-4a3f-b2b9-e9de616c1f42=[]}
    	assigned active {shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-1-consumer-dd4303dc-77aa-4da7-a633-1333feae261d=[0_8, 0_4, 0_0], shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-2-consumer-7bdb4eb5-a2a7-4731-9c29-081ae93b4c6f=[0_9, 0_5, 0_1], shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-3-consumer-34465f47-3ec2-4bbe-99f9-d4d36497f268=[0_10, 0_6, 0_2], shouldThrowIfStoresNotConnectedCorrectly-d5b7b86e-e72f-4765-a5be-b57190ffc60e-StreamThread-4-consumer-425b68c2-4d5f-4a3f-b2b9-e9de616c1f42=[0_11, 0_7, 0_3]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-2, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-6, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-10]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-2, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-6, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-10]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-3, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-7, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-11]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-3, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-7, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-11]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_11, 0_7, 0_3]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_10, 0_6, 0_2]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-1, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-5, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-9]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-1, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-5, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-9]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_9, 0_5, 0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	Assigned partitions:                       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-0, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-4, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-8]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-0, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-4, shouldThrowIfStoresNotConnectedCorrectly.shouldThrowIfStoresNotConnectedCorrectlyinput-8]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_8, 0_4, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.streams.errors.StreamsException: failed to initialize processor AsyncProcessor
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.init(ProcessorNode.java:110)
    	at org.apache.kafka.streams.processor.internals.StreamTask.initializeTopology(StreamTask.java:1023)
    	at org.apache.kafka.streams.processor.internals.StreamTask.completeRestoration(StreamTask.java:287)
    	at org.apache.kafka.streams.processor.internals.TaskManager.tryToCompleteRestoration(TaskManager.java:752)
    	at org.apache.kafka.streams.processor.internals.StreamThread.initializeAndRestorePhase(StreamThread.java:1117)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:921)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: java.lang.IllegalStateException: Processor initialized some stores that were not connected via the ProcessorSupplier, please connect stores for async processors by implementing the ProcessorSupplier#storesNames method
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.verifyConnectedStateStores(AsyncProcessor.java:756)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.completeInitialization(AsyncProcessor.java:251)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.init(AsyncProcessor.java:177)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.init(ProcessorNode.java:107)
    	... 7 more
    org.apache.kafka.streams.errors.StreamsException: failed to initialize processor AsyncProcessor
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.init(ProcessorNode.java:110)
    	at org.apache.kafka.streams.processor.internals.StreamTask.initializeTopology(StreamTask.java:1023)
    	at org.apache.kafka.streams.processor.internals.StreamTask.completeRestoration(StreamTask.java:287)
    	at org.apache.kafka.streams.processor.internals.TaskManager.tryToCompleteRestoration(TaskManager.java:752)
    	at org.apache.kafka.streams.processor.internals.StreamThread.initializeAndRestorePhase(StreamThread.java:1117)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:921)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: java.lang.IllegalStateException: Processor initialized some stores that were not connected via the ProcessorSupplier, please connect stores for async processors by implementing the ProcessorSupplier#storesNames method
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.verifyConnectedStateStores(AsyncProcessor.java:756)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.completeInitialization(AsyncProcessor.java:251)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.init(AsyncProcessor.java:177)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.init(ProcessorNode.java:107)
    	... 7 more
    org.apache.kafka.streams.errors.StreamsException: failed to initialize processor AsyncProcessor
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.init(ProcessorNode.java:110)
    	at org.apache.kafka.streams.processor.internals.StreamTask.initializeTopology(StreamTask.java:1023)
    	at org.apache.kafka.streams.processor.internals.StreamTask.completeRestoration(StreamTask.java:287)
    	at org.apache.kafka.streams.processor.internals.TaskManager.tryToCompleteRestoration(TaskManager.java:752)
    	at org.apache.kafka.streams.processor.internals.StreamThread.initializeAndRestorePhase(StreamThread.java:1117)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:921)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: java.lang.IllegalStateException: Processor initialized some stores that were not connected via the ProcessorSupplier, please connect stores for async processors by implementing the ProcessorSupplier#storesNames method
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.verifyConnectedStateStores(AsyncProcessor.java:756)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.completeInitialization(AsyncProcessor.java:251)
    	at dev.responsive.kafka.api.async.internals.AsyncProcessor.init(AsyncProcessor.java:177)
    	at org.apache.kafka.streams.processor.internals.ProcessorNode.init(ProcessorNode.java:107)
    	... 7 more
    [0K[32m✔[90m shouldThrowIfStoresNotConnectedCorrectly()[31m (7s)[m

AsyncProcessorIntegrationTest STANDARD_ERROR
    Test 1(dev.responsive.kafka.async.AsyncProcessorIntegrationTest): CASSANDRA teardown begins at 1731122618932ms (speed check)
    Test 1(dev.responsive.kafka.async.AsyncProcessorIntegrationTest): CASSANDRA teardown ends at 1731122618933ms (duration: PT0.001S) (speed check)
    Test 1(dev.responsive.kafka.async.AsyncProcessorIntegrationTest): CASSANDRA test total runtime=PT2M28.525S) (speed check)

Gradle Test Executor 10 STANDARD_ERROR
    Test 2: creating ResponsiveExtension(backend=CASSANDRA) at 1731122618934ms (speed check)

  [0K[39mdev.responsive.kafka.bootstrap.ChangelogMigrationToolIntegrationTest[m

    [0K[36m- testFactStore()[m

ChangelogMigrationToolIntegrationTest > testFactStore() SKIPPED
    [0K[36m- test()[m

ChangelogMigrationToolIntegrationTest > test() SKIPPED

Gradle Test Executor 10 STANDARD_ERROR
    Test 2: creating ResponsiveExtension(empty) at 1731122618939ms (speed check)

GlobalStoreIntegrationTest STANDARD_ERROR
    SOPHIE: speed check version 1
    Test 2(dev.responsive.kafka.integration.GlobalStoreIntegrationTest): CASSANDRA setup begins at 1731122618940ms (speed check)
    Test 2(dev.responsive.kafka.integration.GlobalStoreIntegrationTest): CASSANDRA setup ends at 1731122618940ms (duration: PT0S) (speed check)

GlobalStoreIntegrationTest > shouldUseGlobalTable() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-4
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldUseGlobalTable
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 0
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-317ea65c-c745-44df-889a-47d1ac9c4d52-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-317ea65c-c745-44df-889a-47d1ac9c4d52-global-consumer
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-317ea65c-c745-44df-889a-47d1ac9c4d52-global-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldUseGlobalTable-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-317ea65c-c745-44df-889a-47d1ac9c4d52-global-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldUseGlobalTable-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-317ea65c-c745-44df-889a-47d1ac9c4d52-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-317ea65c-c745-44df-889a-47d1ac9c4d52-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldUseGlobalTable-317ea65c-c745-44df-889a-47d1ac9c4d52-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldUseGlobalTable
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    317ea65c-c745-44df-889a-47d1ac9c4d52: [shouldUseGlobalTable-317ea65c-c745-44df-889a-47d1ac9c4d52-StreamThread-1-consumer-666ff191-7543-4562-849a-789c018bb2fc]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [1_0, 1_1] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldUseGlobalTable-317ea65c-c745-44df-889a-47d1ac9c4d52-StreamThread-1-consumer-666ff191-7543-4562-849a-789c018bb2fc=[]}
    	assigned active {shouldUseGlobalTable-317ea65c-c745-44df-889a-47d1ac9c4d52-StreamThread-1-consumer-666ff191-7543-4562-849a-789c018bb2fc=[1_0, 1_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [input-0, input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [input-0, input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 1_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-4
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.GlobalStoreIntegrationTest[m

    [0K[31m✘ shouldUseGlobalTable()[31m (3m 38s)[31m

      java.util.concurrent.TimeoutException: Timed out trying to read [KeyValue(1, 2), KeyValue(0, 2), KeyValue(1, 3), KeyValue(0, 3), KeyValue(1, 4), KeyValue(0, 4), KeyValue(1, 5), KeyValue(0, 5), KeyValue(1, 6), KeyValue(0, 6), KeyValue(1, 7), KeyValue(0, 7), KeyValue(1, 8), KeyValue(0, 8), KeyValue(1, 9), KeyValue(0, 9), KeyValue(1, 10), KeyValue(0, 10), KeyValue(1, 11), KeyValue(0, 11)] events from output-0.
      Not yet seen: [KeyValue(1, 2), KeyValue(1, 3), KeyValue(1, 4), KeyValue(1, 5), KeyValue(1, 6), KeyValue(1, 7), KeyValue(1, 8), KeyValue(1, 9), KeyValue(1, 10), KeyValue(1, 11)].
      All seen: [KeyValue(0, 2), KeyValue(0, 3), KeyValue(0, 4), KeyValue(0, 5), KeyValue(0, 6), KeyValue(0, 7), KeyValue(0, 8), KeyValue(0, 9), KeyValue(0, 10), KeyValue(0, 11)]
          at dev.responsive.kafka.integration.GlobalStoreIntegrationTest.shouldUseGlobalTable(GlobalStoreIntegrationTest.java:119)
[m

GlobalStoreIntegrationTest > shouldUseGlobalTable() FAILED
    java.util.concurrent.TimeoutException: Timed out trying to read [KeyValue(1, 2), KeyValue(0, 2), KeyValue(1, 3), KeyValue(0, 3), KeyValue(1, 4), KeyValue(0, 4), KeyValue(1, 5), KeyValue(0, 5), KeyValue(1, 6), KeyValue(0, 6), KeyValue(1, 7), KeyValue(0, 7), KeyValue(1, 8), KeyValue(0, 8), KeyValue(1, 9), KeyValue(0, 9), KeyValue(1, 10), KeyValue(0, 10), KeyValue(1, 11), KeyValue(0, 11)] events from output-0.
    Not yet seen: [KeyValue(1, 2), KeyValue(1, 3), KeyValue(1, 4), KeyValue(1, 5), KeyValue(1, 6), KeyValue(1, 7), KeyValue(1, 8), KeyValue(1, 9), KeyValue(1, 10), KeyValue(1, 11)].
    All seen: [KeyValue(0, 2), KeyValue(0, 3), KeyValue(0, 4), KeyValue(0, 5), KeyValue(0, 6), KeyValue(0, 7), KeyValue(0, 8), KeyValue(0, 9), KeyValue(0, 10), KeyValue(0, 11)]
        at dev.responsive.kafka.testutils.IntegrationTestUtils.awaitOutput(IntegrationTestUtils.java:348)
        at dev.responsive.kafka.integration.GlobalStoreIntegrationTest.shouldUseGlobalTable(GlobalStoreIntegrationTest.java:119)

GlobalStoreIntegrationTest STANDARD_ERROR
    Test 2(dev.responsive.kafka.integration.GlobalStoreIntegrationTest): CASSANDRA teardown begins at 1731122837497ms (speed check)
    Test 2(dev.responsive.kafka.integration.GlobalStoreIntegrationTest): CASSANDRA teardown ends at 1731122837498ms (duration: PT0.001S) (speed check)
    Test 2(dev.responsive.kafka.integration.GlobalStoreIntegrationTest): CASSANDRA test total runtime=PT3M38.559S) (speed check)

Gradle Test Executor 10 STANDARD_ERROR
    Test 3: creating ResponsiveExtension(backend=MONGO_DB) at 1731122837502ms (speed check)

  [0K[39mdev.responsive.kafka.integration.MinimalIntegrationTest[m

    [0K[36m- test()[m

MinimalIntegrationTest > test() SKIPPED

Gradle Test Executor 10 STANDARD_ERROR
    Test 3: creating ResponsiveExtension(backend=MONGO_DB) at 1731122837513ms (speed check)

ResponsiveForeignKeyJoinIntegrationTest STANDARD_ERROR
    SOPHIE: speed check version 1
    Test 3(dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest): MONGO_DB setup begins at 1731122837515ms (speed check)
    Test 3(dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest): MONGO_DB setup ends at 1731122837515ms (duration: PT0S) (speed check)

ResponsiveForeignKeyJoinIntegrationTest > shouldComputeForeignKeyJoinsCorrectly() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-5
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$JsonSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-6
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$JsonSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:54361
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = CFKJC--127001604
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 2000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = CFKJC--127001604
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    2679bb6c-7ec3-4c38-ab16-f4235671a5d0: [CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-StreamThread-1-consumer-db65b0e3-9b6e-469d-b02c-b0da9f144bf4]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-StreamThread-1-consumer-db65b0e3-9b6e-469d-b02c-b0da9f144bf4=[]}
    	assigned active {CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-StreamThread-1-consumer-db65b0e3-9b6e-469d-b02c-b0da9f144bf4=[1_0, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [CFKJC--127001604-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC--127001604-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC--127001604.inventory-0, CFKJC--127001604.merchant-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [CFKJC--127001604-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC--127001604-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC--127001604.inventory-0, CFKJC--127001604.merchant-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    2679bb6c-7ec3-4c38-ab16-f4235671a5d0: [CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-StreamThread-1-consumer-db65b0e3-9b6e-469d-b02c-b0da9f144bf4]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-StreamThread-1-consumer-db65b0e3-9b6e-469d-b02c-b0da9f144bf4=[1_0, 0_0]}
    	prev owned standby {CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-StreamThread-1-consumer-db65b0e3-9b6e-469d-b02c-b0da9f144bf4=[]}
    	assigned active {CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-StreamThread-1-consumer-db65b0e3-9b6e-469d-b02c-b0da9f144bf4=[1_0, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [CFKJC--127001604-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC--127001604-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC--127001604.inventory-0, CFKJC--127001604.merchant-0]
    	Current owned partitions:                  [CFKJC--127001604-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC--127001604-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC--127001604.inventory-0, CFKJC--127001604.merchant-0]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 0_0]
    	New standby tasks: []
    	Existing active tasks: [1_0, 0_0]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-5
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$EnrichedDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-7
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$JsonSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-8
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$JsonSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:54361
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = CFKJC--127001604
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 2000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = CFKJC--127001604
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    2679bb6c-7ec3-4c38-ab16-f4235671a5d0: [CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-StreamThread-1-consumer-e4632618-c82d-4efe-b96b-38acb79ba61c]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-StreamThread-1-consumer-e4632618-c82d-4efe-b96b-38acb79ba61c=[1_0]}
    	assigned active {CFKJC--127001604-2679bb6c-7ec3-4c38-ab16-f4235671a5d0-StreamThread-1-consumer-e4632618-c82d-4efe-b96b-38acb79ba61c=[1_0, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [CFKJC--127001604-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC--127001604-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC--127001604.inventory-0, CFKJC--127001604.merchant-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [CFKJC--127001604-KTABLE-FK-JOIN-SUBSCRIPTION-REGISTRATION-0000000006-topic-0, CFKJC--127001604-KTABLE-FK-JOIN-SUBSCRIPTION-RESPONSE-0000000014-topic-0, CFKJC--127001604.inventory-0, CFKJC--127001604.merchant-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-6
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest$EnrichedDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest[m

    [0K[32m✔[90m shouldComputeForeignKeyJoinsCorrectly()[31m (24.5s)[m

ResponsiveForeignKeyJoinIntegrationTest STANDARD_ERROR
    Test 3(dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest): MONGO_DB teardown begins at 1731122862099ms (speed check)
    Test 3(dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest): MONGO_DB teardown ends at 1731122862099ms (duration: PT0S) (speed check)
    Test 3(dev.responsive.kafka.integration.ResponsiveForeignKeyJoinIntegrationTest): MONGO_DB test total runtime=PT24.586S) (speed check)

Gradle Test Executor 10 STANDARD_ERROR
    Test 4: creating ResponsiveExtension(backend=MONGO_DB) at 1731122862106ms (speed check)

ResponsiveKafkaStreamsIntegrationTest STANDARD_ERROR
    SOPHIE: speed check version 1
    Test 4(dev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest): MONGO_DB setup begins at 1731122862112ms (speed check)
    Test 4(dev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest): MONGO_DB setup ends at 1731122862112ms (duration: PT0S) (speed check)

ResponsiveKafkaStreamsIntegrationTest > shouldDefaultToResponsiveStoresWhenUsingDsl() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-9
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:54361
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldDefaultToResponsiveStoresWhenUsingDsl-1399440471
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDefaultToResponsiveStoresWhenUsingDsl-1399440471-d6901d56-e36f-4d4f-b5f4-27435a5b5def-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDefaultToResponsiveStoresWhenUsingDsl-1399440471-d6901d56-e36f-4d4f-b5f4-27435a5b5def-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDefaultToResponsiveStoresWhenUsingDsl-1399440471-d6901d56-e36f-4d4f-b5f4-27435a5b5def-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDefaultToResponsiveStoresWhenUsingDsl-1399440471-d6901d56-e36f-4d4f-b5f4-27435a5b5def-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldDefaultToResponsiveStoresWhenUsingDsl-1399440471
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    d6901d56-e36f-4d4f-b5f4-27435a5b5def: [shouldDefaultToResponsiveStoresWhenUsingDsl-1399440471-d6901d56-e36f-4d4f-b5f4-27435a5b5def-StreamThread-1-consumer-6778cbfe-271a-4326-84e0-bb58cab3b7a4]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldDefaultToResponsiveStoresWhenUsingDsl-1399440471-d6901d56-e36f-4d4f-b5f4-27435a5b5def-StreamThread-1-consumer-6778cbfe-271a-4326-84e0-bb58cab3b7a4=[]}
    	assigned active {shouldDefaultToResponsiveStoresWhenUsingDsl-1399440471-d6901d56-e36f-4d4f-b5f4-27435a5b5def-StreamThread-1-consumer-6778cbfe-271a-4326-84e0-bb58cab3b7a4=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldDefaultToResponsiveStoresWhenUsingDsl-1399440471.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldDefaultToResponsiveStoresWhenUsingDsl-1399440471.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    Pinged your deployment. You successfully connected to MongoDB!

  [0K[39mdev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest[m

    [0K[32m✔[90m shouldDefaultToResponsiveStoresWhenUsingDsl()[m

ResponsiveKafkaStreamsIntegrationTest STANDARD_ERROR
    Test 4(dev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest): MONGO_DB teardown begins at 1731122862911ms (speed check)
    Test 4(dev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest): MONGO_DB teardown ends at 1731122862911ms (duration: PT0S) (speed check)
    Test 4(dev.responsive.kafka.integration.ResponsiveKafkaStreamsIntegrationTest): MONGO_DB test total runtime=PT0.805S) (speed check)

Gradle Test Executor 10 STANDARD_ERROR
    Test 5: creating ResponsiveExtension(empty) at 1731122862913ms (speed check)

ResponsiveKeyValueStoreEosIntegrationTest STANDARD_ERROR
    SOPHIE: speed check version 1
    Test 5(dev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest): CASSANDRA setup begins at 1731122862914ms (speed check)
    Test 5(dev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest): CASSANDRA setup ends at 1731122862914ms (duration: PT0S) (speed check)

ResponsiveKeyValueStoreEosIntegrationTest > shouldMaintainStateOnEosFailOverAndFenceOldClient(KVSchema) > [1] KEY_VALUE STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-10
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue
    	application.server = a:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 20000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-baaffefa-b0b8-49f6-8cb6-2b983a6dc01b-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-baaffefa-b0b8-49f6-8cb6-2b983a6dc01b-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-baaffefa-b0b8-49f6-8cb6-2b983a6dc01b-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-baaffefa-b0b8-49f6-8cb6-2b983a6dc01b-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-baaffefa-b0b8-49f6-8cb6-2b983a6dc01b-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue
    	application.server = b:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 20000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-e177738f-602d-4046-a15e-6a990f9f2000-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-e177738f-602d-4046-a15e-6a990f9f2000-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-e177738f-602d-4046-a15e-6a990f9f2000-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-e177738f-602d-4046-a15e-6a990f9f2000-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-e177738f-602d-4046-a15e-6a990f9f2000-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    baaffefa-b0b8-49f6-8cb6-2b983a6dc01b: [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-baaffefa-b0b8-49f6-8cb6-2b983a6dc01b-StreamThread-1-consumer-a9ec8823-7f9d-439a-9bf3-6bde20456940]
    e177738f-602d-4046-a15e-6a990f9f2000: [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-e177738f-602d-4046-a15e-6a990f9f2000-StreamThread-1-consumer-7d0a420c-2434-4a1a-8ee4-0f84efdcfa82]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    e177738f-602d-4046-a15e-6a990f9f2000=[activeTasks: ([0_1]) standbyTasks: ([])] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:671)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-baaffefa-b0b8-49f6-8cb6-2b983a6dc01b-StreamThread-1-consumer-a9ec8823-7f9d-439a-9bf3-6bde20456940=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-baaffefa-b0b8-49f6-8cb6-2b983a6dc01b-StreamThread-1-consumer-a9ec8823-7f9d-439a-9bf3-6bde20456940=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-e177738f-602d-4046-a15e-6a990f9f2000-StreamThread-1-consumer-7d0a420c-2434-4a1a-8ee4-0f84efdcfa82=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-e177738f-602d-4046-a15e-6a990f9f2000-StreamThread-1-consumer-7d0a420c-2434-4a1a-8ee4-0f84efdcfa82=[0_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-7
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    e177738f-602d-4046-a15e-6a990f9f2000: [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-e177738f-602d-4046-a15e-6a990f9f2000-StreamThread-1-consumer-7d0a420c-2434-4a1a-8ee4-0f84efdcfa82]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-e177738f-602d-4046-a15e-6a990f9f2000-StreamThread-1-consumer-7d0a420c-2434-4a1a-8ee4-0f84efdcfa82=[0_1]}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-e177738f-602d-4046-a15e-6a990f9f2000-StreamThread-1-consumer-7d0a420c-2434-4a1a-8ee4-0f84efdcfa82=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-e177738f-602d-4046-a15e-6a990f9f2000-StreamThread-1-consumer-7d0a420c-2434-4a1a-8ee4-0f84efdcfa82=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0, shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Current owned partitions:                  [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: [0_1]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-8
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-9
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:322)
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:303)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:273)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeExceptionally(ProducerBatch.java:237)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:830)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:819)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:771)
    	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:702)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$null$1(Sender.java:627)
    	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:612)
    	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
    	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:612)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$8(Sender.java:917)
    	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:154)
    	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:608)
    	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:600)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:349)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-baaffefa-b0b8-49f6-8cb6-2b983a6dc01b-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-baaffefa-b0b8-49f6-8cb6-2b983a6dc01b-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	lost active tasks: []
    	lost assigned standby tasks: []
     (org.apache.kafka.streams.processor.internals.StreamThread:104)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-baaffefa-b0b8-49f6-8cb6-2b983a6dc01b-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-baaffefa-b0b8-49f6-8cb6-2b983a6dc01b-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    baaffefa-b0b8-49f6-8cb6-2b983a6dc01b: [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-baaffefa-b0b8-49f6-8cb6-2b983a6dc01b-StreamThread-1-consumer-dea522d1-ab78-414b-aac1-916af75a616f]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-baaffefa-b0b8-49f6-8cb6-2b983a6dc01b-StreamThread-1-consumer-dea522d1-ab78-414b-aac1-916af75a616f=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue-baaffefa-b0b8-49f6-8cb6-2b983a6dc01b-StreamThread-1-consumer-dea522d1-ab78-414b-aac1-916af75a616f=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0, shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-0, shouldmaintainstateoneosfailoverandfenceoldclientkeyvalue.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)

  [0K[39mdev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest[m

    [0K[39mshouldMaintainStateOnEosFailOverAndFenceOldClient(KVSchema)[m

      [0K[32m✔[90m [1] KEY_VALUE[31m (32.3s)[m

ResponsiveKeyValueStoreEosIntegrationTest > shouldMaintainStateOnEosFailOverAndFenceOldClient(KVSchema) > [2] FACT STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-11
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldmaintainstateoneosfailoverandfenceoldclientfact
    	application.server = a:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 20000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-7f85bee6-48d9-44f9-8285-9d049ea614a9-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-7f85bee6-48d9-44f9-8285-9d049ea614a9-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-7f85bee6-48d9-44f9-8285-9d049ea614a9-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-7f85bee6-48d9-44f9-8285-9d049ea614a9-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-7f85bee6-48d9-44f9-8285-9d049ea614a9-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldmaintainstateoneosfailoverandfenceoldclientfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldmaintainstateoneosfailoverandfenceoldclientfact
    	application.server = b:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 20000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-736642fc-ced5-4dc5-a65f-a8d5d0079ae7-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-736642fc-ced5-4dc5-a65f-a8d5d0079ae7-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-736642fc-ced5-4dc5-a65f-a8d5d0079ae7-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-736642fc-ced5-4dc5-a65f-a8d5d0079ae7-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-736642fc-ced5-4dc5-a65f-a8d5d0079ae7-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldmaintainstateoneosfailoverandfenceoldclientfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    736642fc-ced5-4dc5-a65f-a8d5d0079ae7: [shouldmaintainstateoneosfailoverandfenceoldclientfact-736642fc-ced5-4dc5-a65f-a8d5d0079ae7-StreamThread-1-consumer-a9306567-491e-4876-8e89-78793a584b45]
    7f85bee6-48d9-44f9-8285-9d049ea614a9: [shouldmaintainstateoneosfailoverandfenceoldclientfact-7f85bee6-48d9-44f9-8285-9d049ea614a9-StreamThread-1-consumer-7510db71-120c-4907-afb4-756d5b68f298]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    7f85bee6-48d9-44f9-8285-9d049ea614a9=[activeTasks: ([0_1]) standbyTasks: ([])] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:671)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientfact-736642fc-ced5-4dc5-a65f-a8d5d0079ae7-StreamThread-1-consumer-a9306567-491e-4876-8e89-78793a584b45=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientfact-736642fc-ced5-4dc5-a65f-a8d5d0079ae7-StreamThread-1-consumer-a9306567-491e-4876-8e89-78793a584b45=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	prev owned active {}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientfact-7f85bee6-48d9-44f9-8285-9d049ea614a9-StreamThread-1-consumer-7510db71-120c-4907-afb4-756d5b68f298=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientfact-7f85bee6-48d9-44f9-8285-9d049ea614a9-StreamThread-1-consumer-7510db71-120c-4907-afb4-756d5b68f298=[0_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-10
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    7f85bee6-48d9-44f9-8285-9d049ea614a9: [shouldmaintainstateoneosfailoverandfenceoldclientfact-7f85bee6-48d9-44f9-8285-9d049ea614a9-StreamThread-1-consumer-7510db71-120c-4907-afb4-756d5b68f298]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldmaintainstateoneosfailoverandfenceoldclientfact-7f85bee6-48d9-44f9-8285-9d049ea614a9-StreamThread-1-consumer-7510db71-120c-4907-afb4-756d5b68f298=[0_1]}
    	prev owned standby {shouldmaintainstateoneosfailoverandfenceoldclientfact-7f85bee6-48d9-44f9-8285-9d049ea614a9-StreamThread-1-consumer-7510db71-120c-4907-afb4-756d5b68f298=[]}
    	assigned active {shouldmaintainstateoneosfailoverandfenceoldclientfact-7f85bee6-48d9-44f9-8285-9d049ea614a9-StreamThread-1-consumer-7510db71-120c-4907-afb4-756d5b68f298=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-0, shouldmaintainstateoneosfailoverandfenceoldclientfact.input-1]
    	Current owned partitions:                  [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-1]
    	Added partitions (assigned - owned):       [shouldmaintainstateoneosfailoverandfenceoldclientfact.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: [0_1]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-11
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-12
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:322)
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic shouldmaintainstateoneosfailoverandfenceoldclientfact-shouldmaintainstateoneosfailoverandfenceoldclientfact-changelog for task 0_0 due to:
    org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:303)
    	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$1(RecordCollectorImpl.java:284)
    	at dev.responsive.kafka.internal.clients.ResponsiveProducer$RecordingCallback.onCompletion(ResponsiveProducer.java:233)
    	at org.apache.kafka.clients.producer.KafkaProducer$AppendCallbacks.onCompletion(KafkaProducer.java:1538)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:312)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:273)
    	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeExceptionally(ProducerBatch.java:237)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:830)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:819)
    	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:771)
    	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:702)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$null$1(Sender.java:627)
    	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:612)
    	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
    	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:612)
    	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$8(Sender.java:917)
    	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:154)
    	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:608)
    	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:600)
    	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:349)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:252)
    	at java.base/java.lang.Thread.run(Thread.java:829)
    Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-736642fc-ced5-4dc5-a65f-a8d5d0079ae7-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-736642fc-ced5-4dc5-a65f-a8d5d0079ae7-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	lost active tasks: []
    	lost assigned standby tasks: []
     (org.apache.kafka.streams.processor.internals.StreamThread:104)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-736642fc-ced5-4dc5-a65f-a8d5d0079ae7-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldmaintainstateoneosfailoverandfenceoldclientfact-736642fc-ced5-4dc5-a65f-a8d5d0079ae7-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
      [0K[32m✔[90m [2] FACT[31m (37.2s)[m

ResponsiveKeyValueStoreEosIntegrationTest STANDARD_ERROR
    Test 5(dev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest): CASSANDRA teardown begins at 1731122932615ms (speed check)
    Test 5(dev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest): CASSANDRA teardown ends at 1731122932616ms (duration: PT0.001S) (speed check)
    Test 5(dev.responsive.kafka.integration.ResponsiveKeyValueStoreEosIntegrationTest): CASSANDRA test total runtime=PT1M9.703S) (speed check)

Gradle Test Executor 10 STANDARD_ERROR
    Test 6: creating ResponsiveExtension(backend=MONGO_DB) at 1731122932618ms (speed check)

ResponsiveKeyValueStoreIntegrationTest STANDARD_ERROR
    SOPHIE: speed check version 1
    Test 6(dev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest): MONGO_DB setup begins at 1731122932621ms (speed check)
    Test 6(dev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest): MONGO_DB setup ends at 1731122932621ms (duration: PT0S) (speed check)

ResponsiveKeyValueStoreIntegrationTest > shouldMatchRocksDB() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-12
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:54361
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldMatchRocksDB--1285465978
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldMatchRocksDB--1285465978-8b467633-a211-4344-bf1c-ca23836cfa3a-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldMatchRocksDB--1285465978-8b467633-a211-4344-bf1c-ca23836cfa3a-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldMatchRocksDB--1285465978-8b467633-a211-4344-bf1c-ca23836cfa3a-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldMatchRocksDB--1285465978-8b467633-a211-4344-bf1c-ca23836cfa3a-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldMatchRocksDB--1285465978
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    8b467633-a211-4344-bf1c-ca23836cfa3a: [shouldMatchRocksDB--1285465978-8b467633-a211-4344-bf1c-ca23836cfa3a-StreamThread-1-consumer-80be1759-24a2-4c25-bcee-dbc2d556083f]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldMatchRocksDB--1285465978-8b467633-a211-4344-bf1c-ca23836cfa3a-StreamThread-1-consumer-80be1759-24a2-4c25-bcee-dbc2d556083f=[]}
    	assigned active {shouldMatchRocksDB--1285465978-8b467633-a211-4344-bf1c-ca23836cfa3a-StreamThread-1-consumer-80be1759-24a2-4c25-bcee-dbc2d556083f=[1_0, 0_1, 0_0, 1_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldMatchRocksDB--1285465978-shouldMatchRocksDB--1285465978-repartition-0, shouldMatchRocksDB--1285465978-shouldMatchRocksDB--1285465978-repartition-1, shouldMatchRocksDB--1285465978.input-0, shouldMatchRocksDB--1285465978.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldMatchRocksDB--1285465978-shouldMatchRocksDB--1285465978-repartition-0, shouldMatchRocksDB--1285465978-shouldMatchRocksDB--1285465978-repartition-1, shouldMatchRocksDB--1285465978.input-0, shouldMatchRocksDB--1285465978.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 0_1, 0_0, 1_1]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    8b467633-a211-4344-bf1c-ca23836cfa3a: [shouldMatchRocksDB--1285465978-8b467633-a211-4344-bf1c-ca23836cfa3a-StreamThread-1-consumer-80be1759-24a2-4c25-bcee-dbc2d556083f]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {shouldMatchRocksDB--1285465978-8b467633-a211-4344-bf1c-ca23836cfa3a-StreamThread-1-consumer-80be1759-24a2-4c25-bcee-dbc2d556083f=[1_0, 0_1, 1_1, 0_0]}
    	prev owned standby {shouldMatchRocksDB--1285465978-8b467633-a211-4344-bf1c-ca23836cfa3a-StreamThread-1-consumer-80be1759-24a2-4c25-bcee-dbc2d556083f=[]}
    	assigned active {shouldMatchRocksDB--1285465978-8b467633-a211-4344-bf1c-ca23836cfa3a-StreamThread-1-consumer-80be1759-24a2-4c25-bcee-dbc2d556083f=[1_0, 0_1, 0_0, 1_1]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldMatchRocksDB--1285465978-shouldMatchRocksDB--1285465978-repartition-0, shouldMatchRocksDB--1285465978-shouldMatchRocksDB--1285465978-repartition-1, shouldMatchRocksDB--1285465978.input-0, shouldMatchRocksDB--1285465978.input-1]
    	Current owned partitions:                  [shouldMatchRocksDB--1285465978-shouldMatchRocksDB--1285465978-repartition-0, shouldMatchRocksDB--1285465978-shouldMatchRocksDB--1285465978-repartition-1, shouldMatchRocksDB--1285465978.input-0, shouldMatchRocksDB--1285465978.input-1]
    	Added partitions (assigned - owned):       []
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [1_0, 0_1, 0_0, 1_1]
    	New standby tasks: []
    	Existing active tasks: [1_0, 0_1, 1_1, 0_0]
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)

  [0K[39mdev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest[m

    [0K[32m✔[90m shouldMatchRocksDB()[31m (3.1s)[m

ResponsiveKeyValueStoreIntegrationTest STANDARD_ERROR
    Test 6(dev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest): MONGO_DB teardown begins at 1731122935813ms (speed check)
    Test 6(dev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest): MONGO_DB teardown ends at 1731122935813ms (duration: PT0S) (speed check)
    Test 6(dev.responsive.kafka.integration.ResponsiveKeyValueStoreIntegrationTest): MONGO_DB test total runtime=PT3.195S) (speed check)

Gradle Test Executor 10 STANDARD_ERROR
    Test 7: creating ResponsiveExtension(backend=CASSANDRA) at 1731122935814ms (speed check)

ResponsiveKeyValueStoreRestoreIntegrationTest STANDARD_ERROR
    SOPHIE: speed check version 1
    Test 7(dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest): CASSANDRA setup begins at 1731122935815ms (speed check)
    Test 7(dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest): CASSANDRA setup ends at 1731122935815ms (duration: PT0S) (speed check)

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldRestoreUnflushedChangelog(KVSchema) > [1] KEY_VALUE STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-13
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogkeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-821ae9ae-6ec2-4ccc-92f5-29f8cad6d749-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-821ae9ae-6ec2-4ccc-92f5-29f8cad6d749-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-821ae9ae-6ec2-4ccc-92f5-29f8cad6d749-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogkeyvalue-821ae9ae-6ec2-4ccc-92f5-29f8cad6d749-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-821ae9ae-6ec2-4ccc-92f5-29f8cad6d749-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    821ae9ae-6ec2-4ccc-92f5-29f8cad6d749: [shouldrestoreunflushedchangelogkeyvalue-821ae9ae-6ec2-4ccc-92f5-29f8cad6d749-StreamThread-1-consumer-d5f8b58f-eecd-4c0f-893c-39da43ef8865]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogkeyvalue-821ae9ae-6ec2-4ccc-92f5-29f8cad6d749-StreamThread-1-consumer-d5f8b58f-eecd-4c0f-893c-39da43ef8865=[]}
    	assigned active {shouldrestoreunflushedchangelogkeyvalue-821ae9ae-6ec2-4ccc-92f5-29f8cad6d749-StreamThread-1-consumer-d5f8b58f-eecd-4c0f-893c-39da43ef8865=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogkeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-edd754bf-311d-41c2-829c-3e9368ec2272-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-edd754bf-311d-41c2-829c-3e9368ec2272-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-edd754bf-311d-41c2-829c-3e9368ec2272-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogkeyvalue-edd754bf-311d-41c2-829c-3e9368ec2272-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-edd754bf-311d-41c2-829c-3e9368ec2272-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    edd754bf-311d-41c2-829c-3e9368ec2272: [shouldrestoreunflushedchangelogkeyvalue-edd754bf-311d-41c2-829c-3e9368ec2272-StreamThread-1-consumer-09c27ece-37af-4ab3-bcf8-38b99936674d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogkeyvalue-edd754bf-311d-41c2-829c-3e9368ec2272-StreamThread-1-consumer-09c27ece-37af-4ab3-bcf8-38b99936674d=[]}
    	assigned active {shouldrestoreunflushedchangelogkeyvalue-edd754bf-311d-41c2-829c-3e9368ec2272-StreamThread-1-consumer-09c27ece-37af-4ab3-bcf8-38b99936674d=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.streams.errors.StreamsException: java.lang.RuntimeException: oops
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:729)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    Caused by: java.lang.RuntimeException: oops
    	at dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest.shouldRestoreUnflushedChangelog(ResponsiveKeyValueStoreRestoreIntegrationTest.java:304)
    	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
    	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:727)
    	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
    	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
    	at org.junit.jupiter.engine.extension.SameThreadTimeoutInvocation.proceed(SameThreadTimeoutInvocation.java:45)
    	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156)
    	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:147)
    	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestTemplateMethod(TimeoutExtension.java:94)
    	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103)
    	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)
    	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
    	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
    	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
    	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
    	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)
    	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86)
    	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:217)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:213)
    	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:138)
    	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:68)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:204)
    	at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:142)
    	at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.lambda$execute$2(TestTemplateTestDescriptor.java:110)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
    	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
    	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
    	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
    	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
    	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
    	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
    	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:274)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
    	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
    	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
    	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
    	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
    	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
    	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
    	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:274)
    	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
    	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
    	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
    	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
    	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
    	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
    	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
    	at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:110)
    	at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:44)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
    	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
    	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
    	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
    	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
    	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
    	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
    	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
    	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
    	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
    	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
    	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
    	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
    	at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.processAllTestClasses(JUnitPlatformTestClassProcessor.java:110)
    	at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.access$000(JUnitPlatformTestClassProcessor.java:90)
    	at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor.stop(JUnitPlatformTestClassProcessor.java:85)
    	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:62)
    	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
    	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
    	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
    	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)
    	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)
    	at com.sun.proxy.$Proxy2.stop(Unknown Source)
    	at org.gradle.api.internal.tasks.testing.worker.TestWorker$3.run(TestWorker.java:193)
    	at org.gradle.api.internal.tasks.testing.worker.TestWorker.executeAndMaintainThreadName(TestWorker.java:129)
    	at org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:100)
    	at org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:60)
    	at org.gradle.process.internal.worker.child.ActionExecutionWorker.execute(ActionExecutionWorker.java:56)
    	at org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:113)
    	at org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:65)
    	at worker.org.gradle.process.internal.worker.GradleWorkerMain.run(GradleWorkerMain.java:69)
    	at worker.org.gradle.process.internal.worker.GradleWorkerMain.main(GradleWorkerMain.java:74)
    Using Scylla optimized driver!!!
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogkeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-2efa2dd7-be18-4e0b-bf93-2b5abd8a465e-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-2efa2dd7-be18-4e0b-bf93-2b5abd8a465e-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-2efa2dd7-be18-4e0b-bf93-2b5abd8a465e-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogkeyvalue-2efa2dd7-be18-4e0b-bf93-2b5abd8a465e-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogkeyvalue-2efa2dd7-be18-4e0b-bf93-2b5abd8a465e-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    2efa2dd7-be18-4e0b-bf93-2b5abd8a465e: [shouldrestoreunflushedchangelogkeyvalue-2efa2dd7-be18-4e0b-bf93-2b5abd8a465e-StreamThread-1-consumer-251ca5fb-e555-4348-9042-1b4cdd4abe5f]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogkeyvalue-2efa2dd7-be18-4e0b-bf93-2b5abd8a465e-StreamThread-1-consumer-251ca5fb-e555-4348-9042-1b4cdd4abe5f=[]}
    	assigned active {shouldrestoreunflushedchangelogkeyvalue-2efa2dd7-be18-4e0b-bf93-2b5abd8a465e-StreamThread-1-consumer-251ca5fb-e555-4348-9042-1b4cdd4abe5f=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogkeyvalue.input-0, shouldrestoreunflushedchangelogkeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-13
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest[m

    [0K[39mshouldRestoreUnflushedChangelog(KVSchema)[m

      [0K[32m✔[90m [1] KEY_VALUE[31m (22.2s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldRestoreUnflushedChangelog(KVSchema) > [2] FACT STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-14
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogfact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-b079cd46-c8a1-40b7-a5a7-39aef069a413-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-b079cd46-c8a1-40b7-a5a7-39aef069a413-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-b079cd46-c8a1-40b7-a5a7-39aef069a413-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogfact-b079cd46-c8a1-40b7-a5a7-39aef069a413-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-b079cd46-c8a1-40b7-a5a7-39aef069a413-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    b079cd46-c8a1-40b7-a5a7-39aef069a413: [shouldrestoreunflushedchangelogfact-b079cd46-c8a1-40b7-a5a7-39aef069a413-StreamThread-1-consumer-4742cf8f-e545-48ca-a4c2-a4d4e9bd1057]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogfact-b079cd46-c8a1-40b7-a5a7-39aef069a413-StreamThread-1-consumer-4742cf8f-e545-48ca-a4c2-a4d4e9bd1057=[]}
    	assigned active {shouldrestoreunflushedchangelogfact-b079cd46-c8a1-40b7-a5a7-39aef069a413-StreamThread-1-consumer-4742cf8f-e545-48ca-a4c2-a4d4e9bd1057=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	lost active tasks: [0_0]
    	lost assigned standby tasks: []
     (org.apache.kafka.streams.processor.internals.StreamThread:104)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-b079cd46-c8a1-40b7-a5a7-39aef069a413-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogfact-b079cd46-c8a1-40b7-a5a7-39aef069a413-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    b079cd46-c8a1-40b7-a5a7-39aef069a413: [shouldrestoreunflushedchangelogfact-b079cd46-c8a1-40b7-a5a7-39aef069a413-StreamThread-1-consumer-0e29e172-709b-4bec-accf-f4b9f092d8a5]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogfact-b079cd46-c8a1-40b7-a5a7-39aef069a413-StreamThread-1-consumer-0e29e172-709b-4bec-accf-f4b9f092d8a5=[]}
    	assigned active {shouldrestoreunflushedchangelogfact-b079cd46-c8a1-40b7-a5a7-39aef069a413-StreamThread-1-consumer-0e29e172-709b-4bec-accf-f4b9f092d8a5=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogfact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-b006d883-ca0b-426c-a2fe-54b2a44ed2ad-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-b006d883-ca0b-426c-a2fe-54b2a44ed2ad-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-b006d883-ca0b-426c-a2fe-54b2a44ed2ad-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogfact-b006d883-ca0b-426c-a2fe-54b2a44ed2ad-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-b006d883-ca0b-426c-a2fe-54b2a44ed2ad-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    b006d883-ca0b-426c-a2fe-54b2a44ed2ad: [shouldrestoreunflushedchangelogfact-b006d883-ca0b-426c-a2fe-54b2a44ed2ad-StreamThread-1-consumer-87185cad-d280-4429-bc31-17cc05b87bda]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogfact-b006d883-ca0b-426c-a2fe-54b2a44ed2ad-StreamThread-1-consumer-87185cad-d280-4429-bc31-17cc05b87bda=[]}
    	assigned active {shouldrestoreunflushedchangelogfact-b006d883-ca0b-426c-a2fe-54b2a44ed2ad-StreamThread-1-consumer-87185cad-d280-4429-bc31-17cc05b87bda=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    Using Scylla optimized driver!!!
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrestoreunflushedchangelogfact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-07108716-abcb-49b9-aea3-ac58b7b695da-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-07108716-abcb-49b9-aea3-ac58b7b695da-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-07108716-abcb-49b9-aea3-ac58b7b695da-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrestoreunflushedchangelogfact-07108716-abcb-49b9-aea3-ac58b7b695da-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrestoreunflushedchangelogfact-07108716-abcb-49b9-aea3-ac58b7b695da-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrestoreunflushedchangelogfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    07108716-abcb-49b9-aea3-ac58b7b695da: [shouldrestoreunflushedchangelogfact-07108716-abcb-49b9-aea3-ac58b7b695da-StreamThread-1-consumer-2e9a130c-b02b-4bb1-97eb-70a3d954a44c]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrestoreunflushedchangelogfact-07108716-abcb-49b9-aea3-ac58b7b695da-StreamThread-1-consumer-2e9a130c-b02b-4bb1-97eb-70a3d954a44c=[]}
    	assigned active {shouldrestoreunflushedchangelogfact-07108716-abcb-49b9-aea3-ac58b7b695da-StreamThread-1-consumer-2e9a130c-b02b-4bb1-97eb-70a3d954a44c=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrestoreunflushedchangelogfact.input-0, shouldrestoreunflushedchangelogfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-14
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
      [0K[32m✔[90m [2] FACT[31m (25s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldFlushStoresBeforeClose(KVSchema) > [1] KEY_VALUE STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-15
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldflushstoresbeforeclosekeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosekeyvalue-5e506b21-37eb-4d5d-80a4-4bbbdaddbc07-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosekeyvalue-5e506b21-37eb-4d5d-80a4-4bbbdaddbc07-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosekeyvalue-5e506b21-37eb-4d5d-80a4-4bbbdaddbc07-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldflushstoresbeforeclosekeyvalue-5e506b21-37eb-4d5d-80a4-4bbbdaddbc07-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosekeyvalue-5e506b21-37eb-4d5d-80a4-4bbbdaddbc07-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldflushstoresbeforeclosekeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    5e506b21-37eb-4d5d-80a4-4bbbdaddbc07: [shouldflushstoresbeforeclosekeyvalue-5e506b21-37eb-4d5d-80a4-4bbbdaddbc07-StreamThread-1-consumer-4262cd85-78ea-4b01-937a-264ecd4fbdad]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldflushstoresbeforeclosekeyvalue-5e506b21-37eb-4d5d-80a4-4bbbdaddbc07-StreamThread-1-consumer-4262cd85-78ea-4b01-937a-264ecd4fbdad=[]}
    	assigned active {shouldflushstoresbeforeclosekeyvalue-5e506b21-37eb-4d5d-80a4-4bbbdaddbc07-StreamThread-1-consumer-4262cd85-78ea-4b01-937a-264ecd4fbdad=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldflushstoresbeforeclosekeyvalue.input-0, shouldflushstoresbeforeclosekeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldflushstoresbeforeclosekeyvalue.input-0, shouldflushstoresbeforeclosekeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    Using Scylla optimized driver!!!
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-15
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

    [0K[39mshouldFlushStoresBeforeClose(KVSchema)[m

      [0K[32m✔[90m [1] KEY_VALUE[31m (8.4s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldFlushStoresBeforeClose(KVSchema) > [2] FACT STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-16
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldflushstoresbeforeclosefact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosefact-fff9f50d-c51e-4093-9be4-0aff18c0206f-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosefact-fff9f50d-c51e-4093-9be4-0aff18c0206f-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosefact-fff9f50d-c51e-4093-9be4-0aff18c0206f-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldflushstoresbeforeclosefact-fff9f50d-c51e-4093-9be4-0aff18c0206f-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosefact-fff9f50d-c51e-4093-9be4-0aff18c0206f-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldflushstoresbeforeclosefact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    fff9f50d-c51e-4093-9be4-0aff18c0206f: [shouldflushstoresbeforeclosefact-fff9f50d-c51e-4093-9be4-0aff18c0206f-StreamThread-1-consumer-e859233c-4bb5-4790-aa2f-fe194a720390]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldflushstoresbeforeclosefact-fff9f50d-c51e-4093-9be4-0aff18c0206f-StreamThread-1-consumer-e859233c-4bb5-4790-aa2f-fe194a720390=[]}
    	assigned active {shouldflushstoresbeforeclosefact-fff9f50d-c51e-4093-9be4-0aff18c0206f-StreamThread-1-consumer-e859233c-4bb5-4790-aa2f-fe194a720390=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldflushstoresbeforeclosefact.input-0, shouldflushstoresbeforeclosefact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldflushstoresbeforeclosefact.input-0, shouldflushstoresbeforeclosefact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	lost active tasks: [0_0]
    	lost assigned standby tasks: []
     (org.apache.kafka.streams.processor.internals.StreamThread:104)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldflushstoresbeforeclosefact-fff9f50d-c51e-4093-9be4-0aff18c0206f-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldflushstoresbeforeclosefact-fff9f50d-c51e-4093-9be4-0aff18c0206f-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    fff9f50d-c51e-4093-9be4-0aff18c0206f: [shouldflushstoresbeforeclosefact-fff9f50d-c51e-4093-9be4-0aff18c0206f-StreamThread-1-consumer-845cdf95-d5ac-41d7-8745-ce9b2a5be077]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldflushstoresbeforeclosefact-fff9f50d-c51e-4093-9be4-0aff18c0206f-StreamThread-1-consumer-845cdf95-d5ac-41d7-8745-ce9b2a5be077=[]}
    	assigned active {shouldflushstoresbeforeclosefact-fff9f50d-c51e-4093-9be4-0aff18c0206f-StreamThread-1-consumer-845cdf95-d5ac-41d7-8745-ce9b2a5be077=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldflushstoresbeforeclosefact.input-0, shouldflushstoresbeforeclosefact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldflushstoresbeforeclosefact.input-0, shouldflushstoresbeforeclosefact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    Using Scylla optimized driver!!!
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-16
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
      [0K[32m✔[90m [2] FACT[31m (11.3s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldRepairOffsetsIfOutOfRangeAndConfigured(KVSchema) > [1] KEY_VALUE STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-17
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = true
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-52b63f56-4a21-4c58-a641-7b272f0522ce-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-52b63f56-4a21-4c58-a641-7b272f0522ce-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-52b63f56-4a21-4c58-a641-7b272f0522ce-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-52b63f56-4a21-4c58-a641-7b272f0522ce-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-52b63f56-4a21-4c58-a641-7b272f0522ce-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    52b63f56-4a21-4c58-a641-7b272f0522ce: [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-52b63f56-4a21-4c58-a641-7b272f0522ce-StreamThread-1-consumer-1b751283-c951-45c0-a9b6-21e035946965]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-52b63f56-4a21-4c58-a641-7b272f0522ce-StreamThread-1-consumer-1b751283-c951-45c0-a9b6-21e035946965=[]}
    	assigned active {shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-52b63f56-4a21-4c58-a641-7b272f0522ce-StreamThread-1-consumer-1b751283-c951-45c0-a9b6-21e035946965=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input-0, shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input-0, shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-17
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = true
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-13b62b02-7bbc-4060-8687-2bc38900661a-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-13b62b02-7bbc-4060-8687-2bc38900661a-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-13b62b02-7bbc-4060-8687-2bc38900661a-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-13b62b02-7bbc-4060-8687-2bc38900661a-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-13b62b02-7bbc-4060-8687-2bc38900661a-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    13b62b02-7bbc-4060-8687-2bc38900661a: [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-13b62b02-7bbc-4060-8687-2bc38900661a-StreamThread-1-consumer-a7e9961f-8415-4dae-a47d-84969f5e5c80]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-13b62b02-7bbc-4060-8687-2bc38900661a-StreamThread-1-consumer-a7e9961f-8415-4dae-a47d-84969f5e5c80=[]}
    	assigned active {shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-13b62b02-7bbc-4060-8687-2bc38900661a-StreamThread-1-consumer-a7e9961f-8415-4dae-a47d-84969f5e5c80=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input-0, shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input-0, shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.clients.consumer.OffsetOutOfRangeException: Fetch position FetchPosition{offset=198, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:54363 (id: 1 rack: null)], epoch=0}} is out of range for partition shouldrepairoffsetsifoutofrangeandconfiguredkeyvalue-shouldrepairoffsetsifoutofrangeandconfiguredkeyvalueagg-changelog-0
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.handleInitializeErrors(FetchCollector.java:348)
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.initialize(FetchCollector.java:230)
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.collectFetch(FetchCollector.java:110)
    	at org.apache.kafka.clients.consumer.internals.Fetcher.collectFetch(Fetcher.java:145)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.pollForFetches(LegacyKafkaConsumer.java:693)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.poll(LegacyKafkaConsumer.java:617)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.poll(LegacyKafkaConsumer.java:590)
    	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:874)
    	at dev.responsive.kafka.internal.clients.DelegatingConsumer.poll(DelegatingConsumer.java:95)
    	at dev.responsive.kafka.internal.clients.ResponsiveRestoreConsumer.poll(ResponsiveRestoreConsumer.java:111)
    	at org.apache.kafka.streams.processor.internals.StoreChangelogReader.pollRecordsFromRestoreConsumer(StoreChangelogReader.java:494)
    	at org.apache.kafka.streams.processor.internals.StoreChangelogReader.restore(StoreChangelogReader.java:450)
    	at org.apache.kafka.streams.processor.internals.StreamThread.initializeAndRestorePhase(StreamThread.java:1134)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:921)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-18
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

    [0K[39mshouldRepairOffsetsIfOutOfRangeAndConfigured(KVSchema)[m

      [0K[32m✔[90m [1] KEY_VALUE[31m (21.4s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest > shouldRepairOffsetsIfOutOfRangeAndConfigured(KVSchema) > [2] FACT STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-18
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = true
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrepairoffsetsifoutofrangeandconfiguredfact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-c0875558-9c09-4a85-95bd-5b76ab60c119-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-c0875558-9c09-4a85-95bd-5b76ab60c119-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-c0875558-9c09-4a85-95bd-5b76ab60c119-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-c0875558-9c09-4a85-95bd-5b76ab60c119-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-c0875558-9c09-4a85-95bd-5b76ab60c119-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrepairoffsetsifoutofrangeandconfiguredfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    c0875558-9c09-4a85-95bd-5b76ab60c119: [shouldrepairoffsetsifoutofrangeandconfiguredfact-c0875558-9c09-4a85-95bd-5b76ab60c119-StreamThread-1-consumer-a8456661-2c92-4401-8d4f-0545fe46f04c]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrepairoffsetsifoutofrangeandconfiguredfact-c0875558-9c09-4a85-95bd-5b76ab60c119-StreamThread-1-consumer-a8456661-2c92-4401-8d4f-0545fe46f04c=[]}
    	assigned active {shouldrepairoffsetsifoutofrangeandconfiguredfact-c0875558-9c09-4a85-95bd-5b76ab60c119-StreamThread-1-consumer-a8456661-2c92-4401-8d4f-0545fe46f04c=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	lost active tasks: [0_0]
    	lost assigned standby tasks: []
     (org.apache.kafka.streams.processor.internals.StreamThread:104)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-c0875558-9c09-4a85-95bd-5b76ab60c119-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-c0875558-9c09-4a85-95bd-5b76ab60c119-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    c0875558-9c09-4a85-95bd-5b76ab60c119: [shouldrepairoffsetsifoutofrangeandconfiguredfact-c0875558-9c09-4a85-95bd-5b76ab60c119-StreamThread-1-consumer-ddf8703c-8de0-4ef1-a84e-847a0daf7fec]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrepairoffsetsifoutofrangeandconfiguredfact-c0875558-9c09-4a85-95bd-5b76ab60c119-StreamThread-1-consumer-ddf8703c-8de0-4ef1-a84e-847a0daf7fec=[]}
    	assigned active {shouldrepairoffsetsifoutofrangeandconfiguredfact-c0875558-9c09-4a85-95bd-5b76ab60c119-StreamThread-1-consumer-ddf8703c-8de0-4ef1-a84e-847a0daf7fec=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-19
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = true
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 0
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldrepairoffsetsifoutofrangeandconfiguredfact
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-c3039d76-9275-4172-8c12-d735129ed712-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-c3039d76-9275-4172-8c12-d735129ed712-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-c3039d76-9275-4172-8c12-d735129ed712-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 20000
    	transactional.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-c3039d76-9275-4172-8c12-d735129ed712-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldrepairoffsetsifoutofrangeandconfiguredfact-c3039d76-9275-4172-8c12-d735129ed712-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldrepairoffsetsifoutofrangeandconfiguredfact
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 5000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    c3039d76-9275-4172-8c12-d735129ed712: [shouldrepairoffsetsifoutofrangeandconfiguredfact-c3039d76-9275-4172-8c12-d735129ed712-StreamThread-1-consumer-08656be8-72e6-4f21-83d4-55f48abea9d7]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldrepairoffsetsifoutofrangeandconfiguredfact-c3039d76-9275-4172-8c12-d735129ed712-StreamThread-1-consumer-08656be8-72e6-4f21-83d4-55f48abea9d7=[]}
    	assigned active {shouldrepairoffsetsifoutofrangeandconfiguredfact-c3039d76-9275-4172-8c12-d735129ed712-StreamThread-1-consumer-08656be8-72e6-4f21-83d4-55f48abea9d7=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldrepairoffsetsifoutofrangeandconfiguredfact.input-0, shouldrepairoffsetsifoutofrangeandconfiguredfact.input_tbl-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    org.apache.kafka.clients.consumer.OffsetOutOfRangeException: Fetch position FetchPosition{offset=198, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:54363 (id: 1 rack: null)], epoch=0}} is out of range for partition shouldrepairoffsetsifoutofrangeandconfiguredfact-shouldrepairoffsetsifoutofrangeandconfiguredfactagg-changelog-0
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.handleInitializeErrors(FetchCollector.java:348)
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.initialize(FetchCollector.java:230)
    	at org.apache.kafka.clients.consumer.internals.FetchCollector.collectFetch(FetchCollector.java:110)
    	at org.apache.kafka.clients.consumer.internals.Fetcher.collectFetch(Fetcher.java:145)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.pollForFetches(LegacyKafkaConsumer.java:693)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.poll(LegacyKafkaConsumer.java:617)
    	at org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer.poll(LegacyKafkaConsumer.java:590)
    	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:874)
    	at dev.responsive.kafka.internal.clients.DelegatingConsumer.poll(DelegatingConsumer.java:95)
    	at dev.responsive.kafka.internal.clients.ResponsiveRestoreConsumer.poll(ResponsiveRestoreConsumer.java:111)
    	at org.apache.kafka.streams.processor.internals.StoreChangelogReader.pollRecordsFromRestoreConsumer(StoreChangelogReader.java:494)
    	at org.apache.kafka.streams.processor.internals.StoreChangelogReader.restore(StoreChangelogReader.java:450)
    	at org.apache.kafka.streams.processor.internals.StreamThread.initializeAndRestorePhase(StreamThread.java:1134)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runOnceWithoutProcessingThreads(StreamThread.java:921)
    	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:686)
    	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:645)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-20
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
      [0K[32m✔[90m [2] FACT[31m (22.6s)[m

ResponsiveKeyValueStoreRestoreIntegrationTest STANDARD_ERROR
    Test 7(dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest): CASSANDRA teardown begins at 1731123047006ms (speed check)
    Test 7(dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest): CASSANDRA teardown ends at 1731123047006ms (duration: PT0S) (speed check)
    Test 7(dev.responsive.kafka.integration.ResponsiveKeyValueStoreRestoreIntegrationTest): CASSANDRA test total runtime=PT1M51.192S) (speed check)

Gradle Test Executor 10 STANDARD_ERROR
    Test 8: creating ResponsiveExtension(backend=MONGO_DB) at 1731123047008ms (speed check)

ResponsiveSessionStoreIntegrationTest STANDARD_ERROR
    SOPHIE: speed check version 1
    Test 8(dev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest): MONGO_DB setup begins at 1731123047025ms (speed check)
    Test 8(dev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest): MONGO_DB setup ends at 1731123047025ms (duration: PT0S) (speed check)

ResponsiveSessionStoreIntegrationTest > shouldComputeSessionAggregate() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-19
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:54361
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldComputeSessionAggregate-296655225
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeSessionAggregate-296655225-2104765b-29d1-4c2b-93e7-71d404b41592-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeSessionAggregate-296655225-2104765b-29d1-4c2b-93e7-71d404b41592-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeSessionAggregate-296655225-2104765b-29d1-4c2b-93e7-71d404b41592-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeSessionAggregate-296655225-2104765b-29d1-4c2b-93e7-71d404b41592-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldComputeSessionAggregate-296655225
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1000
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    2104765b-29d1-4c2b-93e7-71d404b41592: [shouldComputeSessionAggregate-296655225-2104765b-29d1-4c2b-93e7-71d404b41592-StreamThread-1-consumer-8d76b9d3-8e31-4ecc-a5ac-7d097c427bba]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldComputeSessionAggregate-296655225-2104765b-29d1-4c2b-93e7-71d404b41592-StreamThread-1-consumer-8d76b9d3-8e31-4ecc-a5ac-7d097c427bba=[]}
    	assigned active {shouldComputeSessionAggregate-296655225-2104765b-29d1-4c2b-93e7-71d404b41592-StreamThread-1-consumer-8d76b9d3-8e31-4ecc-a5ac-7d097c427bba=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldComputeSessionAggregate-296655225.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldComputeSessionAggregate-296655225.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)

  [0K[39mdev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest[m

    [0K[32m✔[90m shouldComputeSessionAggregate()[33m (1.5s)[m

ResponsiveSessionStoreIntegrationTest STANDARD_ERROR
    Test 8(dev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest): MONGO_DB teardown begins at 1731123048595ms (speed check)
    Test 8(dev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest): MONGO_DB teardown ends at 1731123048595ms (duration: PT0S) (speed check)
    Test 8(dev.responsive.kafka.integration.ResponsiveSessionStoreIntegrationTest): MONGO_DB test total runtime=PT1.587S) (speed check)

Gradle Test Executor 10 STANDARD_ERROR
    Test 9: creating ResponsiveExtension(backend=MONGO_DB) at 1731123048596ms (speed check)

ResponsiveWindowStoreIntegrationTest STANDARD_ERROR
    SOPHIE: speed check version 1
    Test 9(dev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest): MONGO_DB setup begins at 1731123048598ms (speed check)
    Test 9(dev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest): MONGO_DB setup ends at 1731123048598ms (duration: PT0S) (speed check)

ResponsiveWindowStoreIntegrationTest > shouldDoStreamStreamJoin() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-20
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:54361
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 1
    	responsive.window.bloom.filter.expected.keys = 10
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldDoStreamStreamJoin--1128762815
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDoStreamStreamJoin--1128762815-d9a6ad6c-1f1a-45b5-bf5d-477fd0725b03-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDoStreamStreamJoin--1128762815-d9a6ad6c-1f1a-45b5-bf5d-477fd0725b03-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDoStreamStreamJoin--1128762815-d9a6ad6c-1f1a-45b5-bf5d-477fd0725b03-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldDoStreamStreamJoin--1128762815-d9a6ad6c-1f1a-45b5-bf5d-477fd0725b03-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldDoStreamStreamJoin--1128762815
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    d9a6ad6c-1f1a-45b5-bf5d-477fd0725b03: [shouldDoStreamStreamJoin--1128762815-d9a6ad6c-1f1a-45b5-bf5d-477fd0725b03-StreamThread-1-consumer-71b46415-9880-4b23-b8a7-afaf82de8d45]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldDoStreamStreamJoin--1128762815-d9a6ad6c-1f1a-45b5-bf5d-477fd0725b03-StreamThread-1-consumer-71b46415-9880-4b23-b8a7-afaf82de8d45=[]}
    	assigned active {shouldDoStreamStreamJoin--1128762815-d9a6ad6c-1f1a-45b5-bf5d-477fd0725b03-StreamThread-1-consumer-71b46415-9880-4b23-b8a7-afaf82de8d45=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldDoStreamStreamJoin--1128762815.input-0, shouldDoStreamStreamJoin--1128762815.other-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldDoStreamStreamJoin--1128762815.input-0, shouldDoStreamStreamJoin--1128762815.other-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    Joining: L:a, R:a
    Joining: L:a2, R:a
    Joining: L:a3, R:a
    Joining: L:b, R:b
    Joining: L:b, R:b2
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-21
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 500
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest[m

    [0K[32m✔[90m shouldDoStreamStreamJoin()[33m (1.7s)[m

ResponsiveWindowStoreIntegrationTest > shouldComputeHoppingWindowAggregateWithRetention() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-21
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:54361
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 1
    	responsive.window.bloom.filter.expected.keys = 10
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldComputeHoppingWindowAggregateWithRetention-1024141456
    	application.server = host1:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeHoppingWindowAggregateWithRetention-1024141456-4e9dc1d4-656a-4e96-ad82-ae681f0bd6a5-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeHoppingWindowAggregateWithRetention-1024141456-4e9dc1d4-656a-4e96-ad82-ae681f0bd6a5-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeHoppingWindowAggregateWithRetention-1024141456-4e9dc1d4-656a-4e96-ad82-ae681f0bd6a5-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeHoppingWindowAggregateWithRetention-1024141456-4e9dc1d4-656a-4e96-ad82-ae681f0bd6a5-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldComputeHoppingWindowAggregateWithRetention-1024141456
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    4e9dc1d4-656a-4e96-ad82-ae681f0bd6a5: [shouldComputeHoppingWindowAggregateWithRetention-1024141456-4e9dc1d4-656a-4e96-ad82-ae681f0bd6a5-StreamThread-1-consumer-63473810-0701-4dd0-8983-0ce73fe05064]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldComputeHoppingWindowAggregateWithRetention-1024141456-4e9dc1d4-656a-4e96-ad82-ae681f0bd6a5-StreamThread-1-consumer-63473810-0701-4dd0-8983-0ce73fe05064=[]}
    	assigned active {shouldComputeHoppingWindowAggregateWithRetention-1024141456-4e9dc1d4-656a-4e96-ad82-ae681f0bd6a5-StreamThread-1-consumer-63473810-0701-4dd0-8983-0ce73fe05064=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldComputeHoppingWindowAggregateWithRetention-1024141456.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldComputeHoppingWindowAggregateWithRetention-1024141456.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    [0K[32m✔[90m shouldComputeHoppingWindowAggregateWithRetention()[31m (1m 1s)[m

ResponsiveWindowStoreIntegrationTest > shouldComputeTumblingWindowAggregateWithRetention() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:54361
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 1
    	responsive.window.bloom.filter.expected.keys = 10
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldComputeTumblingWindowAggregateWithRetention--361639894
    	application.server = host1:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention--361639894-43110c04-958f-4a48-9f8b-28a667108d34-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention--361639894-43110c04-958f-4a48-9f8b-28a667108d34-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention--361639894-43110c04-958f-4a48-9f8b-28a667108d34-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention--361639894-43110c04-958f-4a48-9f8b-28a667108d34-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldComputeTumblingWindowAggregateWithRetention--361639894
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-22
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    43110c04-958f-4a48-9f8b-28a667108d34: [shouldComputeTumblingWindowAggregateWithRetention--361639894-43110c04-958f-4a48-9f8b-28a667108d34-StreamThread-1-consumer-75a1460e-d25a-406a-abae-cd84323c2e19]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldComputeTumblingWindowAggregateWithRetention--361639894-43110c04-958f-4a48-9f8b-28a667108d34-StreamThread-1-consumer-75a1460e-d25a-406a-abae-cd84323c2e19=[]}
    	assigned active {shouldComputeTumblingWindowAggregateWithRetention--361639894-43110c04-958f-4a48-9f8b-28a667108d34-StreamThread-1-consumer-75a1460e-d25a-406a-abae-cd84323c2e19=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldComputeTumblingWindowAggregateWithRetention--361639894.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldComputeTumblingWindowAggregateWithRetention--361639894.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:54361
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 1
    	responsive.window.bloom.filter.expected.keys = 10
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldComputeTumblingWindowAggregateWithRetention--361639894
    	application.server = host2:1024
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention--361639894-9c89ab53-6230-4066-83c9-aed00ef562b0-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention--361639894-9c89ab53-6230-4066-83c9-aed00ef562b0-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention--361639894-9c89ab53-6230-4066-83c9-aed00ef562b0-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeTumblingWindowAggregateWithRetention--361639894-9c89ab53-6230-4066-83c9-aed00ef562b0-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldComputeTumblingWindowAggregateWithRetention--361639894
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-23
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    9c89ab53-6230-4066-83c9-aed00ef562b0: [shouldComputeTumblingWindowAggregateWithRetention--361639894-9c89ab53-6230-4066-83c9-aed00ef562b0-StreamThread-1-consumer-93685b03-50bc-446d-9c52-254dda66b6c2]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldComputeTumblingWindowAggregateWithRetention--361639894-9c89ab53-6230-4066-83c9-aed00ef562b0-StreamThread-1-consumer-93685b03-50bc-446d-9c52-254dda66b6c2=[]}
    	assigned active {shouldComputeTumblingWindowAggregateWithRetention--361639894-9c89ab53-6230-4066-83c9-aed00ef562b0-StreamThread-1-consumer-93685b03-50bc-446d-9c52-254dda66b6c2=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldComputeTumblingWindowAggregateWithRetention--361639894.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldComputeTumblingWindowAggregateWithRetention--361639894.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    [0K[32m✔[90m shouldComputeTumblingWindowAggregateWithRetention()[31m (3m 6s)[m

ResponsiveWindowStoreIntegrationTest > shouldComputeMultipleWindowsPerSegment() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = null
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = null
    	responsive.cassandra.password = null
    	responsive.cassandra.port = -1
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = mongodb://localhost:54361
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = MONGO_DB
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 1
    	responsive.window.bloom.filter.expected.keys = 10
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Pinged your deployment. You successfully connected to MongoDB!
    	acceptable.recovery.lag = 10000
    	application.id = shouldComputeMultipleWindowsPerSegment-1174712602
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeMultipleWindowsPerSegment-1174712602-46ba3efc-08b0-4ad3-9d84-07712032e2a3-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeMultipleWindowsPerSegment-1174712602-46ba3efc-08b0-4ad3-9d84-07712032e2a3-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeMultipleWindowsPerSegment-1174712602-46ba3efc-08b0-4ad3-9d84-07712032e2a3-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldComputeMultipleWindowsPerSegment-1174712602-46ba3efc-08b0-4ad3-9d84-07712032e2a3-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldComputeMultipleWindowsPerSegment-1174712602
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 5000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 4999
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-24
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    46ba3efc-08b0-4ad3-9d84-07712032e2a3: [shouldComputeMultipleWindowsPerSegment-1174712602-46ba3efc-08b0-4ad3-9d84-07712032e2a3-StreamThread-1-consumer-05efd294-57ff-4fce-84ae-c7acf63b9533]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldComputeMultipleWindowsPerSegment-1174712602-46ba3efc-08b0-4ad3-9d84-07712032e2a3-StreamThread-1-consumer-05efd294-57ff-4fce-84ae-c7acf63b9533=[]}
    	assigned active {shouldComputeMultipleWindowsPerSegment-1174712602-46ba3efc-08b0-4ad3-9d84-07712032e2a3-StreamThread-1-consumer-05efd294-57ff-4fce-84ae-c7acf63b9533=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldComputeMultipleWindowsPerSegment-1174712602.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldComputeMultipleWindowsPerSegment-1174712602.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    [0K[32m✔[90m shouldComputeMultipleWindowsPerSegment()[31m (1m 1s)[m

ResponsiveWindowStoreIntegrationTest STANDARD_ERROR
    Test 9(dev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest): MONGO_DB teardown begins at 1731123359393ms (speed check)
    Test 9(dev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest): MONGO_DB teardown ends at 1731123359393ms (duration: PT0S) (speed check)
    Test 9(dev.responsive.kafka.integration.ResponsiveWindowStoreIntegrationTest): MONGO_DB test total runtime=PT5M10.797S) (speed check)

Gradle Test Executor 10 STANDARD_ERROR
    Test 10: creating ResponsiveExtension(backend=CASSANDRA) at 1731123359397ms (speed check)

RowLevelTtlIntegrationTest STANDARD_ERROR
    SOPHIE: speed check version 1
    Test 10(dev.responsive.kafka.integration.RowLevelTtlIntegrationTest): CASSANDRA setup begins at 1731123359401ms (speed check)
    Test 10(dev.responsive.kafka.integration.RowLevelTtlIntegrationTest): CASSANDRA setup ends at 1731123359401ms (duration: PT0S) (speed check)

RowLevelTtlIntegrationTest > shouldApplyRowLevelTtlForKeyAndValue() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-25
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = maxIdleTimeMs=60000
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldApplyRowLevelTtlForKeyAndValue
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 0
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldApplyRowLevelTtlForKeyAndValue-34ec550f-f112-405b-be57-cd8ad6216db5-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldApplyRowLevelTtlForKeyAndValue-34ec550f-f112-405b-be57-cd8ad6216db5-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldApplyRowLevelTtlForKeyAndValue-34ec550f-f112-405b-be57-cd8ad6216db5-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldApplyRowLevelTtlForKeyAndValue-34ec550f-f112-405b-be57-cd8ad6216db5-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldApplyRowLevelTtlForKeyAndValue
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    34ec550f-f112-405b-be57-cd8ad6216db5: [shouldApplyRowLevelTtlForKeyAndValue-34ec550f-f112-405b-be57-cd8ad6216db5-StreamThread-1-consumer-3f425f61-7aa3-4752-bbbb-4ca1158a4f0c]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldApplyRowLevelTtlForKeyAndValue-34ec550f-f112-405b-be57-cd8ad6216db5-StreamThread-1-consumer-3f425f61-7aa3-4752-bbbb-4ca1158a4f0c=[]}
    	assigned active {shouldApplyRowLevelTtlForKeyAndValue-34ec550f-f112-405b-be57-cd8ad6216db5-StreamThread-1-consumer-3f425f61-7aa3-4752-bbbb-4ca1158a4f0c=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldApplyRowLevelTtlForKeyAndValue.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldApplyRowLevelTtlForKeyAndValue.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-22
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.RowLevelTtlIntegrationTest[m

    [0K[32m✔[90m shouldApplyRowLevelTtlForKeyAndValue()[31m (6.2s)[m

RowLevelTtlIntegrationTest STANDARD_ERROR
    Test 10(dev.responsive.kafka.integration.RowLevelTtlIntegrationTest): CASSANDRA teardown begins at 1731123365693ms (speed check)
    Test 10(dev.responsive.kafka.integration.RowLevelTtlIntegrationTest): CASSANDRA teardown ends at 1731123365693ms (duration: PT0S) (speed check)
    Test 10(dev.responsive.kafka.integration.RowLevelTtlIntegrationTest): CASSANDRA test total runtime=PT6.296S) (speed check)

Gradle Test Executor 10 STANDARD_ERROR
    Test 11: creating ResponsiveExtension(backend=CASSANDRA) at 1731123365706ms (speed check)

StoreQueryIntegrationTest STANDARD_ERROR
    SOPHIE: speed check version 1
    Test 11(dev.responsive.kafka.integration.StoreQueryIntegrationTest): CASSANDRA setup begins at 1731123365719ms (speed check)
    Test 11(dev.responsive.kafka.integration.StoreQueryIntegrationTest): CASSANDRA setup ends at 1731123365719ms (duration: PT0S) (speed check)

StoreQueryIntegrationTest > shouldAggregateAcrossAllKeysUsingAllQuery() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-26
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldAggregateAcrossAllKeysUsingAllQuery
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAcrossAllKeysUsingAllQuery-2facc7b8-7fbf-42a9-8d16-49a7599db88c-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAcrossAllKeysUsingAllQuery-2facc7b8-7fbf-42a9-8d16-49a7599db88c-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAcrossAllKeysUsingAllQuery-2facc7b8-7fbf-42a9-8d16-49a7599db88c-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAcrossAllKeysUsingAllQuery-2facc7b8-7fbf-42a9-8d16-49a7599db88c-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldAggregateAcrossAllKeysUsingAllQuery
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    2facc7b8-7fbf-42a9-8d16-49a7599db88c: [shouldAggregateAcrossAllKeysUsingAllQuery-2facc7b8-7fbf-42a9-8d16-49a7599db88c-StreamThread-1-consumer-842bdfae-d47a-4e7b-864b-ee7e286ffde6]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldAggregateAcrossAllKeysUsingAllQuery-2facc7b8-7fbf-42a9-8d16-49a7599db88c-StreamThread-1-consumer-842bdfae-d47a-4e7b-864b-ee7e286ffde6=[]}
    	assigned active {shouldAggregateAcrossAllKeysUsingAllQuery-2facc7b8-7fbf-42a9-8d16-49a7599db88c-StreamThread-1-consumer-842bdfae-d47a-4e7b-864b-ee7e286ffde6=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldAggregateAcrossAllKeysUsingAllQuery.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldAggregateAcrossAllKeysUsingAllQuery.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-23
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.StoreQueryIntegrationTest[m

    [0K[32m✔[90m shouldAggregateAcrossAllKeysUsingAllQuery()[31m (4.5s)[m

StoreQueryIntegrationTest > shouldAggregateAllCapitalLettersUsingRangeQuery() STANDARD_OUT
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-27
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldAggregateAllCapitalLettersUsingRangeQuery
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 1
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAllCapitalLettersUsingRangeQuery-b56b5851-9b5a-4a68-ac69-993b3c2d7773-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAllCapitalLettersUsingRangeQuery-b56b5851-9b5a-4a68-ac69-993b3c2d7773-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAllCapitalLettersUsingRangeQuery-b56b5851-9b5a-4a68-ac69-993b3c2d7773-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldAggregateAllCapitalLettersUsingRangeQuery-b56b5851-9b5a-4a68-ac69-993b3c2d7773-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldAggregateAllCapitalLettersUsingRangeQuery
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    b56b5851-9b5a-4a68-ac69-993b3c2d7773: [shouldAggregateAllCapitalLettersUsingRangeQuery-b56b5851-9b5a-4a68-ac69-993b3c2d7773-StreamThread-1-consumer-19a3b16a-b12d-40f5-a1d5-4b8790e93112]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldAggregateAllCapitalLettersUsingRangeQuery-b56b5851-9b5a-4a68-ac69-993b3c2d7773-StreamThread-1-consumer-19a3b16a-b12d-40f5-a1d5-4b8790e93112=[]}
    	assigned active {shouldAggregateAllCapitalLettersUsingRangeQuery-b56b5851-9b5a-4a68-ac69-993b3c2d7773-StreamThread-1-consumer-19a3b16a-b12d-40f5-a1d5-4b8790e93112=[0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldAggregateAllCapitalLettersUsingRangeQuery.input-0]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldAggregateAllCapitalLettersUsingRangeQuery.input-0]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-24
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    [0K[32m✔[90m shouldAggregateAllCapitalLettersUsingRangeQuery()[31m (4.5s)[m

StoreQueryIntegrationTest STANDARD_ERROR
    Test 11(dev.responsive.kafka.integration.StoreQueryIntegrationTest): CASSANDRA teardown begins at 1731123374868ms (speed check)
    Test 11(dev.responsive.kafka.integration.StoreQueryIntegrationTest): CASSANDRA teardown ends at 1731123374868ms (duration: PT0S) (speed check)
    Test 11(dev.responsive.kafka.integration.StoreQueryIntegrationTest): CASSANDRA test total runtime=PT9.162S) (speed check)

Gradle Test Executor 10 STANDARD_ERROR
    Test 12: creating ResponsiveExtension(empty) at 1731123374874ms (speed check)

TablePartitionerIntegrationTest STANDARD_ERROR
    SOPHIE: speed check version 1
    Test 12(dev.responsive.kafka.integration.TablePartitionerIntegrationTest): CASSANDRA setup begins at 1731123374884ms (speed check)
    Test 12(dev.responsive.kafka.integration.TablePartitionerIntegrationTest): CASSANDRA setup ends at 1731123374884ms (duration: PT0S) (speed check)

TablePartitionerIntegrationTest > shouldFlushToRemoteTableWithSubpartitions() STANDARD_OUT
    Using Scylla optimized driver!!!
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-28
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = 32
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.integration.TablePartitionerIntegrationTest$LongBytesHasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldFlushToRemoteTableWithSubpartitions
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 100
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithSubpartitions-842fd8f2-2a64-4464-b6b7-f73ebcd4e5c4-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithSubpartitions-842fd8f2-2a64-4464-b6b7-f73ebcd4e5c4-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithSubpartitions-842fd8f2-2a64-4464-b6b7-f73ebcd4e5c4-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 10000
    	transactional.id = shouldFlushToRemoteTableWithSubpartitions-842fd8f2-2a64-4464-b6b7-f73ebcd4e5c4-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithSubpartitions-842fd8f2-2a64-4464-b6b7-f73ebcd4e5c4-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldFlushToRemoteTableWithSubpartitions
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    842fd8f2-2a64-4464-b6b7-f73ebcd4e5c4: [shouldFlushToRemoteTableWithSubpartitions-842fd8f2-2a64-4464-b6b7-f73ebcd4e5c4-StreamThread-1-consumer-06823840-a098-4c1d-9f59-45a5220cd305]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldFlushToRemoteTableWithSubpartitions-842fd8f2-2a64-4464-b6b7-f73ebcd4e5c4-StreamThread-1-consumer-06823840-a098-4c1d-9f59-45a5220cd305=[]}
    	assigned active {shouldFlushToRemoteTableWithSubpartitions-842fd8f2-2a64-4464-b6b7-f73ebcd4e5c4-StreamThread-1-consumer-06823840-a098-4c1d-9f59-45a5220cd305=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldFlushToRemoteTableWithSubpartitions.input-0, shouldFlushToRemoteTableWithSubpartitions.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldFlushToRemoteTableWithSubpartitions.input-0, shouldFlushToRemoteTableWithSubpartitions.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-25
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)

  [0K[39mdev.responsive.kafka.integration.TablePartitionerIntegrationTest[m

    [0K[32m✔[90m shouldFlushToRemoteTableWithSubpartitions()[31m (6.4s)[m

TablePartitionerIntegrationTest > shouldFlushToRemoteTableWithoutSubpartitions() STANDARD_OUT
    Using Scylla optimized driver!!!
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-29
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.LongSerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = 32
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 1
    	responsive.subpartition.hasher = class dev.responsive.kafka.integration.TablePartitionerIntegrationTest$LongBytesHasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    Using Scylla optimized driver!!!
    	acceptable.recovery.lag = 10000
    	application.id = shouldFlushToRemoteTableWithoutSubpartitions
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 100
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$LongSerde
    	dsl.store.suppliers.class = class dev.responsive.kafka.api.stores.ResponsiveDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = exactly_once_v2
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 40000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T//kafka-streams
    	statestore.cache.max.bytes = 0
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithoutSubpartitions-86c2f6c8-186a-4978-8bde-71834d754ff7-admin
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = none
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithoutSubpartitions-86c2f6c8-186a-4978-8bde-71834d754ff7-StreamThread-1-restore-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithoutSubpartitions-86c2f6c8-186a-4978-8bde-71834d754ff7-StreamThread-1-producer
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 2147483647
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 100
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 10000
    	transactional.id = shouldFlushToRemoteTableWithoutSubpartitions-86c2f6c8-186a-4978-8bde-71834d754ff7-1
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = false
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = shouldFlushToRemoteTableWithoutSubpartitions-86c2f6c8-186a-4978-8bde-71834d754ff7-StreamThread-1-consumer
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldFlushToRemoteTableWithoutSubpartitions
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = false
    	internal.throw.on.fetch.stable.offset.unsupported = true
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 1000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    86c2f6c8-186a-4978-8bde-71834d754ff7: [shouldFlushToRemoteTableWithoutSubpartitions-86c2f6c8-186a-4978-8bde-71834d754ff7-StreamThread-1-consumer-da06acba-05b1-4002-9ef5-11a8b1849d02]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:629)
    and stateless tasks: [] (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:640)
    	prev owned active {}
    	prev owned standby {shouldFlushToRemoteTableWithoutSubpartitions-86c2f6c8-186a-4978-8bde-71834d754ff7-StreamThread-1-consumer-da06acba-05b1-4002-9ef5-11a8b1849d02=[]}
    	assigned active {shouldFlushToRemoteTableWithoutSubpartitions-86c2f6c8-186a-4978-8bde-71834d754ff7-StreamThread-1-consumer-da06acba-05b1-4002-9ef5-11a8b1849d02=[0_1, 0_0]}
    	revoking active {}
    	assigned standby {}
     (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:904)
    	Assigned partitions:                       [shouldFlushToRemoteTableWithoutSubpartitions.input-0, shouldFlushToRemoteTableWithoutSubpartitions.input-1]
    	Current owned partitions:                  []
    	Added partitions (assigned - owned):       [shouldFlushToRemoteTableWithoutSubpartitions.input-0, shouldFlushToRemoteTableWithoutSubpartitions.input-1]
    	Revoked partitions (owned - assigned):     []
     (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:382)
    	New active tasks: [0_1, 0_0]
    	New standby tasks: []
    	Existing active tasks: []
    	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:328)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 5000
    	auto.include.jmx.reporter = true
    	auto.offset.reset = latest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-null-26
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = false
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = null
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_committed
    	key.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 1
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    [0K[32m✔[90m shouldFlushToRemoteTableWithoutSubpartitions()[31m (7.4s)[m

TablePartitionerIntegrationTest STANDARD_ERROR
    Test 12(dev.responsive.kafka.integration.TablePartitionerIntegrationTest): CASSANDRA teardown begins at 1731123388765ms (speed check)
    Test 12(dev.responsive.kafka.integration.TablePartitionerIntegrationTest): CASSANDRA teardown ends at 1731123388765ms (duration: PT0S) (speed check)
    Test 12(dev.responsive.kafka.integration.TablePartitionerIntegrationTest): CASSANDRA test total runtime=PT13.891S) (speed check)

Gradle Test Executor 10 STANDARD_ERROR
    Test 13: creating ResponsiveExtension(empty) at 1731123388767ms (speed check)

CassandraFactTableIntegrationTest STANDARD_ERROR
    SOPHIE: speed check version 1
    Test 13(dev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest): CASSANDRA setup begins at 1731123388769ms (speed check)
    Test 13(dev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest): CASSANDRA setup ends at 1731123388769ms (duration: PT0S) (speed check)

CassandraFactTableIntegrationTest > shouldRespectSemanticKeyBasedTtl() STANDARD_OUT
    Using Scylla optimized driver!!!

  [0K[39mdev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest[m

    [0K[32m✔[90m shouldRespectSemanticKeyBasedTtl()[31m (3.2s)[m

CassandraFactTableIntegrationTest > shouldRespectOverridesWithValueBasedTtl() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32m✔[90m shouldRespectOverridesWithValueBasedTtl()[31m (3.6s)[m

CassandraFactTableIntegrationTest > shouldInsertAndDelete() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32m✔[90m shouldInsertAndDelete()[31m (3.4s)[m

CassandraFactTableIntegrationTest > shouldInitializeWithCorrectMetadata() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32m✔[90m shouldInitializeWithCorrectMetadata()[31m (2.8s)[m

CassandraFactTableIntegrationTest > shouldRespectSemanticDefaultOnlyTtl() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32m✔[90m shouldRespectSemanticDefaultOnlyTtl()[31m (2.5s)[m

CassandraFactTableIntegrationTest > shouldConfigureDefaultTtl() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32m✔[90m shouldConfigureDefaultTtl()[31m (2.9s)[m

CassandraFactTableIntegrationTest > shouldRespectSemanticKeyValueBasedTtl() STANDARD_OUT
    Using Scylla optimized driver!!!
    [0K[32m✔[90m shouldRespectSemanticKeyValueBasedTtl()[31m (3.1s)[m

CassandraFactTableIntegrationTest STANDARD_ERROR
    Test 13(dev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest): CASSANDRA teardown begins at 1731123410713ms (speed check)
    Test 13(dev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest): CASSANDRA teardown ends at 1731123410714ms (duration: PT0.001S) (speed check)
    Test 13(dev.responsive.kafka.internal.db.CassandraFactTableIntegrationTest): CASSANDRA test total runtime=PT21.947S) (speed check)

Gradle Test Executor 10 STANDARD_ERROR
    Test 14: creating ResponsiveExtension(empty) at 1731123410716ms (speed check)

CassandraKVTableIntegrationTest STANDARD_ERROR
    SOPHIE: speed check version 1
    Test 14(dev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest): CASSANDRA setup begins at 1731123410719ms (speed check)
    Test 14(dev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest): CASSANDRA setup ends at 1731123410719ms (duration: PT0S) (speed check)

CassandraKVTableIntegrationTest > shouldSupportDataKeyThatEqualsMetadataKey() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!

  [0K[39mdev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest[m

    [0K[32m✔[90m shouldSupportDataKeyThatEqualsMetadataKey()[33m (1.7s)[m

CassandraKVTableIntegrationTest > shouldReturnRangeKeysInLexicalOrderAcrossMultipleSubPartitions() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32m✔[90m shouldReturnRangeKeysInLexicalOrderAcrossMultipleSubPartitions()[33m (1.5s)[m

CassandraKVTableIntegrationTest > shouldRespectSemanticDefaultOnlyTtlForRangeQueries() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32m✔[90m shouldRespectSemanticDefaultOnlyTtlForRangeQueries()[33m (1.4s)[m

CassandraKVTableIntegrationTest > shouldRespectSemanticDefaultOnlyTtlForLookups() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32m✔[90m shouldRespectSemanticDefaultOnlyTtlForLookups()[33m (1.4s)[m

CassandraKVTableIntegrationTest > shouldConfigureDefaultTtl() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32m✔[90m shouldConfigureDefaultTtl()[33m (1.3s)[m

CassandraKVTableIntegrationTest > shouldReturnAllKeysInLexicalOrderAcrossMultipleSubPartitions() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32m✔[90m shouldReturnAllKeysInLexicalOrderAcrossMultipleSubPartitions()[33m (1.7s)[m

CassandraKVTableIntegrationTest > shouldRespectSemanticDefaultOnlyTtlForAllQueries() STANDARD_OUT
    	responsive.application.id = 
    	responsive.async.flush.interval.ms = 5000
    	responsive.async.max.events.queued.per.async.thread = 5
    	responsive.async.max.events.queued.per.key = 3
    	responsive.async.thread.pool.size = 0
    	responsive.cassandra.check.interval.ms = 100
    	responsive.cassandra.consistency.reads = QUORUM
    	responsive.cassandra.consistency.writes = QUORUM
    	responsive.cassandra.datacenter = datacenter1
    	responsive.cassandra.desired.num.partitions = -1
    	responsive.cassandra.hostname = localhost
    	responsive.cassandra.password = null
    	responsive.cassandra.port = 54353
    	responsive.cassandra.username = null
    	responsive.compatibility.mode = FULL
    	responsive.controller.endpoint = 
    	responsive.env = itests
    	responsive.max.concurrent.requests = 128
    	responsive.metrics.enabled = false
    	responsive.mode = RUN
    	responsive.mongo.additional.connection.string.params = 
    	responsive.mongo.collection.sharding.chunks = 4
    	responsive.mongo.collection.sharding.enabled = false
    	responsive.mongo.endpoint = null
    	responsive.mongo.password = null
    	responsive.mongo.username = null
    	responsive.mongo.windowed.key.timestamp.first = false
    	responsive.org = responsive
    	responsive.platform.api.key = 
    	responsive.platform.api.secret = [hidden]
    	responsive.restore.offset.repair.enabled = false
    	responsive.storage.backend.type = CASSANDRA
    	responsive.store.flush.trigger.local.bytes = 9223372036854775807
    	responsive.store.flush.trigger.local.interval.ms = 30000
    	responsive.store.flush.trigger.local.jitter.ms = 0
    	responsive.store.flush.trigger.local.records = 2147483647
    	responsive.subpartition.hasher = class dev.responsive.kafka.internal.db.partitioning.Murmur3Hasher
    	responsive.window.bloom.filter.count = 0
    	responsive.window.bloom.filter.expected.keys = 1000
    	responsive.window.bloom.filter.fpp = 0.03
     (dev.responsive.kafka.api.config.ResponsiveConfig:370)
    Using Scylla optimized driver!!!
    [0K[32m✔[90m shouldRespectSemanticDefaultOnlyTtlForAllQueries()[33m (1.8s)[m

CassandraKVTableIntegrationTest STANDARD_ERROR
    Test 14(dev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest): CASSANDRA teardown begins at 1731123421876ms (speed check)
    Test 14(dev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest): CASSANDRA teardown ends at 1731123421876ms (duration: PT0S) (speed check)
    Test 14(dev.responsive.kafka.internal.db.CassandraKVTableIntegrationTest): CASSANDRA test total runtime=PT11.16S) (speed check)

Gradle Test Executor 10 STANDARD_ERROR
    Test 15: creating ResponsiveExtension(empty) at 1731123421878ms (speed check)

GlobalStreamThreadIntegrationTest STANDARD_ERROR
    SOPHIE: speed check version 1
    Test 15(org.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest): CASSANDRA setup begins at 1731123421884ms (speed check)
    Test 15(org.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest): CASSANDRA setup ends at 1731123421884ms (duration: PT0S) (speed check)

GlobalStreamThreadIntegrationTest > shouldRestoreWithSharedPartitionsAcrossApps() STANDARD_OUT
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-30
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldRestoreWithSharedPartitionsAcrossApps-global-27
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldRestoreWithSharedPartitionsAcrossApps-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldRestoreWithSharedPartitionsAcrossApps-global-28
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldRestoreWithSharedPartitionsAcrossApps-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acceptable.recovery.lag = 10000
    	application.id = shouldRestoreWithSharedPartitionsAcrossAppstestAppId
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 5000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	dsl.store.suppliers.class = class org.apache.kafka.streams.state.BuiltInDslStoreSuppliers$RocksDBDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 2000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T/junit8593752921077892947
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldRestoreWithSharedPartitionsAcrossApps-global-29
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldRestoreWithSharedPartitionsAcrossApps-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldRestoreWithSharedPartitionsAcrossApps-global-30
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldRestoreWithSharedPartitionsAcrossApps-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acceptable.recovery.lag = 10000
    	application.id = shouldRestoreWithSharedPartitionsAcrossAppstestAppId
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 5000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	dsl.store.suppliers.class = class org.apache.kafka.streams.state.BuiltInDslStoreSuppliers$RocksDBDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 2000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T/junit17615041056152380939
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)

  [0K[39morg.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest[m

    [0K[32m✔[90m shouldRestoreWithSharedPartitionsAcrossApps()[31m (2.6s)[m

GlobalStreamThreadIntegrationTest STANDARD_OUT

GlobalStreamThreadIntegrationTest > shouldShareWorkInSteadyState() STANDARD_OUT
    	auto.include.jmx.reporter = true
    	bootstrap.controllers = []
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	client.dns.lookup = use_all_dns_ips
    	client.id = 
    	connections.max.idle.ms = 300000
    	default.api.timeout.ms = 60000
    	enable.metrics.push = true
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
     (org.apache.kafka.clients.admin.AdminClientConfig:370)
    	acks = -1
    	auto.include.jmx.reporter = true
    	batch.size = 16384
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffer.memory = 33554432
    	client.dns.lookup = use_all_dns_ips
    	client.id = producer-31
    	compression.type = none
    	connections.max.idle.ms = 540000
    	delivery.timeout.ms = 120000
    	enable.idempotence = true
    	enable.metrics.push = true
    	interceptor.classes = []
    	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
    	linger.ms = 0
    	max.block.ms = 60000
    	max.in.flight.requests.per.connection = 5
    	max.request.size = 1048576
    	metadata.max.age.ms = 300000
    	metadata.max.idle.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partitioner.adaptive.partitioning.enable = true
    	partitioner.availability.timeout.ms = 0
    	partitioner.class = null
    	partitioner.ignore.keys = false
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retries = 2147483647
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	transaction.timeout.ms = 60000
    	transactional.id = null
    	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
     (org.apache.kafka.clients.producer.ProducerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldShareWorkInSteadyState-global-31
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldShareWorkInSteadyState-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldShareWorkInSteadyState-global-32
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldShareWorkInSteadyState-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acceptable.recovery.lag = 10000
    	application.id = shouldShareWorkInSteadyStatetestAppId
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 5000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	dsl.store.suppliers.class = class org.apache.kafka.streams.state.BuiltInDslStoreSuppliers$RocksDBDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 2000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T/junit13037976165768519513
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldShareWorkInSteadyState-global-33
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldShareWorkInSteadyState-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	allow.auto.create.topics = true
    	auto.commit.interval.ms = 100
    	auto.include.jmx.reporter = true
    	auto.offset.reset = earliest
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	check.crcs = true
    	client.dns.lookup = use_all_dns_ips
    	client.id = consumer-shouldShareWorkInSteadyState-global-34
    	client.rack = 
    	connections.max.idle.ms = 540000
    	default.api.timeout.ms = 60000
    	enable.auto.commit = true
    	enable.metrics.push = true
    	exclude.internal.topics = true
    	fetch.max.bytes = 52428800
    	fetch.max.wait.ms = 500
    	fetch.min.bytes = 1
    	group.id = shouldShareWorkInSteadyState-global
    	group.instance.id = null
    	group.protocol = classic
    	group.remote.assignor = null
    	heartbeat.interval.ms = 3000
    	interceptor.classes = []
    	internal.leave.group.on.close = true
    	internal.throw.on.fetch.stable.offset.unsupported = false
    	isolation.level = read_uncommitted
    	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
    	max.partition.fetch.bytes = 1048576
    	max.poll.interval.ms = 300000
    	max.poll.records = 3
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
    	receive.buffer.bytes = 65536
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	request.timeout.ms = 30000
    	retry.backoff.max.ms = 1000
    	retry.backoff.ms = 100
    	sasl.client.callback.handler.class = null
    	sasl.jaas.config = null
    	sasl.kerberos.kinit.cmd = /usr/bin/kinit
    	sasl.kerberos.min.time.before.relogin = 60000
    	sasl.kerberos.service.name = null
    	sasl.kerberos.ticket.renew.jitter = 0.05
    	sasl.kerberos.ticket.renew.window.factor = 0.8
    	sasl.login.callback.handler.class = null
    	sasl.login.class = null
    	sasl.login.connect.timeout.ms = null
    	sasl.login.read.timeout.ms = null
    	sasl.login.refresh.buffer.seconds = 300
    	sasl.login.refresh.min.period.seconds = 60
    	sasl.login.refresh.window.factor = 0.8
    	sasl.login.refresh.window.jitter = 0.05
    	sasl.login.retry.backoff.max.ms = 10000
    	sasl.login.retry.backoff.ms = 100
    	sasl.mechanism = GSSAPI
    	sasl.oauthbearer.clock.skew.seconds = 30
    	sasl.oauthbearer.expected.audience = null
    	sasl.oauthbearer.expected.issuer = null
    	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
    	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
    	sasl.oauthbearer.jwks.endpoint.url = null
    	sasl.oauthbearer.scope.claim.name = scope
    	sasl.oauthbearer.sub.claim.name = sub
    	sasl.oauthbearer.token.endpoint.url = null
    	security.protocol = PLAINTEXT
    	security.providers = null
    	send.buffer.bytes = 131072
    	session.timeout.ms = 45000
    	socket.connection.setup.timeout.max.ms = 30000
    	socket.connection.setup.timeout.ms = 10000
    	ssl.cipher.suites = null
    	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
    	ssl.endpoint.identification.algorithm = https
    	ssl.engine.factory.class = null
    	ssl.key.password = null
    	ssl.keymanager.algorithm = SunX509
    	ssl.keystore.certificate.chain = null
    	ssl.keystore.key = null
    	ssl.keystore.location = null
    	ssl.keystore.password = null
    	ssl.keystore.type = JKS
    	ssl.protocol = TLSv1.3
    	ssl.provider = null
    	ssl.secure.random.implementation = null
    	ssl.trustmanager.algorithm = PKIX
    	ssl.truststore.certificates = null
    	ssl.truststore.location = null
    	ssl.truststore.password = null
    	ssl.truststore.type = JKS
    	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
     (org.apache.kafka.clients.consumer.ConsumerConfig:370)
    	acceptable.recovery.lag = 10000
    	application.id = shouldShareWorkInSteadyStatetestAppId
    	application.server = 
    	auto.include.jmx.reporter = true
    	bootstrap.servers = [PLAINTEXT://localhost:54363]
    	buffered.records.per.partition = 1000
    	built.in.metrics.version = latest
    	cache.max.bytes.buffering = 10485760
    	client.id = 
    	commit.interval.ms = 5000
    	connections.max.idle.ms = 540000
    	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
    	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    	default.dsl.store = rocksDB
    	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	default.list.key.serde.inner = null
    	default.list.key.serde.type = null
    	default.list.value.serde.inner = null
    	default.list.value.serde.type = null
    	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
    	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
    	dsl.store.suppliers.class = class org.apache.kafka.streams.state.BuiltInDslStoreSuppliers$RocksDBDslStoreSuppliers
    	enable.metrics.push = true
    	max.task.idle.ms = 0
    	max.warmup.replicas = 2
    	metadata.max.age.ms = 300000
    	metric.reporters = []
    	metrics.num.samples = 2
    	metrics.recording.level = INFO
    	metrics.sample.window.ms = 30000
    	num.standby.replicas = 0
    	num.stream.threads = 1
    	poll.ms = 100
    	probing.rebalance.interval.ms = 600000
    	processing.guarantee = at_least_once
    	rack.aware.assignment.non_overlap_cost = null
    	rack.aware.assignment.strategy = none
    	rack.aware.assignment.tags = []
    	rack.aware.assignment.traffic_cost = null
    	receive.buffer.bytes = 32768
    	reconnect.backoff.max.ms = 1000
    	reconnect.backoff.ms = 50
    	repartition.purge.interval.ms = 30000
    	replication.factor = -1
    	request.timeout.ms = 2000
    	retries = 0
    	retry.backoff.ms = 100
    	rocksdb.config.setter = null
    	security.protocol = PLAINTEXT
    	send.buffer.bytes = 131072
    	state.cleanup.delay.ms = 600000
    	state.dir = /var/folders/6w/glybcljj34jbxwh1ts5l9mwm0000gn/T/junit12678114655061754171
    	statestore.cache.max.bytes = 10485760
    	task.timeout.ms = 300000
    	topology.optimization = none
    	upgrade.from = null
    	window.size.ms = null
    	windowed.inner.class.serde = null
    	windowstore.changelog.additional.retention.ms = 86400000
     (org.apache.kafka.streams.StreamsConfig:370)
    [0K[32m✔[90m shouldShareWorkInSteadyState()[31m (3.4s)[m

GlobalStreamThreadIntegrationTest STANDARD_ERROR
    Test 15(org.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest): CASSANDRA teardown begins at 1731123428000ms (speed check)
    Test 15(org.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest): CASSANDRA teardown ends at 1731123428001ms (duration: PT0.001S) (speed check)
    Test 15(org.apache.kafka.streams.processor.internals.GlobalStreamThreadIntegrationTest): CASSANDRA test total runtime=PT6.123S) (speed check)

Gradle Test Executor 10 STANDARD_OUT

Gradle Test Executor 10 finished executing tests.

> Task :kafka-client:test

  [0K[32m41 passing [90m(16m 35s)
  [0K[36m3 pending
  [0K[31m1 failing[m

Finished generating test XML results (0.238 secs) into: /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/test-results/test
Generating HTML test report...
Finished generating test html results (0.114 secs) into: /Users/sophie/Responsive/responsive-pub-copy/kafka-client/build/reports/tests/test

> Task :kafka-client:test FAILED
16 actionable tasks: 3 executed, 13 up-to-date
Watched directory hierarchies: [/Users/sophie/Responsive/responsive-pub-copy]
Stopped 1 worker daemon(s).
